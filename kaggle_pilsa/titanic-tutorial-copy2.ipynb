{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Titanic Tutorial Copy2\n\n## previously....\n\nin the previous notebook, I followed two tutorial written in korean\n- (titanic tutorial1)https://kaggle-kr.tistory.com/17?category=868316\n- (titanic tutorial2)https://kaggle-kr.tistory.com/18?category=868316\nIncluding part 1 and some of tutorial 2. I've prepared dataset for machine learning.\nBut it is not completed.... I'll continue to copy from 4.4. one-hot encoding.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.style.use('seaborn')\nsns.set(font_scale=2.5)\n\nimport missingno as msno\n\n%matplotlib inline\n#Initiallize libraries and matplotlib.pyplot style like previous notebook (titanic_tutorial_copy1)\n\n#let's check out dataframe before we start....\ndf_train=pd.read_csv('../input/titanic-tutorical-copy1to2/df_train1.csv')\ndf_test=pd.read_csv('../input/titanic-tutorical-copy1to2/df_test1.csv')\n\nprint(df_train)\nprint(df_test)","metadata":{"id":"xwO7NHr-imf0","execution":{"iopub.status.busy":"2022-07-09T14:45:39.339477Z","iopub.execute_input":"2022-07-09T14:45:39.34Z","iopub.status.idle":"2022-07-09T14:45:40.055335Z","shell.execute_reply.started":"2022-07-09T14:45:39.339952Z","shell.execute_reply":"2022-07-09T14:45:40.0541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"They have corresponding 7 columns and train set has 'survived' column, as I expected.  Unfortunately, there is NaN value found. Why does it happened? \n\n","metadata":{}},{"cell_type":"code","source":"#df_train.describe()\ndf_train.describe()\ndf_test.describe()\n#df_test_origin=pd.read_csv('../input/titanic/test.csv')\n#df_test_origin.describe()","metadata":{"execution":{"iopub.status.busy":"2022-07-09T14:56:30.507912Z","iopub.execute_input":"2022-07-09T14:56:30.508365Z","iopub.status.idle":"2022-07-09T14:56:30.564443Z","shell.execute_reply.started":"2022-07-09T14:56:30.508329Z","shell.execute_reply":"2022-07-09T14:56:30.563395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It looks like I forgot to fill up some test.csv columns..... as 'age' feature is filled up with average of 'initial' feature, I can fill up again as average does not changed. Also 'fare' can be filled up as the average of pclass.","metadata":{}},{"cell_type":"code","source":"\nfor i in range(418):\n    if df_test.Age_cat.isnull().values[i]==True:\n        print('age is null ',i, df_test['Initial'][i])\n    if df_test.Initial.isnull().values[i]==True:\n        print('Initial is null ',i,df_test['Sex'][i],df_test['Age_cat'][i])\ndf_test[['Initial','Age_cat']].groupby(['Initial'], as_index=True).mean()\nprint(df_test.groupby('Initial').mean())\n","metadata":{"execution":{"iopub.status.busy":"2022-07-09T15:11:55.268133Z","iopub.execute_input":"2022-07-09T15:11:55.269436Z","iopub.status.idle":"2022-07-09T15:11:55.354383Z","shell.execute_reply.started":"2022-07-09T15:11:55.269379Z","shell.execute_reply":"2022-07-09T15:11:55.353061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test['Age_cat'][96]=3.0\ndf_test['Initial'][414]=3.0 #chosen 3.0 from sex and age\ndf_test.describe()","metadata":{"execution":{"iopub.status.busy":"2022-07-09T15:13:22.159185Z","iopub.execute_input":"2022-07-09T15:13:22.159629Z","iopub.status.idle":"2022-07-09T15:13:22.19896Z","shell.execute_reply.started":"2022-07-09T15:13:22.159588Z","shell.execute_reply":"2022-07-09T15:13:22.197754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## One-hot encoding Embarked and Initial.\n\nI'll not discuss One-hot encoding works. Anyway it can be easily done with get_dummies of pandas.","metadata":{}},{"cell_type":"code","source":"df_train=pd.get_dummies(df_train, columns=['Embarked'],prefix='Embarked')\ndf_test=pd.get_dummies(df_test, columns=['Embarked'], prefix = 'Embarked')","metadata":{"execution":{"iopub.status.busy":"2022-07-09T15:15:45.853077Z","iopub.execute_input":"2022-07-09T15:15:45.853494Z","iopub.status.idle":"2022-07-09T15:15:45.883866Z","shell.execute_reply.started":"2022-07-09T15:15:45.85346Z","shell.execute_reply":"2022-07-09T15:15:45.882279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.get_dummies(df_train, columns=['Initial'], prefix='Initial')\ndf_test = pd.get_dummies(df_test, columns=['Initial'], prefix='Initial')\ndf_train.describe()","metadata":{"execution":{"iopub.status.busy":"2022-07-09T15:17:32.206303Z","iopub.execute_input":"2022-07-09T15:17:32.20672Z","iopub.status.idle":"2022-07-09T15:17:32.276346Z","shell.execute_reply.started":"2022-07-09T15:17:32.206686Z","shell.execute_reply":"2022-07-09T15:17:32.274886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"final dataset check-up before building machine learning model","metadata":{}},{"cell_type":"code","source":"print(df_train.describe())\nprint(df_test.describe())","metadata":{"execution":{"iopub.status.busy":"2022-07-09T15:21:07.462561Z","iopub.execute_input":"2022-07-09T15:21:07.46297Z","iopub.status.idle":"2022-07-09T15:21:07.557647Z","shell.execute_reply.started":"2022-07-09T15:21:07.462937Z","shell.execute_reply":"2022-07-09T15:21:07.556103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building machine learning model and prediction using the trained model","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier #randomforest모델을 쓴답니다.\nfrom sklearn import metrics #제출 전 사전평가를 위해 사용한다고 합니다.\nfrom sklearn.model_selection import train_test_split #역시 사전평가에 쓰일 데이터를 준비하는 것 같습니다.","metadata":{"execution":{"iopub.status.busy":"2022-07-09T15:24:19.51856Z","iopub.execute_input":"2022-07-09T15:24:19.518984Z","iopub.status.idle":"2022-07-09T15:24:19.525206Z","shell.execute_reply.started":"2022-07-09T15:24:19.51895Z","shell.execute_reply":"2022-07-09T15:24:19.523959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = df_train.drop('Survived', axis=1).values\ntarget_label = df_train['Survived'].values\nX_test = df_test.values\n#결과를 알고 있는 train셋에서 임의로 일부를 떼어내 테스트 셋으로 사용, 모델의 성능을 예측해봅니다.","metadata":{"id":"dY_lfX6Wi04X","execution":{"iopub.status.busy":"2022-07-09T15:25:07.330898Z","iopub.execute_input":"2022-07-09T15:25:07.331318Z","iopub.status.idle":"2022-07-09T15:25:07.340917Z","shell.execute_reply.started":"2022-07-09T15:25:07.331283Z","shell.execute_reply":"2022-07-09T15:25:07.339234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_tr, X_vld, y_tr, y_vld = train_test_split(X_train, target_label, test_size=0.3, random_state=2018)\nmodel = RandomForestClassifier()\nmodel.fit(X_tr, y_tr)\nprediction = model.predict(X_vld)","metadata":{"execution":{"iopub.status.busy":"2022-07-09T15:27:11.729323Z","iopub.execute_input":"2022-07-09T15:27:11.729766Z","iopub.status.idle":"2022-07-09T15:27:11.966031Z","shell.execute_reply.started":"2022-07-09T15:27:11.729733Z","shell.execute_reply":"2022-07-09T15:27:11.964648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('{}명 중 {}%의 생존을 맞춤.'.format(y_vld.shape[0],100*metrics.accuracy_score(prediction,y_vld)))","metadata":{"execution":{"iopub.status.busy":"2022-07-09T15:30:20.770049Z","iopub.execute_input":"2022-07-09T15:30:20.770503Z","iopub.status.idle":"2022-07-09T15:30:20.7795Z","shell.execute_reply.started":"2022-07-09T15:30:20.770468Z","shell.execute_reply":"2022-07-09T15:30:20.778351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.3. Feature importance\n\n어떤 feature가 생존률에 큰 영향을 줬는지 따져보는 것 같습니다.","metadata":{}},{"cell_type":"markdown","source":"## 4.4 Prediction on Test set","metadata":{}},{"cell_type":"code","source":"from pandas import Series\n\nfeature_importance = model.feature_importances_\nSeries_feat_imp = Series(feature_importance, index=df_test.columns)\n\nplt.figure(figsize=(8,8))\nSeries_feat_imp.sort_values(ascending=True).plot.barh()\nplt.xlabel('Importance')\nplt.ylabel('Feature')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-09T15:33:29.440099Z","iopub.execute_input":"2022-07-09T15:33:29.440489Z","iopub.status.idle":"2022-07-09T15:33:29.778624Z","shell.execute_reply.started":"2022-07-09T15:33:29.440457Z","shell.execute_reply":"2022-07-09T15:33:29.777439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.4 Prediction on Test set","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv('../input/titanic/gender_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-07-09T15:36:12.646914Z","iopub.execute_input":"2022-07-09T15:36:12.647319Z","iopub.status.idle":"2022-07-09T15:36:12.657864Z","shell.execute_reply.started":"2022-07-09T15:36:12.647286Z","shell.execute_reply":"2022-07-09T15:36:12.6563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-09T15:36:26.640256Z","iopub.execute_input":"2022-07-09T15:36:26.640662Z","iopub.status.idle":"2022-07-09T15:36:26.652636Z","shell.execute_reply.started":"2022-07-09T15:36:26.64063Z","shell.execute_reply":"2022-07-09T15:36:26.651597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = model.predict(X_test)\nsubmission['Survived']=prediction\nsubmission.to_csv('./my_first_submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-07-09T15:37:29.301182Z","iopub.execute_input":"2022-07-09T15:37:29.301551Z","iopub.status.idle":"2022-07-09T15:37:29.335757Z","shell.execute_reply.started":"2022-07-09T15:37:29.301519Z","shell.execute_reply":"2022-07-09T15:37:29.334916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"submission 파일을 만들 수 있었습니다.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}