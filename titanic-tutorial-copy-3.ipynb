{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Titanic Tutorial Copy 3\n\nPreviously I copied a blog post about titanic tutorial. It was titanic tutorial copy 1 and 2. Now I'm going to copy a kaggle notebook [EDA to Prediction(DieTanic)](https://www.kaggle.com/code/ash316/eda-to-prediction-dietanic/notebook) by Ashwini Swain\n\n> 삶은 때떄로 잔혹한 유머감각을 보여준다. 최악의 상황에서 항상 원했던 것을 던져주는 것으로  \n-Lisa Kleypas  \n\n도입부에서 글쓴이는 타이타닉 사고의 의미 등을 설명하다가 upvote를 해주면 자신이 의욕을 얻을 수 있을 것 같다고 한다. 별 감흥이 느껴지지 않는다. Kaggle에서는 upvote를 직접적으로 요청하는 것이 금지돼 있지 않나 하는 생각이 먼저 들었다.\n\n## 이 노트북의 내용\n1. 탐험적 데이터 분석 (EDA)\n- Feature 분석\n- 복수의 feature 사이에서 관계와 경향 분석\n2. Feature 다듬기, 데이터 정리\n- 'Adding any few features'?\n- 쓸모없는 feature 제거\n- 모델링에 적당한 모양으로 feature 전환\n3. 예측 모델\n- 기본적인 알고리즘 실행\n- 상호 대조\n- 앙상블을 통한 분석\n- 주요 feature 추출\n\n# Part1: 탐험적 데이터 분석\n먼저 기본적인 라이브러리를 import하고 초기설정을 조금 합니다.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('fivethirtyeight') #style similar to 'fivethirtyeight.com'\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:54:58.163199Z","iopub.execute_input":"2022-07-14T06:54:58.164565Z","iopub.status.idle":"2022-07-14T06:54:58.173715Z","shell.execute_reply.started":"2022-07-14T06:54:58.164514Z","shell.execute_reply":"2022-07-14T06:54:58.172419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"```python\nplt.style.use('fivethirtyeight')\n```\nmatplotlib.pyplot의 style 설정값으로 동명의 사이트와 같은 스타일이라고 합니다. 이외에는 이전에 베낀 블로그 글과 크게 다르지 않습니다.","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('../input/titanic/train.csv')\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:54:58.467944Z","iopub.execute_input":"2022-07-14T06:54:58.468675Z","iopub.status.idle":"2022-07-14T06:54:58.501377Z","shell.execute_reply.started":"2022-07-14T06:54:58.468633Z","shell.execute_reply":"2022-07-14T06:54:58.500524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"데이터를 불러오기 위해서는 competition에 들어가서 notebook을 생성하거나 notebook에서 add data를 통해 titanic data를 불러와야 합니다. 후자의 방법으로 해서 그런지 directory가 달라졌습니다.","metadata":{}},{"cell_type":"code","source":" data.isnull().sum() #check null values","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:54:58.743304Z","iopub.execute_input":"2022-07-14T06:54:58.744281Z","iopub.status.idle":"2022-07-14T06:54:58.755649Z","shell.execute_reply.started":"2022-07-14T06:54:58.744241Z","shell.execute_reply":"2022-07-14T06:54:58.754327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"pandas dataframe의 isnull() 메소드는 각 feature(혹은 column)의 값들을 각각 null값인지 판단해서 bool값으로 바꿔서 반환하고, sum()은 그것들을 합쳐줍니다.  \n Age, Cabin, Embarked에 null값이 있습니다.","metadata":{}},{"cell_type":"markdown","source":"# 얼마나 많이 살아남았나?\n먼저 예측할 대상(target label등으로 불립니다)인 생존 여부에 대해 살펴봅니다.","metadata":{}},{"cell_type":"code","source":"f,ax = plt.subplots(1,2,figsize=(18,8))\ndata['Survived'].value_counts().plot.pie(explode = [0,0.1], autopct='%1.1f%%', ax=ax[0], shadow=True)\nsns.countplot('Survived',data = data,ax=ax[1])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:54:59.430473Z","iopub.execute_input":"2022-07-14T06:54:59.431340Z","iopub.status.idle":"2022-07-14T06:54:59.719562Z","shell.execute_reply.started":"2022-07-14T06:54:59.431278Z","shell.execute_reply":"2022-07-14T06:54:59.718204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#help(pd.DataFrame.plot)\n#help(pd.Series.plot.pie)","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:54:59.827111Z","iopub.execute_input":"2022-07-14T06:54:59.828346Z","iopub.status.idle":"2022-07-14T06:54:59.832636Z","shell.execute_reply.started":"2022-07-14T06:54:59.828301Z","shell.execute_reply":"2022-07-14T06:54:59.831650Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"plot.pie() 메소드의 explode나 autopc에 대해 더 자세히 알아보려고 했지만 별로 찾지 못했습니다. 생존률은 38.4%로 상당히 낮았습니다. 이제 각 feature들을 분석학고 생존율을 봅시다.","metadata":{}},{"cell_type":"markdown","source":"# Feature의 종류\n\n## 분류가능 feature (Categorical Feature)\n둘 혹은 그 이상의 카테고리로 분류됩니다. 성별이 대표적이고 정렬하거나 순서를 붙일 수 없습니다. 'Nominal Variables'라고도 불립니다. 여기서는 Sex, Embarked feature가 그렇습니다.\n\n## 순서 있는 feature (Ordinal Feature)\n분류 가능 feature와 유사하지만 순서가 있습니다. 여기서는 PClass가 있습니다.\n\n## 연속적인 feature\n두 점 사이의 어떤 값이라도 될 수 있는 feature라고 합니다. 두 점은 최소값과 최대값입니다. 여기서는 'Age'가 그에 해당합니다.\n\n# Analysing the Feature\n## Sex->Categorical Feature","metadata":{}},{"cell_type":"code","source":"data.groupby(['Sex','Survived'])['Survived'].count() #groupby returns dataframe'groupby' object, similar to the DF but have some useful method","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:00.215572Z","iopub.execute_input":"2022-07-14T06:55:00.216644Z","iopub.status.idle":"2022-07-14T06:55:00.229179Z","shell.execute_reply.started":"2022-07-14T06:55:00.216597Z","shell.execute_reply":"2022-07-14T06:55:00.227613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, ax =plt. subplots(1,2,figsize=(18,8))\ndata[['Sex', 'Survived']].groupby(['Sex']).mean().plot.bar(ax=ax[0])\nax[0].set_title('Survived vs Sex')\nsns.countplot('Sex', hue='Survived', data=data, ax=ax[1])\nax[1].set_title('Sex:Survived vs Dead')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:00.712268Z","iopub.execute_input":"2022-07-14T06:55:00.713276Z","iopub.status.idle":"2022-07-14T06:55:01.055214Z","shell.execute_reply.started":"2022-07-14T06:55:00.713210Z","shell.execute_reply":"2022-07-14T06:55:01.053653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"성별과 생존률의 관계를 기본적으로 살펴보았는데, 여성이 훨씬 적었는데도 훨씬 많이 살아남았다는 결론이 나왔습니다. 생존률로 보면 그 차이가 극명하여 이 feature는 아주 중요할 예정입니다.","metadata":{}},{"cell_type":"markdown","source":"## Pclass -> Ordinal Feature\n다음은 Pclass에 대해 살펴봅니다.","metadata":{}},{"cell_type":"code","source":"pd.crosstab(data.Pclass,data.Survived #between two categorical/ordinal feature, crosstab shows the number of passengers belongs to combined category\n           ,margins=True).style.background_gradient(cmap='summer_r')","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:01.112922Z","iopub.execute_input":"2022-07-14T06:55:01.113370Z","iopub.status.idle":"2022-07-14T06:55:01.170788Z","shell.execute_reply.started":"2022-07-14T06:55:01.113336Z","shell.execute_reply":"2022-07-14T06:55:01.169436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"분류 자료 두 개를 놓으면 각각의 분류 유형 수를 곱한 것 만큼의 경우의 수(혹은 tuple)를 가지고 새로운 카테고리를 설정할 수 있습니다. crosstab은 이런 합쳐진 카테고리들에 속한 데이터를 보여줍니다.","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(1, 2, figsize = (18,8))\ndata['Pclass'].value_counts().plot.bar(color=['Orange'], ax=ax[0])\nax[0].set_title('Number of Passengers By Class')\nax[0].set_ylabel('Count')\nsns.countplot('Pclass', hue='Survived', data=data,ax=ax[1])\nax[1].set_title('Pclass:Survived vs Dead')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:01.398968Z","iopub.execute_input":"2022-07-14T06:55:01.399428Z","iopub.status.idle":"2022-07-14T06:55:01.735317Z","shell.execute_reply.started":"2022-07-14T06:55:01.399394Z","shell.execute_reply":"2022-07-14T06:55:01.733741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"제일 비싼 1등실 승객들의 생존률이 높았습니다. 구출 우선순위로 설정되었다고 합니다. 확률로 보면 1등 선실부터 63%, 48%, 25%로 급격히 감소합니다.\n이번에는 Sex, Pclass, 생존여부를 한번에 crosstab으로 살펴봅니다.","metadata":{}},{"cell_type":"code","source":"pd.crosstab([data.Sex, data.Survived], data.Pclass, margins=True).style.background_gradient(cmap='summer_r')","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:01.737329Z","iopub.execute_input":"2022-07-14T06:55:01.737646Z","iopub.status.idle":"2022-07-14T06:55:01.792209Z","shell.execute_reply.started":"2022-07-14T06:55:01.737615Z","shell.execute_reply":"2022-07-14T06:55:01.790723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.factorplot('Pclass','Survived',hue='Sex',data=data)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:01.925366Z","iopub.execute_input":"2022-07-14T06:55:01.925776Z","iopub.status.idle":"2022-07-14T06:55:02.516893Z","shell.execute_reply.started":"2022-07-14T06:55:01.925743Z","shell.execute_reply":"2022-07-14T06:55:02.515366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Factor plot에서 Pclass의 영향을 포함해도 여성의 생존률이 더 높게 나타남을 확인합니다. 1등실 남성 승객의 생존률도 3등실 여성 승객에 비해 낮습니다만 오차범위 이내이기는 하네요. crosstab과 factor plot은 사실 거의 같은 데이터입니다. ","metadata":{}},{"cell_type":"markdown","source":"## Age -> Continuous Feature\n이번에는 Age 속성에 대해 알아보겠습니다. 이건 연속적인 속성입니다. 연령 범위에 대해 잠깐 살펴봅니다.\n```python\nprint(data['Age'].max(),data['Age'].min(),data['Age'].mean())\n```\n그 결과 최대 80, 최소 0.42, 평균 29.699...가 나왔습니다. 다음으로는 violin chart를 이용해 연령분포에 따른 생존자의 순을 살펴봅니다. 그런데 앞에서 중요하다고 했던 Pclass, Sex에 따라 나눠서 봅시다.","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(1,2,figsize = (18,8))\nsns.violinplot(\"Pclass\",'Age', hue='Survived', data=data, split=True, ax=ax[0])\nax[0].set_title('Pclass and Age vs Survived')\nax[0].set_yticks(range(0,110,10))\nsns.violinplot('Sex','Age', hue='Survived', data=data, split=True, ax=ax[1])\nax[1].set_yticks(range(0,110,10))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:02.519295Z","iopub.execute_input":"2022-07-14T06:55:02.519697Z","iopub.status.idle":"2022-07-14T06:55:03.023452Z","shell.execute_reply.started":"2022-07-14T06:55:02.519664Z","shell.execute_reply":"2022-07-14T06:55:03.021810Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 관찰 결과\n- 3등실 승객으로 갈수록 10세 이하 어린이가 많았습니다. 아이들은 생존율이 낮았던 3등실에서도 많이 살아남았습니다.\n- 1등실 승객 20세~50세의 생존율이 높습니다. 여성의 경우 더 높습니다.\n- 남성의 경우 연령이 증가할수록 생존율이 줄었습니다\n\nQ나)이 경우 왜 확률을 보여주지 않고 이 바이올린 차트에서 따지는지 궁금하네요. 자료값이 많은 구간은 괜찮지만 적은 곳은 비교하기가 힘듭니다.\n\n### 나이의 null값 채워넣기\n177 null value가 있는데 우리는 그냥 평균값을 줘버리기 보다 승객이 어떤 연령 구간에 속하는지 찾아보고 싶습니다. 여기에서 'Name' 속성을 살펴보도록 합니다. 여기에는 salutation (미스터, 미스, 미세스 같은 것들. Initial과 거의 같은 의미입니다.)이 들어있고 그것의 평균을 취해봅시다.\n\n먼저 'Name' 속성에서 'Initial' 속성을 새로 추출합니다.","metadata":{}},{"cell_type":"code","source":"data['Initial']=0\nfor i in data:\n    data['Initial'] = data.Name.str.extract('([A-Za-z]+)\\.') #extraction of salutation using its format","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:03.025453Z","iopub.execute_input":"2022-07-14T06:55:03.025800Z","iopub.status.idle":"2022-07-14T06:55:03.087755Z","shell.execute_reply.started":"2022-07-14T06:55:03.025762Z","shell.execute_reply":"2022-07-14T06:55:03.086576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"str.extract method에 들어간 것은 'Regular Expression'이라고 불리는데, 다음 문서를 참고하면 좋겠네요.  \n[Regular expression operations - python.org](https://docs.python.org/3/library/re.html)  \n일단 여기서 쓰인 것은 알파벳이 나오다가 마침표로 끝나는 문자열을 추출한다는 것입니다.","metadata":{}},{"cell_type":"code","source":"pd.crosstab(data.Initial, data.Sex).T.style.background_gradient(cmap = 'summer_r')","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:03.090480Z","iopub.execute_input":"2022-07-14T06:55:03.090852Z","iopub.status.idle":"2022-07-14T06:55:03.148641Z","shell.execute_reply.started":"2022-07-14T06:55:03.090819Z","shell.execute_reply":"2022-07-14T06:55:03.147135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"오타/오기/오인된 이니셜이 있다면서 Mlle나 Mme 등을 Miss로 고치는 등의 수정작업을 합니다. 그런데 Dr.에 여성이 한 명 있음에도 불구하고 Mrs로 수정해버리네요. 제 생각엔 Doctor같기 때문에 그렇게 고치지 않겠습니다.","metadata":{}},{"cell_type":"code","source":"data['Initial'].replace(['Mlle','Mme','Ms'],'Miss',inplace=True)\ndata['Initial'].replace(['Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don'],\n                       ['Mr', 'Mrs', 'Mrs', 'Other', 'Other','Other','Mr','Mr','Mr'], inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:03.151117Z","iopub.execute_input":"2022-07-14T06:55:03.151654Z","iopub.status.idle":"2022-07-14T06:55:03.166152Z","shell.execute_reply.started":"2022-07-14T06:55:03.151602Z","shell.execute_reply":"2022-07-14T06:55:03.164204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data.groupby('Initial')['Age'].count())\nprint(data.groupby('Initial')['Age'].mean())","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:03.278340Z","iopub.execute_input":"2022-07-14T06:55:03.279594Z","iopub.status.idle":"2022-07-14T06:55:03.290812Z","shell.execute_reply.started":"2022-07-14T06:55:03.279547Z","shell.execute_reply":"2022-07-14T06:55:03.289776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"NaN values에 같은 initial을 가진 사람의 나이 평균을 대입합니다. loc메소드를 사용합니다. 간단히 dictionary를 만들어서 사용하겠습니다.","metadata":{}},{"cell_type":"code","source":"initial_to_age={'Dr':42, 'Master':4.6, 'Miss': 21.9, 'Mr':32.6, 'Mrs': 36.0, 'Other':45.9}\nfor init in initial_to_age:\n    data.loc[(data.Age.isnull())&(data.Initial==init),'Age']=initial_to_age[init]","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:03.558495Z","iopub.execute_input":"2022-07-14T06:55:03.558959Z","iopub.status.idle":"2022-07-14T06:55:03.573813Z","shell.execute_reply.started":"2022-07-14T06:55:03.558914Z","shell.execute_reply":"2022-07-14T06:55:03.572430Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.Age.isnull().any()","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:03.822129Z","iopub.execute_input":"2022-07-14T06:55:03.822612Z","iopub.status.idle":"2022-07-14T06:55:03.830221Z","shell.execute_reply.started":"2022-07-14T06:55:03.822575Z","shell.execute_reply":"2022-07-14T06:55:03.829098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"isnull()은 시리즈의 값이 null인지 판단해 bool값이 저장된 같은 size의 시리즈를 반환하고, any()는 시리즈의 값들 중 하나라도 True가 있으면 True를 반환합니다. 즉 나이의 null값이 다 없어졌는지 확인한 것입니다. Age도 없고 Initial도 없는 자료는 다행히 없었던 것 같습니다.","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(1,2,figsize=(20,10))\ndata[data['Survived']==0].Age.plot.hist(ax=ax[0],bins=20,edgecolor='black',color='red')\nax[0].set_title('Survived= 0')\nx1=list(range(0,85,5))\nax[0].set_xticks(x1)\ndata[data['Survived']==1].Age.plot.hist(ax=ax[1],color='green',bins=20,edgecolor='black')\nax[1].set_title('Survived=1')\nax[1].set_xticks(x1) #use x1 again cause it's same\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:04.099212Z","iopub.execute_input":"2022-07-14T06:55:04.100306Z","iopub.status.idle":"2022-07-14T06:55:04.596649Z","shell.execute_reply.started":"2022-07-14T06:55:04.100259Z","shell.execute_reply":"2022-07-14T06:55:04.595805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 분석\n- 영유아들은 많이 살았습니다.\n- 최고령자는 생존했습니다.\n- 30세~40세 그룹에서 사망자가 가장 많았습니다.","metadata":{}},{"cell_type":"code","source":"sns.factorplot('Pclass','Survived',col='Initial',data=data[(data['Initial']!='Dr')&(data['Initial']!='Other')])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:04.598824Z","iopub.execute_input":"2022-07-14T06:55:04.599749Z","iopub.status.idle":"2022-07-14T06:55:05.602894Z","shell.execute_reply.started":"2022-07-14T06:55:04.599685Z","shell.execute_reply":"2022-07-14T06:55:05.601434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"닥터와 other는 자료 숫자가 너무 적어서 배제하였습니다.\n표 등급과 관계없이 아이와 여성이 많이 생존했습니다.","metadata":{}},{"cell_type":"markdown","source":"## Embarked -> Categorical Value\n이번에는 승선 항구를 살펴봅니다.","metadata":{}},{"cell_type":"code","source":"pd.crosstab([data.Embarked,data.Pclass],[data.Sex,data.Survived],margins=True).style.background_gradient(cmap='summer_r')","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:05.605305Z","iopub.execute_input":"2022-07-14T06:55:05.605646Z","iopub.status.idle":"2022-07-14T06:55:05.684248Z","shell.execute_reply.started":"2022-07-14T06:55:05.605613Z","shell.execute_reply":"2022-07-14T06:55:05.682905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 승선 항구에 따른 생존률 변화","metadata":{}},{"cell_type":"code","source":"sns.factorplot('Embarked','Survived',data=data)\nfig=plt.gcf() #gcf() get the current figure. make new one if stack is empty\nfig.set_size_inches(5,3)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:05.685608Z","iopub.execute_input":"2022-07-14T06:55:05.685937Z","iopub.status.idle":"2022-07-14T06:55:06.042705Z","shell.execute_reply.started":"2022-07-14T06:55:05.685906Z","shell.execute_reply":"2022-07-14T06:55:06.041208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"항구 C의 생존률이 0.55 정도로 가장 높고 S가 0.34 정도로 가장 낮았습니다.","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(2,2,figsize=(20,15))\nsns.countplot('Embarked', data=data, ax=ax[0,0])\nax[0][0].set_title('No. of Passengers Boarded')\nsns.countplot('Embarked', hue='Sex', data=data, ax=ax[0,1])\nax[0,1].set_title('Male-Female Split for Embarked')\nsns.countplot('Embarked', hue='Survived', data=data, ax=ax[1,0])\nax[1][0].set_title('Embarked vs Survived')\nsns.countplot('Embarked', hue='Pclass', data=data, ax=ax[1][1])\nax[1,1].set_title('Embarked vs Pclass')\nplt.subplots_adjust(wspace=0.2, hspace=0.5)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:06.046638Z","iopub.execute_input":"2022-07-14T06:55:06.047029Z","iopub.status.idle":"2022-07-14T06:55:06.671553Z","shell.execute_reply.started":"2022-07-14T06:55:06.046988Z","shell.execute_reply":"2022-07-14T06:55:06.670122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 분석\n- S항구에서 가장 많은 승객이 탑승했으며 주로 3등실 승객이었다.\n- C항구 승객은 많이 살아남은 것처럼 보이는데 1, 2등실 승객이 많아서 그랬던 것일 수도 있다.\n- S항구에서 1등실 승객이 가장 많이 탔는데 생존률이 낮다. 하지만 이건 3등실 승객이 그보다 훨씬 많이 탑승해서 그런 것이다.\n- Q항구에는 대부분 3등실 승객이 탑승했다. (95%가량)\nQ나) 3등실 승객이라 많이 죽은 것인지 S항구에서 타서 많이 죽은 것인지 인과관계를 함부로 단정짓는 것은 위험한 것 같다. 3등실 승객의 대부분이 S항구에서 승선했기 때문에 구분하기 쉽지 않다.","metadata":{}},{"cell_type":"code","source":"sns.factorplot('Pclass','Survived',hue='Sex',col='Embarked',data=data)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:06.673612Z","iopub.execute_input":"2022-07-14T06:55:06.674105Z","iopub.status.idle":"2022-07-14T06:55:07.956408Z","shell.execute_reply.started":"2022-07-14T06:55:06.674058Z","shell.execute_reply":"2022-07-14T06:55:07.954835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 분석결과\n- 1,2선실 승객 여성은 거의 살아남았다.\n- Q항구 승선자는 특히 남자들의 경우 생존율이 가장 낮았다.\n- S항구 승선자이면서 3등실 승객의 생존율은 굉장히 낮았다.","metadata":{}},{"cell_type":"markdown","source":"## 승선항구 빈 칸 채워넣기\n가장 많은 승객이 S항구에서 승선했으므로 그냥 S항구로 채웁니다. 이런 경우 loc 메소드 등을 써도 되지만 fillna method를 쓰면 간단하게 null값을 채울 수 있습니다.","metadata":{}},{"cell_type":"code","source":"data['Embarked'].fillna('S',inplace=True)\ndata.Embarked.isnull().any()","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:07.957740Z","iopub.execute_input":"2022-07-14T06:55:07.958101Z","iopub.status.idle":"2022-07-14T06:55:07.969049Z","shell.execute_reply.started":"2022-07-14T06:55:07.958066Z","shell.execute_reply":"2022-07-14T06:55:07.967641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SibSp -> 불연속 속성\n이 속성은 가족 멤버의 수를 보여줍니다.\nSibling(형제, 자매, 의형제, 의자매), Spouse(배우자) 둘을 합친 것 같습니다.","metadata":{}},{"cell_type":"code","source":"pd.crosstab([data.SibSp],data.Survived).style.background_gradient(cmap='summer_r')","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:07.972751Z","iopub.execute_input":"2022-07-14T06:55:07.973217Z","iopub.status.idle":"2022-07-14T06:55:08.006935Z","shell.execute_reply.started":"2022-07-14T06:55:07.973181Z","shell.execute_reply":"2022-07-14T06:55:08.005608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, ax = plt.subplots(1,2, figsize=(20,8))\nsns.barplot('SibSp','Survived',data=data,ax=ax[0])\nax[0].set_title('SibSp vs Survived')\nsns.pointplot('SibSp','Survived',data=data,ax=ax[1])\nax[1].set_title('SibSp vs Survived')\n#plt.close(2) #something is wrong. no fig2 if I include this line\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:08.008399Z","iopub.execute_input":"2022-07-14T06:55:08.008850Z","iopub.status.idle":"2022-07-14T06:55:08.851502Z","shell.execute_reply.started":"2022-07-14T06:55:08.008812Z","shell.execute_reply":"2022-07-14T06:55:08.850029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.crosstab(data.SibSp, data.Pclass).style.background_gradient(cmap='summer_r')","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:08.853412Z","iopub.execute_input":"2022-07-14T06:55:08.853793Z","iopub.status.idle":"2022-07-14T06:55:08.889902Z","shell.execute_reply.started":"2022-07-14T06:55:08.853759Z","shell.execute_reply":"2022-07-14T06:55:08.888796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 분석\n막대그래프와 factor plot에서 SibSp가 1인, 즉 혼자 탄 승객은 34.5%의 생존율이 나왔고 SibSp가 증가할수록 생존율이 조금 줄었다. 신경쓸 사람이 많으면 생존이 어려워진다고 설명하면 납득이 간다. SibSp 4-6, 즉 5-8인과 승선한 이들은 다 사망했는데 전부 3등실 승객이었기 때문에 그런 것 같다. ","metadata":{}},{"cell_type":"markdown","source":"## Parch\n 배우자 및 부모자식 수이다.","metadata":{}},{"cell_type":"code","source":"pd.crosstab(data.Parch, data.Pclass).style.background_gradient(cmap='summer_r')","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:08.893405Z","iopub.execute_input":"2022-07-14T06:55:08.893741Z","iopub.status.idle":"2022-07-14T06:55:08.926299Z","shell.execute_reply.started":"2022-07-14T06:55:08.893708Z","shell.execute_reply":"2022-07-14T06:55:08.925061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, ax = plt.subplots(1, 2, figsize=(20,8))\nsns.barplot('Parch','Survived',data=data,ax=ax[0])\nax[0].set_title('Parch vs Survived')\nplt.show()\nsns.factorplot('Parch','Survived',data=data,ax=ax[1])\nax[1].set_title('Parch vs Survived')\nplt.close(2)\nplt.show()\n#Because of weired output, I used netx code.","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:08.928020Z","iopub.execute_input":"2022-07-14T06:55:08.928500Z","iopub.status.idle":"2022-07-14T06:55:09.912231Z","shell.execute_reply.started":"2022-07-14T06:55:08.928465Z","shell.execute_reply":"2022-07-14T06:55:09.911169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, ax = plt.subplots(1, 1, figsize=(6,6))\nsns.barplot('Parch','Survived',data=data,ax=ax)\nax.set_title('Parch vs Survived')\nplt.show()\nsns.factorplot('Parch','Survived',data=data,ax=ax)\nax.set_title('Parch vs Survived')\n#plt.close(2)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:09.915117Z","iopub.execute_input":"2022-07-14T06:55:09.916425Z","iopub.status.idle":"2022-07-14T06:55:10.762406Z","shell.execute_reply.started":"2022-07-14T06:55:09.916386Z","shell.execute_reply":"2022-07-14T06:55:10.761202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 분석\n\n유사한 결과가 나왔는데 부모가 있는 경우 생존율이 크게 증가했다. 1-3부모가 있는 경우 생존율이 증가했고 4인 이상의 부모가 있으면 생존률이 감소했으며 혼자 있어도 살아남기 힘들었다.\n\nQ나) 이 속성은 부모 자식 합한 것 아니었나? 그리고 자료 수가 적은데 경향성을 따지기는 힘들지 않을까.","metadata":{}},{"cell_type":"markdown","source":"## 운임 -> 연속적 속성","metadata":{}},{"cell_type":"code","source":"print('max, min, mean is',data['Fare'].max(),data['Fare'].min(),data['Fare'].mean())","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:10.764065Z","iopub.execute_input":"2022-07-14T06:55:10.765158Z","iopub.status.idle":"2022-07-14T06:55:10.774207Z","shell.execute_reply.started":"2022-07-14T06:55:10.765107Z","shell.execute_reply":"2022-07-14T06:55:10.772698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, ax = plt.subplots(1,3,figsize=(20,8))\nsns.distplot(data[data['Pclass']==1].Fare, ax=ax[0])\nax[0].set_title('Fares in Pclass 1')\nsns.distplot(data[data['Pclass']==2].Fare, ax=ax[1])\nax[1].set_title('Fares in Pclass 2')\nsns.distplot(data[data['Pclass']==3].Fare, ax=ax[2])\nax[2].set_title('Fares in Pclass 3')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:10.776023Z","iopub.execute_input":"2022-07-14T06:55:10.776428Z","iopub.status.idle":"2022-07-14T06:55:11.425378Z","shell.execute_reply.started":"2022-07-14T06:55:10.776395Z","shell.execute_reply":"2022-07-14T06:55:11.423699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1등실 운임은 넓게 퍼져 있었고 등급이 내려갈수록 분포가 좁아졌다. 연속적인 값이기 때문에 구간으로 나누겠다.\n\n## 속성 살펴보기 결록\n성별 : 여성의 생존율이 높았다.\n티켓 클래스 : 비싼 표 가진 사람이 많이 살았다.\n연령 : 10세 이하가 많이 살았고 15~35세는 많이 죽었다.\n항구 : 흥미로운 속성으로 S에서 1클래스가 많았는데도 불구하고 C의 생존율이 높았다. Q는 다 3클래스 표였다. \nQ)이게 맞나?\nParch+SibSp: 1-2SibSp나 1-3Parch를 가질 떄 생존율이 좋았다.","metadata":{}},{"cell_type":"code","source":"## Correlation Between The Features","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:11.428542Z","iopub.execute_input":"2022-07-14T06:55:11.428949Z","iopub.status.idle":"2022-07-14T06:55:11.434247Z","shell.execute_reply.started":"2022-07-14T06:55:11.428914Z","shell.execute_reply":"2022-07-14T06:55:11.433062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(data.corr(),annot=True,cmap='RdYlGn',linewidths=0.2)\nfig=plt.gcf()\nfig.set_size_inches(10,8)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:11.435925Z","iopub.execute_input":"2022-07-14T06:55:11.436480Z","iopub.status.idle":"2022-07-14T06:55:11.947440Z","shell.execute_reply.started":"2022-07-14T06:55:11.436443Z","shell.execute_reply":"2022-07-14T06:55:11.945826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 히트맵 해석\n먼저 correlation이 뭔지 알아봅니다. 양수라면 정비례 관계. 음수라면 반비례 관계인데 1 혹은 -1에 가까울수록 그 관계가 강한 겁니다. 1 혹은 -1에 너무 가까우면 MultiColinearity라고 하는데 거의 같은 정보를 가지고 있다는 뜻이고 하나는 제거해도 괜찮을 수 있습니다.\n그렇지만 위에서는 가장 높은 correlation이 0.41으로 제거할 속성은 보이지 않습니다. ","metadata":{}},{"cell_type":"markdown","source":"# Part2: 속성 다듬기와 데이터 청소\nFeature Engineering(속성 다듬기)\n모든 속성이 중요하지는 않은 데이터셋에서 불필요한 것들을 제거하거나 다른 속성에서 추출하는 등 새로운 속성을 추가하는 경우가 이에 속합니다. 예측 모델링에 적합한 형태로 바꾸기도 합니다.\n\n## Age_band\n연속값은 기계학습에서 문제가 있기 떄문에 categorical value(분류 값)으로 바꿔줍니다. 정규화를 할 수도 있고 Binning을 할 수도 있습니다. binning을 할건데 그것은 그룹을 나눈 다음에 하나의 값을 부여한다는 겁니다.\n16세를 기준으로 나누겠습니다.","metadata":{}},{"cell_type":"code","source":"data['Age_band']=0\nfor i in range(5): #use for loop for efficiency\n    data.loc[(data['Age']>16*i)&(data['Age']<=16*(i+1)),'Age_band']=i\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:11.950072Z","iopub.execute_input":"2022-07-14T06:55:11.950602Z","iopub.status.idle":"2022-07-14T06:55:11.985205Z","shell.execute_reply.started":"2022-07-14T06:55:11.950552Z","shell.execute_reply":"2022-07-14T06:55:11.983567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Age_band'].value_counts().to_frame().style.background_gradient(cmap='summer')\n#to_frame shows table-like output in some frame","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:11.987061Z","iopub.execute_input":"2022-07-14T06:55:11.987553Z","iopub.status.idle":"2022-07-14T06:55:12.008422Z","shell.execute_reply.started":"2022-07-14T06:55:11.987504Z","shell.execute_reply":"2022-07-14T06:55:12.006767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.factorplot('Age_band','Survived',data=data, col='Pclass')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:12.010668Z","iopub.execute_input":"2022-07-14T06:55:12.011309Z","iopub.status.idle":"2022-07-14T06:55:13.032138Z","shell.execute_reply.started":"2022-07-14T06:55:12.011261Z","shell.execute_reply":"2022-07-14T06:55:13.030425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Pclass와 관계없이 생존율은 나이에 반비례하였습니다.","metadata":{}},{"cell_type":"markdown","source":"## 가족 크기\n\nFamily_size와 Alone이라는 속성을 추가하겠습니다. Parch와 SibSp에서 구해지는 속성으로, 이것을 합하면 혼자 승선했는지의 여부도 알 수 있습니다.","metadata":{}},{"cell_type":"code","source":"data['Family_Size']=0\ndata['Family_Size']=data['Parch']+data['SibSp']\ndata['Alone']=0\ndata.loc[data.Family_Size==0,'Alone']=1\n\nf, ax = plt.subplots(1, 2, figsize=(18,6))\nsns.factorplot('Family_Size','Survived', data=data, ax=ax[0])\nax[0].set_title('Family Size vs Survived')\nsns.factorplot('Alone', 'Survived', data=data, ax=ax[1])\nax[1].set_title('Alone vs Survived')\nplt.close(0) \nplt.close(1)#it was originaly close(2), close(3). I don't know where to start solve this,\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:13.035192Z","iopub.execute_input":"2022-07-14T06:55:13.035558Z","iopub.status.idle":"2022-07-14T06:55:14.880685Z","shell.execute_reply.started":"2022-07-14T06:55:13.035526Z","shell.execute_reply":"2022-07-14T06:55:14.879083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"혼자이면 생존률이 매우 감소했고 가족크기가 4 이상이었을 때도 그랬습니다. 중요한 것 같으니 더 살펴봅시다.","metadata":{}},{"cell_type":"code","source":"sns.factorplot('Alone','Survived',data=data, hue='Sex', col='Pclass')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:14.882387Z","iopub.execute_input":"2022-07-14T06:55:14.882732Z","iopub.status.idle":"2022-07-14T06:55:16.030235Z","shell.execute_reply.started":"2022-07-14T06:55:14.882699Z","shell.execute_reply":"2022-07-14T06:55:16.029157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"주요 속성이었던 Sex, Pclass와 별개로 혼자이면 생존율이 감소했습니다. 하지만 3등실 여성 중에서는 가족이 없는 경우의 생존율이 컸습니다.","metadata":{}},{"cell_type":"markdown","source":"## Fare Range \n운임 역시 연속적 속성이므로 ordinal value로 바꿉니다. padas.qcut 메소드를 사용하겠습니다. 이걸 사용하면 같은 숫자의 자료를 가지도록 나눌 수 있습니다.","metadata":{}},{"cell_type":"code","source":"data['Fare_Range']=pd.qcut(data['Fare'],4)\ndata.groupby(['Fare_Range'])['Survived'].mean().to_frame().style.background_gradient(cmap='summer_r')\n","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:16.031645Z","iopub.execute_input":"2022-07-14T06:55:16.032347Z","iopub.status.idle":"2022-07-14T06:55:16.062453Z","shell.execute_reply.started":"2022-07-14T06:55:16.032303Z","shell.execute_reply":"2022-07-14T06:55:16.060942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"위에서 논의된 바와 같이 운임과 생존율도 비례하였습니다. 이제 Fare_Range를 Age_Band처럼 구간으로 바꿉니다.","metadata":{}},{"cell_type":"code","source":"Fare_Ranges=[-0.001,7.91,14.454,31.0,512.329]\ndata['Fare_cat']=0\nfor i in range(4):\n    data.loc[(data['Fare']>Fare_Ranges[i])&(data['Fare']<=Fare_Ranges[i+1]),'Fare_cat']=i","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:16.065036Z","iopub.execute_input":"2022-07-14T06:55:16.066220Z","iopub.status.idle":"2022-07-14T06:55:16.078631Z","shell.execute_reply.started":"2022-07-14T06:55:16.066171Z","shell.execute_reply":"2022-07-14T06:55:16.077390Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.tail(2)","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:16.080261Z","iopub.execute_input":"2022-07-14T06:55:16.081348Z","iopub.status.idle":"2022-07-14T06:55:16.103019Z","shell.execute_reply.started":"2022-07-14T06:55:16.081308Z","shell.execute_reply":"2022-07-14T06:55:16.102131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.factorplot('Fare_cat','Survived',data=data,hue='Sex')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:16.106015Z","iopub.execute_input":"2022-07-14T06:55:16.106809Z","iopub.status.idle":"2022-07-14T06:55:16.753160Z","shell.execute_reply.started":"2022-07-14T06:55:16.106773Z","shell.execute_reply":"2022-07-14T06:55:16.751795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"운임에 따라 생존율이 증가하는 것도 경향성이 뚜렸했습니다. 성별과 마찬가지로 중요 속성이 될 것 같습니다.","metadata":{}},{"cell_type":"markdown","source":"## 문자열을 수로 전환하기\nSex, Embarked 등을 숫자로 바꾸어줍니다. 이 과정에서 Dr와 Other를 합치겠습니다. 평균 연령도 비슷하고 Dr가 지식층이다 같은 것을 이용하기에는 수가 너무 작습니다.","metadata":{}},{"cell_type":"code","source":"data['Sex'].replace(['male','female'],[0,1],inplace=True)\ndata['Embarked'].replace(['S','C','Q'],[0,1,2],inplace=True)\ndata['Initial'].replace(['Mr','Mrs','Miss','Master','Other','Dr'],[0,1,2,3,4,4], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:16.754891Z","iopub.execute_input":"2022-07-14T06:55:16.755244Z","iopub.status.idle":"2022-07-14T06:55:16.771155Z","shell.execute_reply.started":"2022-07-14T06:55:16.755210Z","shell.execute_reply":"2022-07-14T06:55:16.769634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 불필요한 속성들 제거\n\n__Name__ 은 추출한 Initial 이외에 사용하지 않습니다.  \n__Age__ 는 Age_band가 대체했습니다.  \n__Ticket__ 의 경우 딱히 정보를 찾지 못해 배제합니다.  \n__Fare__ 는 Fare_cat이 대체했습니다.  \n__Cabin__ 은 NaN 값이 너무 많고 여러 값을 가진 승객이 많습니다.  \n__Fare_Range__ fare_cat이 대체합니다.  \n__PAssengerId__ 는 분류가 안됩니다.  ","metadata":{}},{"cell_type":"code","source":"data.drop(['Name','Age','Ticket','Fare','Cabin','Fare_Range','PassengerId'],axis=1, inplace=True)\nsns.heatmap(data.corr(), annot=True, cmap='RdYlGn',linewidths=0.2, annot_kws={'size':20})\nfig=plt.gcf()\nfig.set_size_inches(18,15)\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:16.773769Z","iopub.execute_input":"2022-07-14T06:55:16.774486Z","iopub.status.idle":"2022-07-14T06:55:17.634677Z","shell.execute_reply.started":"2022-07-14T06:55:16.774406Z","shell.execute_reply":"2022-07-14T06:55:17.633622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Part3 모델에서 예측 해보기\n\n일부 식견을 얻긴 했지만 어떤 승객의 생존에 대해 예상할 수는 없습니다. 이제 분류 알고리듬을 써서 예측 해봅시다. 여기서는 다음과 같은 알고리즘을 사용할 겁니다.\n1. 로지스틱 회귀\n2. support vector machines(SVM, Linear and radial)\n3. Random Forest\n4. K-Nearest Neighbours\n5. Naive Bayes\n6. 선택나무\n7. 로지스틱 회귀 (왜 반복됐을까요?)\n\n필요한 모든 기계학습 패키지를 불러옵니다.","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn import svm\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\n","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:17.636410Z","iopub.execute_input":"2022-07-14T06:55:17.636839Z","iopub.status.idle":"2022-07-14T06:55:17.644539Z","shell.execute_reply.started":"2022-07-14T06:55:17.636800Z","shell.execute_reply":"2022-07-14T06:55:17.642906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train, test=train_test_split(data,test_size=0.3, random_state=0, stratify=data['Survived'])\ntrain_X=train[train.columns[1:]]\ntrain_Y=train[train.columns[:1]] #first column is 'target label', so divided like this.\ntest_X=test[test.columns[1:]]\ntest_Y=test[test.columns[:1]]\nX=data[data.columns[1:]]\nY=data['Survived']","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:17.646622Z","iopub.execute_input":"2022-07-14T06:55:17.647761Z","iopub.status.idle":"2022-07-14T06:55:17.666518Z","shell.execute_reply.started":"2022-07-14T06:55:17.647712Z","shell.execute_reply":"2022-07-14T06:55:17.664380Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#rbf-SVM\nmodel=svm.SVC(kernel='rbf',C=1,gamma=0.1)\nmodel.fit(train_X, train_Y)\nprediction1=model.predict(test_X)\nprint('Accuracy for rbf SVM is ',metrics.accuracy_score(prediction1,test_Y))","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:17.670140Z","iopub.execute_input":"2022-07-14T06:55:17.670565Z","iopub.status.idle":"2022-07-14T06:55:17.709092Z","shell.execute_reply.started":"2022-07-14T06:55:17.670529Z","shell.execute_reply":"2022-07-14T06:55:17.707345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Linear-SVM\nmodel = svm.SVC(kernel='linear',C=0.1,gamma=0.1)\nmodel.fit(train_X, train_Y)\nprediction2 = model.predict(test_X)\nprint('Accuracy for linear SVM is ',metrics.accuracy_score(prediction2, test_Y))","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:17.710704Z","iopub.execute_input":"2022-07-14T06:55:17.711094Z","iopub.status.idle":"2022-07-14T06:55:17.739154Z","shell.execute_reply.started":"2022-07-14T06:55:17.711047Z","shell.execute_reply":"2022-07-14T06:55:17.738105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Decision Tree\n\nmodel = LogisticRegression()\nmodel.fit(train_X, train_Y)\nprediction3 = model.predict(test_X)\nprint('Accuracy for Logistic Regression is ', metrics.accuracy_score(prediction3, test_Y))","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:17.740487Z","iopub.execute_input":"2022-07-14T06:55:17.741123Z","iopub.status.idle":"2022-07-14T06:55:17.765087Z","shell.execute_reply.started":"2022-07-14T06:55:17.741084Z","shell.execute_reply":"2022-07-14T06:55:17.763619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#K-Nearest Neighbors (KNN)\nmodel = KNeighborsClassifier()\nmodel.fit(train_X,train_Y)\nprediction5 = model.predict(test_X)\nprint('accuray for KNN is ',metrics.accuracy_score(prediction5,test_Y))","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:17.766905Z","iopub.execute_input":"2022-07-14T06:55:17.767268Z","iopub.status.idle":"2022-07-14T06:55:17.792340Z","shell.execute_reply.started":"2022-07-14T06:55:17.767236Z","shell.execute_reply":"2022-07-14T06:55:17.791165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"KNN 모델의 정확도는 n_neighbors 속성을 변경하면 바뀔겁니다. 기본값은 5인데 이에 따라 어떻게 변화하나 봅시다.","metadata":{}},{"cell_type":"code","source":"a_index = list(range(1,11))\na=pd.Series()\nx=list(range(11))\nfor i in list(range(1,11)):\n    model=KNeighborsClassifier(n_neighbors=i)\n    model.fit(train_X, train_Y)\n    prediction=model.predict(test_X)\n    a=a.append(pd.Series(metrics.accuracy_score(prediction,test_Y)))\nplt.plot(a_index,a)\nplt.xticks(x)\nfig=plt.gcf()\nfig.set_size_inches(12,6)\nplt.show()\nprint(a.values, '\\nfor different n. maximum was ',a.values.max())","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:17.793791Z","iopub.execute_input":"2022-07-14T06:55:17.794405Z","iopub.status.idle":"2022-07-14T06:55:18.196790Z","shell.execute_reply.started":"2022-07-14T06:55:17.794367Z","shell.execute_reply":"2022-07-14T06:55:18.194781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Gaussian Naive Bayes\nmodel=GaussianNB()\nmodel.fit(train_X,train_Y)\nprediction6 = model.predict(test_X)\nprint('Accuracy of NaiveBayes is ',metrics.accuracy_score(prediction6, test_Y))","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:18.203118Z","iopub.execute_input":"2022-07-14T06:55:18.203987Z","iopub.status.idle":"2022-07-14T06:55:18.223207Z","shell.execute_reply.started":"2022-07-14T06:55:18.203936Z","shell.execute_reply":"2022-07-14T06:55:18.221407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Random Forests\n\nmodel = RandomForestClassifier(n_estimators = 100)\nmodel.fit(train_X,train_Y)\nprediction7 = model.predict(test_X)\nprint('Accuracy of Random Forest is ',metrics.accuracy_score(prediction7,test_Y))","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:18.225696Z","iopub.execute_input":"2022-07-14T06:55:18.227043Z","iopub.status.idle":"2022-07-14T06:55:18.469663Z","shell.execute_reply.started":"2022-07-14T06:55:18.226977Z","shell.execute_reply":"2022-07-14T06:55:18.468430Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"모델의 정확도는 분류 알고리즘의 견고함을 알려주는 유일한 요소가 아닙니다. 분류 모델이 90%의 정확도를 보여주었다고 한다면 아주 좋은 정확도 같지만 새로운 데이터셋에 대해 시험했을때 같은 정확도가 나오리라는 보장은 없습니다. 각각의 자료(instance, 여기서는 승객) 중 어떤 것을 학습에 쓸지 우리가 결정하지 않습니다. 학습 - 정확도 확인 데이터가 바뀌면 정확도도 바뀔 겁니다. 이 때의 증감을 model variance라고 합니다.  \n이것을 극복하기 위해 __Cross Validation__ 이 사용됩니다.\n\n# Cross Validation\n데이터가 불균형한 경우가 많습니다. 불균형하다는 것은 하나의 분류에 자료가 몰려있다거나 하다는 겁니다. 우리는 데이터셋의 instance 하나하나 그리고 전부에 대해 학습시키고 테스트해야 합니다. 그러면 평균을 취할 수 있겠습니다.\n\n__K-Fold Cross Validation__\n1. 데이터셋을 먼저 k-subsets으로 나눕니다.\n2. 5개로 나누었다고 하면 1part를 테스트에 쓰고 4parts를 학습에 씁니다.\n3. test part를 바꿔가며 반복해서 정확도의 평균을 얻습니다.\n이렇게 특정 데이터셋에 대해 underfit되거나 overfit될 가능성을 없앱니다.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import KFold, cross_val_score, cross_val_predict\nkfold = KFold(n_splits=10, random_state=22, shuffle=True) #shuffle set to True according to the error message\nxyz=[]\naccuracy=[]\nstd=[]\nclassifiers=['Linear Svm', 'Radial Svm', 'Logistic Regression', 'KNN', 'Decision Tree', 'Naive Bayes', 'Random Forest']\nmodels=[svm.SVC(kernel='linear'),svm.SVC(kernel='rbf'),LogisticRegression(),KNeighborsClassifier(n_neighbors=9),DecisionTreeClassifier(),GaussianNB(),RandomForestClassifier(n_estimators=100)]\nfor i in models:\n    model = i\n    cv_result = cross_val_score(model,X,Y, cv = kfold, scoring = 'accuracy')\n    cv_result=cv_result\n    xyz.append(cv_result.mean())\n    std.append(cv_result.std())\n    accuracy.append(cv_result)\nnew_models_dataframe2 = pd.DataFrame({'CV Mean':xyz, 'Std':std}, index = classifiers)\nnew_models_dataframe2","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:18.471657Z","iopub.execute_input":"2022-07-14T06:55:18.472018Z","iopub.status.idle":"2022-07-14T06:55:21.722567Z","shell.execute_reply.started":"2022-07-14T06:55:18.471985Z","shell.execute_reply":"2022-07-14T06:55:21.721091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplots(figsize=(12,6))\nbox=pd.DataFrame(accuracy, index=[classifiers])\nbox.T.boxplot()","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:21.724708Z","iopub.execute_input":"2022-07-14T06:55:21.725653Z","iopub.status.idle":"2022-07-14T06:55:21.999662Z","shell.execute_reply.started":"2022-07-14T06:55:21.725588Z","shell.execute_reply":"2022-07-14T06:55:21.998054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_models_dataframe2['CV Mean'].plot.barh(width=0.8)\nplt.title('Average CV Mean Accuracy')\nfig=plt.gcf()\nfig.set_size_inches(8,5)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:22.002197Z","iopub.execute_input":"2022-07-14T06:55:22.002712Z","iopub.status.idle":"2022-07-14T06:55:22.226988Z","shell.execute_reply.started":"2022-07-14T06:55:22.002664Z","shell.execute_reply":"2022-07-14T06:55:22.225401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"분류 정확도는 자료 불균형으로 오도될 수 있습니다. confusion matrix를 통해 결과를 요약해서 모델의 어디가 잘못됐는지 아니면 어떤 분류(class)가 잘못 예측하게 만들었는지 알 수 있습니다.","metadata":{}},{"cell_type":"markdown","source":"# Confusion Matrix\n\n분류 모델이 분류에 성공하고 실패한 숫자를 알 수 있습니다.","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(3,3,figsize=(12,10))\ny_pred = cross_val_predict(svm.SVC(kernel='rbf'),X,Y,cv=10)\nsns.heatmap(confusion_matrix(Y,y_pred),ax=ax[0][0], annot=True, fmt='2.0f')\nax[0,0].set_title('Matrix for rbf-SVM')\n\ny_pred = cross_val_predict(svm.SVC(kernel='linear'),X,Y,cv=10)\nsns.heatmap(confusion_matrix(Y,y_pred),ax=ax[0][1], annot=True, fmt='2.0f')\nax[0,1].set_title('Matrix for linear-SVM')\n\ny_pred = cross_val_predict(KNeighborsClassifier(n_neighbors=9),X,Y,cv=10)\nsns.heatmap(confusion_matrix(Y,y_pred),ax=ax[0][2], annot=True, fmt='2.0f')\nax[0,2].set_title('Matrix for KNN')\n\ny_pred = cross_val_predict(RandomForestClassifier(n_estimators=100),X,Y,cv=10)\nsns.heatmap(confusion_matrix(Y,y_pred),ax=ax[1][0], annot=True, fmt='2.0f')\nax[1,0].set_title('Random Forests')\n\ny_pred = cross_val_predict(LogisticRegression(),X,Y,cv=10)\nsns.heatmap(confusion_matrix(Y,y_pred),ax=ax[1][1], annot=True, fmt='2.0f')\nax[1,1].set_title('Logistic-Regression')\n\ny_pred = cross_val_predict(DecisionTreeClassifier(),X,Y,cv=10)\nsns.heatmap(confusion_matrix(Y,y_pred),ax=ax[1][2], annot=True, fmt='2.0f')\nax[1,2].set_title('DecisionTree')\n\ny_pred = cross_val_predict(GaussianNB(),X,Y,cv=10)\nsns.heatmap(confusion_matrix(Y,y_pred),ax=ax[2][0], annot=True, fmt='2.0f')\nax[2,0].set_title('Naive Bayes')\n\nplt.subplots_adjust(hspace=0.2, wspace=0.2)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:22.229106Z","iopub.execute_input":"2022-07-14T06:55:22.229665Z","iopub.status.idle":"2022-07-14T06:55:27.688598Z","shell.execute_reply.started":"2022-07-14T06:55:22.229615Z","shell.execute_reply":"2022-07-14T06:55:27.687436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Confusion Matrix 해석\n\n1. rbf-SVM의 경우를 예로 들어보면 CV 정확도는 $\\left({491+247}\\right)/891$ 입니다.\n2. Errors 58 사망자에 대해 생존했다고 잘못 판단하고, 95 생존자에 대해 사망했다고 판단했습니다. 후자의 경우가 더 많았습니다.\n이런 식으로 rbf-SVM는 사망자를 잘 가려내고 NaiveBayes는 생존자를 잘 가려낸다고 할 수 있습니다.\n","metadata":{}},{"cell_type":"markdown","source":"## Hyper-Parameters 조정\n\n기계학습은 블랙박스와 같아서 초기값을 조정하여 더 나은 학습 결과를 얻을 수 있습니다. SVM모델의 C, $\\gamma$ 등이 있죠. 이들이 hyper-parameter라고 불리고 이것을 조정하는 것을 Hyper-Parameter Tuning이라고 합니다. SVM과 RandomForests에 대해 이것을 해보겠습니다.\n\n","metadata":{}},{"cell_type":"code","source":"#SVM\nfrom sklearn.model_selection import GridSearchCV\nc=[0.05,0.1,0.2,0.3,0.25,0.4,0.5,0.6,0.7,0.8,0.9, 1.]\ngamma=[0.1, .2, .3, .4, .5, .6, .7, .8, .9, 1.]\nkernel = ['rbf','linear']\nhyper = {'kernel':kernel, 'C':c, 'gamma':gamma}\ngd=GridSearchCV(estimator=svm.SVC(),param_grid=hyper,verbose=True)\ngd.fit(X,Y)\nprint(gd.best_score_)\nprint(gd.best_estimator_)","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:27.692763Z","iopub.execute_input":"2022-07-14T06:55:27.693158Z","iopub.status.idle":"2022-07-14T06:55:59.370189Z","shell.execute_reply.started":"2022-07-14T06:55:27.693123Z","shell.execute_reply":"2022-07-14T06:55:59.368911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Random Forests\nn_estimators = range(100,1000,100)\nhyper = {'n_estimators':n_estimators}\ngd = GridSearchCV(estimator = RandomForestClassifier(random_state=0), param_grid=hyper, verbose=True)\ngd.fit(X,Y)\nprint(gd.best_score_)\nprint(gd.best_estimator_)","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:55:59.372293Z","iopub.execute_input":"2022-07-14T06:55:59.372681Z","iopub.status.idle":"2022-07-14T06:56:48.074007Z","shell.execute_reply.started":"2022-07-14T06:55:59.372646Z","shell.execute_reply":"2022-07-14T06:56:48.072904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"이렇게 두 모델에 대해서 예측 결과가 잘 나오는 hyper-parameter 값을 찾을 수 있었습니다.\n\n# Ensembling\n\n가능한 모든 parameter에 대한 결과를 바탕으로 특정 parameter에서의 결과를 알 수 있겠습니다.\n이것은 다음과 같은 단계를 거쳐 진행됩니다.\n1. Voting Classifier (분류자 투표)\n2. Bagging (구걸)\n3. Boosting\n\n## Voting Classifier\n\n간단한 기계학습 모델의 예측을 조합하는 가장 단순한 방법입니다. 하위모델의 모든 예측결과의 평균을 취합니다. ","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\nensemble_lin_rbf = VotingClassifier(estimators=[('KNN', KNeighborsClassifier(n_neighbors=10)),\n                                               ('RBF',svm.SVC(probability = True, kernel = 'rbf', C=0.5, gamma=0.1))],\n                                   voting='soft').fit(train_X, train_Y)\nprint(ensemble_lin_rbf.score(test_X,test_Y))\ncross = cross_val_score(ensemble_lin_rbf, X, Y, cv = 10, scoring = 'accuracy')\nprint(cross.mean())","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:56:48.075444Z","iopub.execute_input":"2022-07-14T06:56:48.075814Z","iopub.status.idle":"2022-07-14T06:56:49.424831Z","shell.execute_reply.started":"2022-07-14T06:56:48.075781Z","shell.execute_reply":"2022-07-14T06:56:49.423413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Bagging\n일반적인 ensemble method로 비슷한 분류알고리즘을 데이터셋의 작은 부분에 적용하고 평균을 취합니다. 평균을 취하기 때문에 편차가 감쇠합니다. Voting classifier와 달리 유사한 분류 알고리즘을 씁니다.\n\n### Bagged KNN\nBagging은 분산이 큰 모델에서 효과가 좋습니다. Decision Tree나 Random Forest 같은 것이요. n_neigbors 값이 작은 KNN을 사용할 수 있습니다.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import BaggingClassifier\nmodel=BaggingClassifier(base_estimator=KNeighborsClassifier(n_neighbors=3), random_state=0, n_estimators=700)\nmodel.fit(train_X, train_Y)\nprediction=model.predict(test_X)\nprint('accuracy of bagged KNN ',metrics.accuracy_score(prediction, test_Y))\nresult=cross_val_score(model,X,Y,cv=10, scoring='accuracy')\nprint('CV score is ', result.mean())","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:56:49.426516Z","iopub.execute_input":"2022-07-14T06:56:49.426845Z","iopub.status.idle":"2022-07-14T06:57:15.757741Z","shell.execute_reply.started":"2022-07-14T06:56:49.426812Z","shell.execute_reply":"2022-07-14T06:57:15.756926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Boosting\n예측을 잘 한 instance와 잘 못 한 인스턴스에 다른 가중치를 주는 방식으로 학습을 반복시킵니다.","metadata":{}},{"cell_type":"code","source":"##Adaptive Boosting\nfrom sklearn.ensemble import AdaBoostClassifier\nada=AdaBoostClassifier(n_estimators = 200, random_state=0, learning_rate=0.1)\nresult = cross_val_score(ada, X, Y, cv = 10, scoring= 'accuracy')\nprint(result.mean())","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:57:15.759758Z","iopub.execute_input":"2022-07-14T06:57:15.760223Z","iopub.status.idle":"2022-07-14T06:57:20.027903Z","shell.execute_reply.started":"2022-07-14T06:57:15.760188Z","shell.execute_reply":"2022-07-14T06:57:20.026996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#confusion matrix for the best model\nada = AdaBoostClassifier(n_estimators = 200, random_state=0, learning_rate=0.05)\nresult=cross_val_predict(ada,X,Y,cv=10)\nsns.heatmap(confusion_matrix(Y,result),cmap='winter',annot=True, fmt='2.0f')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:57:20.029453Z","iopub.execute_input":"2022-07-14T06:57:20.030810Z","iopub.status.idle":"2022-07-14T06:57:24.427076Z","shell.execute_reply.started":"2022-07-14T06:57:20.030746Z","shell.execute_reply":"2022-07-14T06:57:24.425759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Importance","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(1,1,figsize=(7,6))\nmodel=RandomForestClassifier(n_estimators=500, random_state=0)\nmodel.fit(X,Y)\npd.Series(model.feature_importances_, X.columns).sort_values(ascending=True).plot.barh(width=.8,ax=ax)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:57:24.428651Z","iopub.execute_input":"2022-07-14T06:57:24.429238Z","iopub.status.idle":"2022-07-14T06:57:25.685584Z","shell.execute_reply.started":"2022-07-14T06:57:24.429189Z","shell.execute_reply":"2022-07-14T06:57:25.684232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 분석\n\n- initial, Fare_cat, Pclass, Family_size는 공통적으로 중요한 속성이었다\n- Sex는 RandomForest에서만 중요한 속성이었다. Initial은 중요한 것을 봤을 때는 좀 재고할 필요가 있다.\n- Pclass 와 Fare_cat의 관계는 가족 크기??가 어쩄다는 것일까\n\n마지막으로 작자는 기계학습에 대한 식견을 얻었기를 바란다면서 소개하면서 끝낸다.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}