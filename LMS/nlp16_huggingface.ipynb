{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bc6f8a5",
   "metadata": {},
   "source": [
    "# About this notebook\n",
    "this notebook is written by changhyun yi, taking Modulab's Aiffel Program (Deep learning education course).  \n",
    "ì´ ë…¸íŠ¸ë¶ì€ ëª¨ë‘ì˜ì—°êµ¬ì†Œ AIFFEL ê³¼ì • ì¤‘ going-deeper node 16, hugging face custom model ë§Œë“¤ê¸°ì— ì œì¶œí•˜ê¸° ìœ„í•´ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "# mnli task\n",
    "MNLI taskì— ëŒ€í•œ descriptionì€ [MultiNLI](https://cims.nyu.edu/~sbowman/multinli/) ì—ì„œ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‘ ë¬¸ì¥ì´ __ì „ì œ(premise)__ ì™€ __ê°€ì„¤(hypothesis)__ ë¡œ ì œì‹œë˜ê³  ê·¸ ì‚¬ì´ì˜ ê´€ê³„ë¥¼ entailment - ì´ì–´ì§, contradict - ë°˜(å)í•¨, neutral - ê´€ê³„ì—†ìŒ ì„¸ labelë¡œ ë‚˜ëˆ•ë‹ˆë‹¤. \n",
    "\n",
    "nodeì—ì„œ ë‹¤ë£¬ ê²ƒì€ ì •ì œëœ BERT pretrainëª¨ë¸ì…ë‹ˆë‹¤. ì´ê²ƒì€ labelì—†ì´ ë§ë­‰ì¹˜ì—ì„œ ë§ˆìŠ¤í¬ë¥¼ ì”Œìš°ê³  ë¬¸ì¥ì´ ì´ì–´ì§€ëŠ”ì§€ë¥¼ ë¼ë²¨ë¡œ í•˜ì—¬ í•™ìŠµì‹œí‚¨ ê²ƒì´ë¯€ë¡œ, ë‘ ë¬¸ì¥ì˜ ê´€ê³„ë¥¼ ë”°ì§€ëŠ” ê²ƒì´ë¼ ì—°ê´€ì´ ì•„ì˜ˆ ì—†ì–´ë³´ì´ì§€ëŠ” ì•ŠëŠ”ë° ì•ˆëœë‹¤ë‹ˆ ì•„ì‰½ë„¤ìš”.  \n",
    "\n",
    "\n",
    "# MNLI dataset ë‘˜ëŸ¬ë³´ê¸°\n",
    "\n",
    "tensorflow-datasets íŒ¨í‚¤ì§€ì™€ í¬í•¨ëœ datasetsì— ë¦¬ìŠ¤íŠ¸ì— ëŒ€í•´ì„œëŠ” https://www.tensorflow.org/datasets/catalog/overview#all_datasets, \n",
    "ê·¸ ì¤‘ GLUEì— ê´€í•œ ë¶€ë¶„ì€ https://www.tensorflow.org/datasets/catalog/glue ì—ì„œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "```Shell\n",
    "pip install tensorflow-datasets -U\n",
    "```\n",
    "glueëŠ” ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì¡°ë¡œ ë¼ìˆìŠµë‹ˆë‹¤.\n",
    "```python\n",
    "FeaturesDict({\n",
    "    'hypothesis': Text(shape=(), dtype=tf.string),\n",
    "    'idx': tf.int32,\n",
    "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),\n",
    "    'premise': Text(shape=(), dtype=tf.string),\n",
    "})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6a45478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4eb8db73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.4.0\n"
     ]
    }
   ],
   "source": [
    "print(tfds.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d54498c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 298.29 MiB (download: 298.29 MiB, generated: 100.56 MiB, total: 398.85 MiB) to /aiffel/tensorflow_datasets/glue/mnli/2.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f355e73a884efc8d41a92ba1aeaf4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff62ceeadba4a91b4fd6c5d37b671f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba3087e7bca422cade2cfaaa4bcb363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/5 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...:   0%|          | 0/392702 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling glue-train.tfrecord...:   0%|          | 0/392702 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation_matched examples...:   0%|          | 0/9815 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling glue-validation_matched.tfrecord...:   0%|          | 0/9815 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation_mismatched examples...:   0%|          | 0/9832 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling glue-validation_mismatched.tfrecord...:   0%|          | 0/9832 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_matched examples...:   0%|          | 0/9796 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling glue-test_matched.tfrecord...:   0%|          | 0/9796 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_mismatched examples...:   0%|          | 0/9847 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling glue-test_mismatched.tfrecord...:   0%|          | 0/9847 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset glue downloaded and prepared to /aiffel/tensorflow_datasets/glue/mnli/2.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ds=tfds.load('glue/mnli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "016b33e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tfds.load('glue/mnli'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acf65a1",
   "metadata": {},
   "source": [
    "STEP 1. mnli ë°ì´í„°ì…‹ì„ ë¶„ì„í•´ ë³´ê¸°\n",
    "tensorflow-datasetsë¥¼ ì´ìš©í•˜ì—¬ glue/mnlië¥¼ ë‹¤ìš´ë¡œë“œí•˜ë ¤ë©´ tensorflow-datasets ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ì„ ì˜¬ë ¤ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "$ pip install tensorflow-datasets -U\n",
    "ìœ„ ëª…ë ¹ì–´ë¥¼ í†µí•´ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—…ê·¸ë ˆì´ë“œë¥¼ ì§„í–‰í•´ ì£¼ì„¸ìš”!\n",
    "\n",
    "STEP 2. MNLIProcessorí´ë˜ìŠ¤ êµ¬í˜„í•˜ê¸°\n",
    "STEP 3. ìœ„ì—ì„œ êµ¬í˜„í•œ processor ë° Huggingfaceì—ì„œ ì œê³µí•˜ëŠ” tokenizerë¥¼ í™œìš©í•˜ì—¬ ë°ì´í„°ì…‹ êµ¬ì„±í•˜ê¸°\n",
    "STEP 4. modelì„ ìƒì„±í•˜ì—¬ í•™ìŠµ ë° í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•´ ë³´ê¸°\n",
    "ğŸ’¡ íŒíŠ¸\n",
    "í˜¹ì‹œ STEP 2ì˜ ì§„í–‰ì— ì–´ë ¤ì›€ì„ ê²ªê³  ê³„ì‹ ë‹¤ë©´ transformer í”„ë¡œì íŠ¸ ë‚´ë¶€ë¥¼ ì‚´í´ë³´ì‹œë©´ ì°¸ê³ í• ë§Œí•œ ì˜ˆì‹œ ì½”ë“œë¥¼ ì°¾ì•„ë³¼ ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤. transformersì˜ ê³µì‹ githubì„ ì°¸ê³ í•˜ëŠ” ê²ƒë„ ì¢‹ì€ ë°©ë²•ì´ì—ìš”!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c32bf4e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([Split('train'), 'validation_matched', 'validation_mismatched', 'test_matched', 'test_mismatched'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25aa130b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: {hypothesis: (), idx: (), label: (), premise: ()}, types: {hypothesis: tf.string, idx: tf.int32, label: tf.int64, premise: tf.string}>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6bc216c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\ttf.Tensor(16399, shape=(), dtype=int32)\ttf.Tensor(b'Meaningful partnerships with stakeholders is crucial.', shape=(), dtype=string)\ttf.Tensor(1, shape=(), dtype=int64)\ttf.Tensor(b'In recognition of these tensions, LSC has worked diligently since 1995 to convey the expectations of the State Planning Initiative and to establish meaningful partnerships with stakeholders aimed at fostering a new symbiosis between the federal provider and recipients of legal services funding.', shape=(), dtype=string)\n",
      "\n",
      "\n",
      "1\ttf.Tensor(206287, shape=(), dtype=int32)\ttf.Tensor(b'The Clinton followers kept to the higher ground in the discussion. ', shape=(), dtype=string)\ttf.Tensor(0, shape=(), dtype=int64)\ttf.Tensor(b'The Clinton surrogates also held the high ground in the context war.', shape=(), dtype=string)\n",
      "\n",
      "\n",
      "2\ttf.Tensor(352707, shape=(), dtype=int32)\ttf.Tensor(b'Women have jobs in all areas of the workforce, they are almost getting the same wages as most men,', shape=(), dtype=string)\ttf.Tensor(1, shape=(), dtype=int64)\ttf.Tensor(b\"um-hum because women are in every field now i mean i can't think of a field that they're not involved in\", shape=(), dtype=string)\n",
      "\n",
      "\n",
      "3\ttf.Tensor(372070, shape=(), dtype=int32)\ttf.Tensor(b'Houston is freezing and dry right now.', shape=(), dtype=string)\ttf.Tensor(2, shape=(), dtype=int64)\ttf.Tensor(b'Houston is really humid now', shape=(), dtype=string)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for idx, doc in enumerate(ds['train']):\n",
    "    print(idx,doc['idx'], doc['hypothesis'], doc['label'], doc['premise'], sep='\\t')\n",
    "    print('\\n')\n",
    "    if idx==3:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f223fe2e",
   "metadata": {},
   "source": [
    "ë¬¸ì¥ì„ ëª‡ ê°œ ì‚´í´ë³´ë‹ˆ, labelì´ ë‹¤ìŒê³¼ ê°™ìŒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.   \n",
    "\n",
    "|Label|0|1|2|\n",
    "|---|---|---|---|\n",
    "|ê´€ê³„|ì´ì–´ì§|ë¬´ê´€|ë°˜ë¡€|\n",
    "\n",
    "ê·¸ëŸ°ë° 0, 1ì´ í™•ì‹¤í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì˜ ëª¨ë¥´ê² ë„¤ìš”. ì¼ë‹¨ ê³„ì† í•´ë´…ì‹œë‹¤. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb9f74d",
   "metadata": {},
   "source": [
    "[tensorflow.org, tfds.as_dataframe](https://www.tensorflow.org/datasets/api_docs/python/tfds/as_dataframe) ì„ í†µí•´ pandas ë°ì´í„°í”„ë ˆì„ì„ ë°›ì„ ìˆ˜ ìˆë‹¤ê³  í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9578934f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Split('train'), 'validation_matched', 'validation_mismatched', 'test_matched', 'test_mismatched']\n"
     ]
    }
   ],
   "source": [
    "keys=list(ds.keys())\n",
    "print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "81f04eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: {hypothesis: (), idx: (), label: (), premise: ()}, types: {hypothesis: tf.string, idx: tf.int32, label: tf.int64, premise: tf.string}>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[keys[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b0217013",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=tfds.as_dataframe(ds[keys[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9e95a45a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>idx</th>\n",
       "      <th>label</th>\n",
       "      <th>premise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'Meaningful partnerships with stakeholders is...</td>\n",
       "      <td>16399</td>\n",
       "      <td>1</td>\n",
       "      <td>b'In recognition of these tensions, LSC has wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'The Clinton followers kept to the higher gro...</td>\n",
       "      <td>206287</td>\n",
       "      <td>0</td>\n",
       "      <td>b'The Clinton surrogates also held the high gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'Women have jobs in all areas of the workforc...</td>\n",
       "      <td>352707</td>\n",
       "      <td>1</td>\n",
       "      <td>b\"um-hum because women are in every field now ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'Houston is freezing and dry right now.'</td>\n",
       "      <td>372070</td>\n",
       "      <td>2</td>\n",
       "      <td>b'Houston is really humid now'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b\"But they wouldn't be leaving right now. \"</td>\n",
       "      <td>160184</td>\n",
       "      <td>1</td>\n",
       "      <td>b'But not now.'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          hypothesis     idx  label  \\\n",
       "0  b'Meaningful partnerships with stakeholders is...   16399      1   \n",
       "1  b'The Clinton followers kept to the higher gro...  206287      0   \n",
       "2  b'Women have jobs in all areas of the workforc...  352707      1   \n",
       "3          b'Houston is freezing and dry right now.'  372070      2   \n",
       "4        b\"But they wouldn't be leaving right now. \"  160184      1   \n",
       "\n",
       "                                             premise  \n",
       "0  b'In recognition of these tensions, LSC has wo...  \n",
       "1  b'The Clinton surrogates also held the high gr...  \n",
       "2  b\"um-hum because women are in every field now ...  \n",
       "3                     b'Houston is really humid now'  \n",
       "4                                    b'But not now.'  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cc28f727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392702"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e31531d",
   "metadata": {},
   "source": [
    "ìš©ëŸ‰ì´ 300MB ì •ë„ë¼ì„œ ì‹œê°„ì´ ê½¤ ê±¸ë¦¬ë¯€ë¡œ ì¼ë¶€ë§Œ ì¨ì„œ í…ŒìŠ¤íŠ¸í•˜ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ae451ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7c7ec6f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>idx</th>\n",
       "      <th>label</th>\n",
       "      <th>premise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'Meaningful partnerships with stakeholders is...</td>\n",
       "      <td>16399</td>\n",
       "      <td>1</td>\n",
       "      <td>b'In recognition of these tensions, LSC has wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'The Clinton followers kept to the higher gro...</td>\n",
       "      <td>206287</td>\n",
       "      <td>0</td>\n",
       "      <td>b'The Clinton surrogates also held the high gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'Women have jobs in all areas of the workforc...</td>\n",
       "      <td>352707</td>\n",
       "      <td>1</td>\n",
       "      <td>b\"um-hum because women are in every field now ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'Houston is freezing and dry right now.'</td>\n",
       "      <td>372070</td>\n",
       "      <td>2</td>\n",
       "      <td>b'Houston is really humid now'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b\"But they wouldn't be leaving right now. \"</td>\n",
       "      <td>160184</td>\n",
       "      <td>1</td>\n",
       "      <td>b'But not now.'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>b'John made me light the gas.'</td>\n",
       "      <td>88879</td>\n",
       "      <td>2</td>\n",
       "      <td>b'John strode across the room, and lit the gas. '</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>b\"Music doesn't identify good or bad things. \"</td>\n",
       "      <td>257511</td>\n",
       "      <td>2</td>\n",
       "      <td>b\"yeah i'm kind of thinking that's maybe our g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>b'Lawrence Cavendish woke me up during the nig...</td>\n",
       "      <td>262058</td>\n",
       "      <td>0</td>\n",
       "      <td>b'It seemed to be the middle of the night when...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>b'This was from another student at state.'</td>\n",
       "      <td>201141</td>\n",
       "      <td>0</td>\n",
       "      <td>b'well the interesting thing was this was from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>b'Less than half of the colonists did not melt...</td>\n",
       "      <td>305981</td>\n",
       "      <td>1</td>\n",
       "      <td>b'Unlike the other colonists, who eventually m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            hypothesis     idx  label  \\\n",
       "0    b'Meaningful partnerships with stakeholders is...   16399      1   \n",
       "1    b'The Clinton followers kept to the higher gro...  206287      0   \n",
       "2    b'Women have jobs in all areas of the workforc...  352707      1   \n",
       "3            b'Houston is freezing and dry right now.'  372070      2   \n",
       "4          b\"But they wouldn't be leaving right now. \"  160184      1   \n",
       "..                                                 ...     ...    ...   \n",
       "995                     b'John made me light the gas.'   88879      2   \n",
       "996     b\"Music doesn't identify good or bad things. \"  257511      2   \n",
       "997  b'Lawrence Cavendish woke me up during the nig...  262058      0   \n",
       "998         b'This was from another student at state.'  201141      0   \n",
       "999  b'Less than half of the colonists did not melt...  305981      1   \n",
       "\n",
       "                                               premise  \n",
       "0    b'In recognition of these tensions, LSC has wo...  \n",
       "1    b'The Clinton surrogates also held the high gr...  \n",
       "2    b\"um-hum because women are in every field now ...  \n",
       "3                       b'Houston is really humid now'  \n",
       "4                                      b'But not now.'  \n",
       "..                                                 ...  \n",
       "995  b'John strode across the room, and lit the gas. '  \n",
       "996  b\"yeah i'm kind of thinking that's maybe our g...  \n",
       "997  b'It seemed to be the middle of the night when...  \n",
       "998  b'well the interesting thing was this was from...  \n",
       "999  b'Unlike the other colonists, who eventually m...  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7ebfb293",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, info = tfds.load('glue/mnli', with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3cde4698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <PrefetchDataset shapes: {hypothesis: (), idx: (), label: (), premise: ()}, types: {hypothesis: tf.string, idx: tf.int32, label: tf.int64, premise: tf.string}>,\n",
       " 'validation_matched': <PrefetchDataset shapes: {hypothesis: (), idx: (), label: (), premise: ()}, types: {hypothesis: tf.string, idx: tf.int32, label: tf.int64, premise: tf.string}>,\n",
       " 'validation_mismatched': <PrefetchDataset shapes: {hypothesis: (), idx: (), label: (), premise: ()}, types: {hypothesis: tf.string, idx: tf.int32, label: tf.int64, premise: tf.string}>,\n",
       " 'test_matched': <PrefetchDataset shapes: {hypothesis: (), idx: (), label: (), premise: ()}, types: {hypothesis: tf.string, idx: tf.int32, label: tf.int64, premise: tf.string}>,\n",
       " 'test_mismatched': <PrefetchDataset shapes: {hypothesis: (), idx: (), label: (), premise: ()}, types: {hypothesis: tf.string, idx: tf.int32, label: tf.int64, premise: tf.string}>}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "700e9912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='glue',\n",
       "    full_name='glue/mnli/2.0.0',\n",
       "    description=\"\"\"\n",
       "    GLUE, the General Language Understanding Evaluation benchmark\n",
       "    (https://gluebenchmark.com/) is a collection of resources for training,\n",
       "    evaluating, and analyzing natural language understanding systems.\n",
       "    \"\"\",\n",
       "    config_description=\"\"\"\n",
       "    The Multi-Genre Natural Language Inference Corpus is a crowdsourced\n",
       "    collection of sentence pairs with textual entailment annotations. Given a premise sentence\n",
       "    and a hypothesis sentence, the task is to predict whether the premise entails the hypothesis\n",
       "    (entailment), contradicts the hypothesis (contradiction), or neither (neutral). The premise sentences are\n",
       "    gathered from ten different sources, including transcribed speech, fiction, and government reports.\n",
       "    We use the standard test set, for which we obtained private labels from the authors, and evaluate\n",
       "    on both the matched (in-domain) and mismatched (cross-domain) section. We also use and recommend\n",
       "    the SNLI corpus as 550k examples of auxiliary training data.\n",
       "    \"\"\",\n",
       "    homepage='http://www.nyu.edu/projects/bowman/multinli/',\n",
       "    data_path='/aiffel/tensorflow_datasets/glue/mnli/2.0.0',\n",
       "    download_size=298.29 MiB,\n",
       "    dataset_size=100.56 MiB,\n",
       "    features=FeaturesDict({\n",
       "        'hypothesis': Text(shape=(), dtype=tf.string),\n",
       "        'idx': tf.int32,\n",
       "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),\n",
       "        'premise': Text(shape=(), dtype=tf.string),\n",
       "    }),\n",
       "    supervised_keys=None,\n",
       "    disable_shuffling=False,\n",
       "    splits={\n",
       "        'test_matched': <SplitInfo num_examples=9796, num_shards=1>,\n",
       "        'test_mismatched': <SplitInfo num_examples=9847, num_shards=1>,\n",
       "        'train': <SplitInfo num_examples=392702, num_shards=1>,\n",
       "        'validation_matched': <SplitInfo num_examples=9815, num_shards=1>,\n",
       "        'validation_mismatched': <SplitInfo num_examples=9832, num_shards=1>,\n",
       "    },\n",
       "    citation=\"\"\"@InProceedings{N18-1101,\n",
       "      author = \"Williams, Adina\n",
       "                and Nangia, Nikita\n",
       "                and Bowman, Samuel\",\n",
       "      title = \"A Broad-Coverage Challenge Corpus for\n",
       "               Sentence Understanding through Inference\",\n",
       "      booktitle = \"Proceedings of the 2018 Conference of\n",
       "                   the North American Chapter of the\n",
       "                   Association for Computational Linguistics:\n",
       "                   Human Language Technologies, Volume 1 (Long\n",
       "                   Papers)\",\n",
       "      year = \"2018\",\n",
       "      publisher = \"Association for Computational Linguistics\",\n",
       "      pages = \"1112--1122\",\n",
       "      location = \"New Orleans, Louisiana\",\n",
       "      url = \"http://aclweb.org/anthology/N18-1101\"\n",
       "    }\n",
       "    @article{bowman2015large,\n",
       "      title={A large annotated corpus for learning natural language inference},\n",
       "      author={Bowman, Samuel R and Angeli, Gabor and Potts, Christopher and Manning, Christopher D},\n",
       "      journal={arXiv preprint arXiv:1508.05326},\n",
       "      year={2015}\n",
       "    }\n",
       "    @inproceedings{wang2019glue,\n",
       "      title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\n",
       "      author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},\n",
       "      note={In the Proceedings of ICLR.},\n",
       "      year={2019}\n",
       "    }\n",
       "    \n",
       "    Note that each GLUE dataset has its own citation. Please see the source to see\n",
       "    the correct citation for each contained dataset.\"\"\",\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fb6518ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset glue (/aiffel/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e596e9469e864849ac6f5d0b1011bcc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
      "        num_rows: 392702\n",
      "    })\n",
      "    validation_matched: Dataset({\n",
      "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
      "        num_rows: 9815\n",
      "    })\n",
      "    validation_mismatched: Dataset({\n",
      "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
      "        num_rows: 9832\n",
      "    })\n",
      "    test_matched: Dataset({\n",
      "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
      "        num_rows: 9796\n",
      "    })\n",
      "    test_mismatched: Dataset({\n",
      "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
      "        num_rows: 9847\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "huggingface_mnli_dataset = load_dataset('glue', 'mnli')\n",
    "print(huggingface_mnli_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2e66a733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datasets.dataset_dict.DatasetDict,\n",
       " DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "         num_rows: 392702\n",
       "     })\n",
       "     validation_matched: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "         num_rows: 9815\n",
       "     })\n",
       "     validation_mismatched: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "         num_rows: 9832\n",
       "     })\n",
       "     test_matched: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "         num_rows: 9796\n",
       "     })\n",
       "     test_mismatched: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "         num_rows: 9847\n",
       "     })\n",
       " }))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(huggingface_mnli_dataset), huggingface_mnli_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "16c1e311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premise': ['Conceptually cream skimming has two basic dimensions - product and geography.',\n",
       "  'you know during the season and i guess at at your level uh you lose them to the next level if if they decide to recall the the parent team the Braves decide to call to recall a guy from triple A then a double A guy goes up to replace him and a single A guy goes up to replace him',\n",
       "  'One of our number will carry out your instructions minutely.',\n",
       "  'How do you know? All this is their information again.',\n",
       "  \"yeah i tell you what though if you go price some of those tennis shoes i can see why now you know they're getting up in the hundred dollar range\"],\n",
       " 'hypothesis': ['Product and geography are what make cream skimming work. ',\n",
       "  'You lose the things to the following level if the people recall.',\n",
       "  'A member of my team will execute your orders with immense precision.',\n",
       "  'This information belongs to them.',\n",
       "  'The tennis shoes have a range of prices.'],\n",
       " 'label': [1, 0, 0, 0, 1],\n",
       " 'idx': [0, 1, 2, 3, 4]}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huggingface_mnli_dataset['train'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "51b593df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(huggingface_mnli_dataset['train'][:5]['premise'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4735b663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package datasets:\n",
      "\n",
      "NAME\n",
      "    datasets\n",
      "\n",
      "DESCRIPTION\n",
      "    # flake8: noqa\n",
      "    # coding=utf-8\n",
      "    # Copyright 2020 The HuggingFace Datasets Authors and the TensorFlow Datasets Authors.\n",
      "    #\n",
      "    # Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "    # you may not use this file except in compliance with the License.\n",
      "    # You may obtain a copy of the License at\n",
      "    #\n",
      "    #     http://www.apache.org/licenses/LICENSE-2.0\n",
      "    #\n",
      "    # Unless required by applicable law or agreed to in writing, software\n",
      "    # distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "    # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "    # See the License for the specific language governing permissions and\n",
      "    # limitations under the License.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    arrow_dataset\n",
      "    arrow_reader\n",
      "    arrow_writer\n",
      "    builder\n",
      "    combine\n",
      "    commands (package)\n",
      "    config\n",
      "    data_files\n",
      "    dataset_dict\n",
      "    features (package)\n",
      "    filesystems (package)\n",
      "    fingerprint\n",
      "    formatting (package)\n",
      "    hf_api\n",
      "    info\n",
      "    inspect\n",
      "    io (package)\n",
      "    iterable_dataset\n",
      "    keyhash\n",
      "    load\n",
      "    metric\n",
      "    naming\n",
      "    packaged_modules (package)\n",
      "    search\n",
      "    splits\n",
      "    streaming\n",
      "    table\n",
      "    tasks (package)\n",
      "    utils (package)\n",
      "\n",
      "SUBMODULES\n",
      "    deprecation_utils\n",
      "    doc_utils\n",
      "    download_manager\n",
      "    extract\n",
      "    file_utils\n",
      "    filelock\n",
      "    info_utils\n",
      "    logging\n",
      "    mock_download_manager\n",
      "    patching\n",
      "    py_utils\n",
      "    streaming_download_manager\n",
      "    tqdm_utils\n",
      "    typing\n",
      "    version\n",
      "\n",
      "FUNCTIONS\n",
      "    total_allocated_bytes(...)\n",
      "        total_allocated_bytes()\n",
      "        \n",
      "        Return the currently allocated bytes from the default memory pool.\n",
      "        Other memory pools may not be accounted for.\n",
      "\n",
      "DATA\n",
      "    SCRIPTS_VERSION = '1.14.0'\n",
      "    tqdm = <datasets.utils.tqdm_utils._tqdm_cls object>\n",
      "\n",
      "VERSION\n",
      "    1.14.0\n",
      "\n",
      "FILE\n",
      "    /opt/conda/lib/python3.9/site-packages/datasets/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0479f592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class DataProcessor in module transformers.data.processors.utils:\n",
      "\n",
      "class DataProcessor(builtins.object)\n",
      " |  Base class for data converters for sequence classification data sets.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  get_dev_examples(self, data_dir)\n",
      " |      Gets a collection of :class:`InputExample` for the dev set.\n",
      " |  \n",
      " |  get_example_from_tensor_dict(self, tensor_dict)\n",
      " |      Gets an example from a dict with tensorflow tensors.\n",
      " |      \n",
      " |      Args:\n",
      " |          tensor_dict: Keys and values should match the corresponding Glue\n",
      " |              tensorflow_dataset examples.\n",
      " |  \n",
      " |  get_labels(self)\n",
      " |      Gets the list of labels for this data set.\n",
      " |  \n",
      " |  get_test_examples(self, data_dir)\n",
      " |      Gets a collection of :class:`InputExample` for the test set.\n",
      " |  \n",
      " |  get_train_examples(self, data_dir)\n",
      " |      Gets a collection of :class:`InputExample` for the train set.\n",
      " |  \n",
      " |  tfds_map(self, example)\n",
      " |      Some tensorflow_datasets datasets are not formatted the same way the GLUE datasets are. This method converts\n",
      " |      examples to the correct format.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers.data.processors.utils import DataProcessor, InputExample, InputFeatures\n",
    "\n",
    "help(DataProcessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2f1602",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
