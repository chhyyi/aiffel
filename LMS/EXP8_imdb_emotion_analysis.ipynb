{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chhyyi/aiffel/blob/main/LMS/EXP8_imdb_emotion_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzXz7ZAJBlj_"
      },
      "source": [
        "이 노트북은 modulab의 lms exploration node, imdb감정분석 노트북입니다.\n",
        "\n",
        "\n",
        "# 2. 네이버 영화 리뷰 감성분석 (8-11 프로젝트)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.(1). 데이터 준비와 확인"
      ],
      "metadata": {
        "id": "Vbs43oTeXFr9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "google colab에서 쓰기 위해 mecab 설치 : 아무튼 이걸 하니까 됩니다.\n",
        "참고로 mecab은 원래 일본 전통과자라는 것 같습니다. konlpy 공식 홈페이지로 보이는 곳에서 다운받았습니다만 업데이트가 몇 년 전에 종료됐습니다. 앞으로도 괜찮을까요? 아무튼 일단은 작동합니다.\n",
        "```python\n",
        "!apt-get update && apt-get install -y g++ default-jdk\n",
        "!pip install konlpy\n",
        "!sudo apt-get install curl git\n",
        "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
        "```"
      ],
      "metadata": {
        "id": "5uUcNx_wFS84"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXv9kpti-K8R"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HrxfLf9g1LB",
        "outputId": "67519386-1c2a-4b71-c82d-33ca607ef1e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "1.3.5\n",
            "0.6.0\n",
            "3.6.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "!pip install konlpy\n",
        "import konlpy\n",
        "import gensim\n",
        "import numpy as np\n",
        "\n",
        "print(pd.__version__)\n",
        "print(konlpy.__version__)\n",
        "print(gensim.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "버전이 조금씩 다르지만 크게 다르지는 않습니다. 평소에도 그랬듯 잘 작동하길 기대하면서 일단 진행합니다. "
      ],
      "metadata": {
        "id": "tOZmqR37XQZ9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1U3DXEzZCTHZ",
        "outputId": "e6e8a331-ce1b-4d87-e91f-6ecfd2c9cdc1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id                                           document  label\n",
              "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
              "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
              "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
              "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
              "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a0e8de65-0976-4144-9313-2381ddabab27\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9976970</td>\n",
              "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3819312</td>\n",
              "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10265843</td>\n",
              "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9045019</td>\n",
              "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6483659</td>\n",
              "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0e8de65-0976-4144-9313-2381ddabab27')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a0e8de65-0976-4144-9313-2381ddabab27 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a0e8de65-0976-4144-9313-2381ddabab27');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "#import pandas as pd\n",
        "\n",
        "train_data = pd.read_table('/content/drive/MyDrive/colabdata/modulabs/lms_exp8/ratings_train.txt')\n",
        "test_data = pd.read_table('/content/drive/MyDrive/colabdata/modulabs/lms_exp8/ratings_test.txt')\n",
        "\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "google drive에 옮겨둔 파일을 로드합니다. 잘 읽어왔습니다.\n",
        "\n",
        "## 2.(2) 데이터로더 구성\n",
        "데이터로더가 너무 길어졌습니다. 뒤늦게 counter의 존재를 알아버렸네요."
      ],
      "metadata": {
        "id": "dDuwTLbhXfmH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uC8zHvWC9ex",
        "outputId": "7846cf51-3308-4608-b1f8-de47983c30b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0, 1, 2, 3, 3, 4, 5, 6, 7, 8], [9, 3, 10, 11, 12, 13, 14, 15, 3, 16, 17, 18, 19, 20, 21, 22, 23], [24, 25, 26], [27, 28, 29, 3, 3, 30, 31, 32, 33, 3, 3, 34, 35], [36, 37, 38, 18, 39, 40, 14, 41, 42, 43, 44, 45, 46, 47, 48, 49, 40, 50, 51, 52, 53, 54, 33]]\n"
          ]
        }
      ],
      "source": [
        "from konlpy.tag import Mecab\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "num_words=10000\n",
        "tokenizer = Mecab()\n",
        "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
        "\n",
        "\n",
        "def load_data(train_data, test_data, num_words=num_words):\n",
        "    train_data.drop_duplicates(inplace=True)\n",
        "    test_data.drop_duplicates(inplace=True)\n",
        "    train_data.dropna(inplace=True)\n",
        "    test_data.dropna(inplace=True)\n",
        "\n",
        "    train_idx=[]\n",
        "    test_idx=[]\n",
        "    \n",
        "    dict_last_index=0\n",
        "\n",
        "    appearance={\"<PAD>\":100,\"<BOS>\":100, \"<UNK>\":100}\n",
        "    #appearance: 전체 데이터에서 등장 횟수.\n",
        "    #인덱스는 그냥 word로 하겠습니다.\n",
        "    \n",
        "    #word to_index, index_to_word 초기화.\n",
        "    word_to_index={\"<PAD>\":0, \"<BOS>\":1, \"<UNK>\":2}\n",
        "    index_to_word={0:\"<PAD>\", 1:\"<BOS>\", 2:\"<UNK>\"}\n",
        "\n",
        "    for sentence in train_data['document']:\n",
        "        tokens=tokenizer.morphs(sentence)\n",
        "        token_to_index=[]\n",
        "        \n",
        "        for tk in tokens:\n",
        "            if tk not in stopwords:\n",
        "                if tk in word_to_index.keys():\n",
        "                    token_to_index.append(word_to_index[tk])\n",
        "                    appearance[tk]+=1\n",
        "\n",
        "                else:\n",
        "                    index_to_word[dict_last_index]=tk\n",
        "                    word_to_index[tk]=dict_last_index\n",
        "                    dict_last_index+=1\n",
        "                    token_to_index.append(word_to_index[tk])\n",
        "                    appearance[tk]=1\n",
        "\n",
        "        train_idx.append(token_to_index)\n",
        "\n",
        "    for sentence in test_data['document']:\n",
        "        tokens=tokenizer.morphs(sentence)\n",
        "        token_to_index=[]\n",
        "        for tk in tokens:\n",
        "            if tk not in stopwords:\n",
        "                if tk in word_to_index.keys():\n",
        "                    token_to_index.append(word_to_index[tk])\n",
        "                    appearance[tk]+=1\n",
        "                else:\n",
        "                    index_to_word[dict_last_index]=tk\n",
        "                    word_to_index[tk]=dict_last_index\n",
        "                    dict_last_index+=1\n",
        "                    token_to_index.append(word_to_index[tk])\n",
        "                    appearance[tk]=1\n",
        "\n",
        "        test_idx.append(token_to_index)\n",
        "    \n",
        "    if len(index_to_word)>num_words:\n",
        "        min=np.min(appearance.values())\n",
        "        for word, index in word_to_index.items():\n",
        "            if appearance[word]==min:\n",
        "                del word_to_index[word] \n",
        "                del index_to_word[index]\n",
        "            if len(index_to_word)<num_words:\n",
        "                break\n",
        "    \n",
        "    \n",
        "    for i, sentence in enumerate(test_idx):\n",
        "        for j, token in enumerate(sentence):\n",
        "            if token not in index_to_word.keys():\n",
        "                test_idx[i,j]=word_to_index[\"<UNK>\"]\n",
        "    for i, sentence in enumerate(train_idx):\n",
        "        for j, token in enumerate(sentence):\n",
        "            if token not in index_to_word.keys():\n",
        "                train_idx[i,j]=word_to_index[\"<UNK>\"]\n",
        "\n",
        "        \n",
        "    return train_idx, train_data['label'], test_idx, test_data['label'], word_to_index, index_to_word\n",
        "\n",
        "#index_to_word도 load_data에서 만들었기 때문에 그냥 같이 반환합니다.\n",
        "X_train, y_train, X_test, y_test, word_to_index, index_to_word = load_data(train_data, test_data)\n",
        "print(X_train[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "hur9R1zuDABd"
      },
      "outputs": [],
      "source": [
        "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
        "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
        "def get_encoded_sentence(sentence, word_to_index):\n",
        "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
        "\n",
        "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
        "def get_encoded_sentences(sentences, word_to_index):\n",
        "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
        "\n",
        "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
        "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
        "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
        "\n",
        "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
        "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
        "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_decoded_sentence(X_train[4], index_to_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "872H3Uj8OawA",
        "outputId": "ce6851e5-c520-4f4d-de60-d17cfe86fbfa"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'익살 스런 연기 돋보였 던 영화 ! 스파이더맨 에서 늙 어 보이 기 만 했 던 커스틴 던스트 너무나 이뻐 보였 다'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터로더가 잘 작동하는 것 같습니다. \n",
        "\n",
        "## 2.(3). 모델 구성을 위한 데이터 분석 및 가공\n",
        "평균$+2\\sigma$으로 자르겠습니다."
      ],
      "metadata": {
        "id": "fxBln-HGWfCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "length=[len(sentence) for sentence in X_train]\n",
        "print(np.max(length), np.mean(length), np.std(length))\n",
        "maxlen=int(np.mean(length)*np.std(length))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DivaWW1OjJag",
        "outputId": "0ec2e4fe-ab5e-4ece-83c0-a09d4d154e9a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116 15.644794826494216 12.841204643969176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "x_train = tf.keras.preprocessing.sequence.pad_sequences(X_train,\n",
        "                                                        value=word_to_index[\"<PAD>\"],\n",
        "                                                        padding='pre',\n",
        "                                                        maxlen=maxlen)\n",
        "\n",
        "x_test = tf.keras.preprocessing.sequence.pad_sequences(X_test,\n",
        "                                                       value=word_to_index[\"<PAD>\"],\n",
        "                                                       padding='pre',\n",
        "                                                       maxlen=maxlen)\n",
        "\n",
        "print(x_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7_rGkIxlwwS",
        "outputId": "6bc08945-3498-478b-db35-f25a73b2820b"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(149995, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_test.shape, x_train.shape)\n",
        "print(x_train[356],get_decoded_sentence(x_train[356], index_to_word))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWxDD6_8meJM",
        "outputId": "8535e810-f796-41e5-cfdf-89e5b1e5e713"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(49997, 200) (149995, 200)\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0 1845 1567 1846 1847\n",
            " 1848   48 1849   14 1010  195  115  298 1850 1851 1852 1853 1854 1855\n",
            " 1856  106  223  119] 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 학위 위 조성 범죄자 문제자 만 모아서 영화 찍 음 왜 그랬 으까 제작비 아끼 려구 패자 부 활전 하 냐 ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.(4). 모델 구성 및 validation set 구성\n",
        "일단 이전에 썼던 것을 그대로 해보겠습니다. test용으로 10000개만 남기고 test였던 것을 validation으로 써먹겠습니다.\n",
        "\n",
        "__모델 바꿔보기__\n",
        "- 지금은 LSTM 레이어 하나만 했습니다. 왜냐하면 그 전에 그냥 썼던 거라서요. 이걸 늘려 볼 수도 있겠죠.\n",
        "- Convolution Layer를 넣어 볼 수도 있겠죠.\n",
        "- Fully Connected Layer\n"
      ],
      "metadata": {
        "id": "tRdh5nglmB_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_valid=x_test[10000:]\n",
        "y_valid=y_test[10000:]\n",
        "x_test=x_test[:10000]\n",
        "y_test=y_test[:10000]"
      ],
      "metadata": {
        "id": "9NOX6OHg0jUK"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(word_to_index)+1\n",
        "word_vector_dim = 32  # 단어 하나를 표현하는 임베딩 벡터의 차원수입니다. \n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
        "model.add(tf.keras.layers.LSTM(32))\n",
        "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26H7E9FQmBQU",
        "outputId": "901f62d8-cbe9-4444-d21e-023eb5f82864"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, None, 32)          1969152   \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 32)                8320      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 32)                1056      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,978,561\n",
            "Trainable params: 1,978,561\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train.shape, x_train.shape)\n",
        "print(len(word_to_index), len(index_to_word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YghaSaPH3KDx",
        "outputId": "ab79953e-2bb3-421d-dac1-0d4ffbc44d52"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(149995,) (149995, 200)\n",
            "61535 61532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.(5). 모델 훈련\n"
      ],
      "metadata": {
        "id": "_-jFI9rsmGUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "epochs=20 \n",
        "\n",
        "history = model.fit(x_train,\n",
        "                    y_train,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_valid, y_valid), verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAh6ZaBLqCe4",
        "outputId": "fcd9cb6c-0aa3-4d3c-fc90-e7d79efe7929"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "293/293 [==============================] - 120s 399ms/step - loss: 0.4244 - accuracy: 0.8091 - val_loss: 0.3514 - val_accuracy: 0.8516\n",
            "Epoch 2/20\n",
            "293/293 [==============================] - 122s 417ms/step - loss: 0.3012 - accuracy: 0.8763 - val_loss: 0.3460 - val_accuracy: 0.8523\n",
            "Epoch 3/20\n",
            "293/293 [==============================] - 120s 410ms/step - loss: 0.2602 - accuracy: 0.8959 - val_loss: 0.3517 - val_accuracy: 0.8509\n",
            "Epoch 4/20\n",
            "293/293 [==============================] - 119s 405ms/step - loss: 0.2282 - accuracy: 0.9113 - val_loss: 0.3657 - val_accuracy: 0.8493\n",
            "Epoch 5/20\n",
            "293/293 [==============================] - 120s 408ms/step - loss: 0.2019 - accuracy: 0.9225 - val_loss: 0.3857 - val_accuracy: 0.8502\n",
            "Epoch 6/20\n",
            "293/293 [==============================] - 119s 407ms/step - loss: 0.1758 - accuracy: 0.9322 - val_loss: 0.4088 - val_accuracy: 0.8483\n",
            "Epoch 7/20\n",
            "293/293 [==============================] - 121s 412ms/step - loss: 0.1541 - accuracy: 0.9402 - val_loss: 0.4646 - val_accuracy: 0.8456\n",
            "Epoch 8/20\n",
            "293/293 [==============================] - 120s 411ms/step - loss: 0.1370 - accuracy: 0.9478 - val_loss: 0.4625 - val_accuracy: 0.8461\n",
            "Epoch 9/20\n",
            "293/293 [==============================] - 120s 410ms/step - loss: 0.1228 - accuracy: 0.9534 - val_loss: 0.5253 - val_accuracy: 0.8428\n",
            "Epoch 10/20\n",
            "293/293 [==============================] - 122s 416ms/step - loss: 0.1111 - accuracy: 0.9582 - val_loss: 0.5782 - val_accuracy: 0.8426\n",
            "Epoch 11/20\n",
            "293/293 [==============================] - 121s 413ms/step - loss: 0.1005 - accuracy: 0.9629 - val_loss: 0.6138 - val_accuracy: 0.8421\n",
            "Epoch 12/20\n",
            "293/293 [==============================] - 120s 410ms/step - loss: 0.0939 - accuracy: 0.9652 - val_loss: 0.6010 - val_accuracy: 0.8346\n",
            "Epoch 13/20\n",
            "293/293 [==============================] - 121s 412ms/step - loss: 0.0875 - accuracy: 0.9675 - val_loss: 0.6470 - val_accuracy: 0.8366\n",
            "Epoch 14/20\n",
            "293/293 [==============================] - 121s 413ms/step - loss: 0.0799 - accuracy: 0.9708 - val_loss: 0.6997 - val_accuracy: 0.8378\n",
            "Epoch 15/20\n",
            "293/293 [==============================] - 123s 421ms/step - loss: 0.0732 - accuracy: 0.9736 - val_loss: 0.7711 - val_accuracy: 0.8345\n",
            "Epoch 16/20\n",
            "293/293 [==============================] - 121s 412ms/step - loss: 0.0699 - accuracy: 0.9746 - val_loss: 0.7808 - val_accuracy: 0.8329\n",
            "Epoch 17/20\n",
            "293/293 [==============================] - 120s 410ms/step - loss: 0.0655 - accuracy: 0.9763 - val_loss: 0.7665 - val_accuracy: 0.8290\n",
            "Epoch 18/20\n",
            "293/293 [==============================] - 123s 419ms/step - loss: 0.0639 - accuracy: 0.9770 - val_loss: 0.8046 - val_accuracy: 0.8360\n",
            "Epoch 19/20\n",
            "293/293 [==============================] - 122s 418ms/step - loss: 0.0599 - accuracy: 0.9787 - val_loss: 0.8678 - val_accuracy: 0.8358\n",
            "Epoch 20/20\n",
            "293/293 [==============================] - 118s 403ms/step - loss: 0.0557 - accuracy: 0.9801 - val_loss: 0.8885 - val_accuracy: 0.8366\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "print(history.history.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6y-TIf591zc",
        "outputId": "18f4bb26-5ddb-43a5-db3f-b9eb57260bf2"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "loss, accuracy가 train - test 사이에서 교차하는 모습이 참 안타깝습니다. 이대로라면 epoch은 2~5정도면 충분해 보입니다."
      ],
      "metadata": {
        "id": "I1k_RooH1CK1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.(6). Loss, Accuracy 그래프 시각화\n"
      ],
      "metadata": {
        "id": "KfizmvmHmJb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['accuracy'], label='acc')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.plot(history.history['val_accuracy'], label='val_acc')\n",
        "\n",
        "plt.legend()\n",
        "plt.xticks(ticks=list(range(20)))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "yNrk0JDZFto3",
        "outputId": "6ffe21e2-384e-4e79-dcd3-8c8dec941637"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.(6). 학습된 embedding 레이어 분석\n"
      ],
      "metadata": {
        "id": "wsOWezeomQjd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.(7). 한국어 Word2Vec임베딩 활용하여 성능 개선\n"
      ],
      "metadata": {
        "id": "SG2S9aRzmRNd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyY-xqrhb2rT"
      },
      "source": [
        "\n",
        "\n",
        "# 1. 프로젝트 이전 코드\n",
        "lms에서 코드를 좀 가져오겠습니다.\n",
        "-> mecab 설치 너무 번거롭네요. 그냥 lms의 주피터 노트북으로 갑시다 -> 다시 여기서 하기로 하였습니다.  \n",
        "## 1.1. encode, decode함수\n",
        "단어를 index(숫자)로 저장했다가 다시 문장으로 해석했다 하는 과정입니다. 여러개 처리하는 것을 function 둘로 나눠놨네요. for loop 표현식을 쓰고 있습니다.\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트로 변환해 주는 함수를 만들어 봅시다.\n",
        "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
        "def get_encoded_sentence(sentence, word_to_index):\n",
        "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
        "\n",
        "#print(get_encoded_sentence('i eat lunch', word_to_index))\n",
        "\n",
        "# 여러 개의 문장 리스트를 한꺼번에 숫자 텐서로 encode해 주는 함수입니다. \n",
        "def get_encoded_sentences(sentences, word_to_index):\n",
        "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
        "\n",
        "# sentences=['i feel hungry', 'i eat lunch', 'now i feel happy'] 가 아래와 같이 변환됩니다. \n",
        "\n",
        "#encoded_sentences = get_encoded_sentences(sentences, word_to_index)\n",
        "#print(encoded_sentences)\n",
        "```\n",
        "\n",
        "```python\n",
        "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
        "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
        "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
        "\n",
        "#print(get_decoded_sentence([1, 3, 4, 5], index_to_word))\n",
        "\n",
        "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
        "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
        "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\n",
        "\n",
        "# encoded_sentences=[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 가 아래와 같이 변환됩니다.\n",
        "#print(get_decoded_sentences(encoded_sentences, index_to_word))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ok7Qlpp2d0uC"
      },
      "source": [
        "## 1.2. IMDB데이터셋 가져오기\n",
        "tf.keras에 서 데이터를 가져옵니다. 인코딩 된 것이라 사전도 같이 줍니다.\n",
        "\n",
        "```python\n",
        "imdb = tf.keras.datasets.imdb\n",
        "\n",
        "# IMDb 데이터셋 다운로드 \n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
        "print(\"훈련 샘플 개수: {}, 테스트 개수: {}\".format(len(x_train), len(x_test)))\n",
        "\n",
        "\n",
        "word_to_index = imdb.get_word_index()\n",
        "index_to_word = {index:word for word, index in word_to_index.items()}\n",
        "\n",
        "#실제 인코딩 인덱스는 제공된 word_to_index에서 index 기준으로 3씩 뒤로 밀려 있습니다.  \n",
        "word_to_index = {k:(v+3) for k,v in word_to_index.items()}\n",
        "\n",
        "# 처음 몇 개 인덱스는 사전에 정의되어 있습니다\n",
        "word_to_index[\"<PAD>\"] = 0\n",
        "word_to_index[\"<BOS>\"] = 1\n",
        "word_to_index[\"<UNK>\"] = 2  # unknown\n",
        "word_to_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "index_to_word = {index:word for word, index in word_to_index.items()}\n",
        "\n",
        "#print(index_to_word[1])     # '<BOS>' 가 출력됩니다. \n",
        "#print(word_to_index['the'])  # 4 이 출력됩니다. \n",
        "#print(index_to_word[4])     # 'the' 가 출력됩니다.\n",
        "\n",
        "total_data_text = list(x_train) + list(x_test)\n",
        "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
        "num_tokens = [len(tokens) for tokens in total_data_text]\n",
        "num_tokens = np.array(num_tokens)\n",
        "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
        "print('문장길이 평균 : ', np.mean(num_tokens))\n",
        "print('문장길이 최대 : ', np.max(num_tokens))\n",
        "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
        "\n",
        "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
        "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
        "maxlen = int(max_tokens)\n",
        "print('pad_sequences maxlen : ', maxlen)\n",
        "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))\n",
        "\n",
        "#padding: pre 혹은 post로\n",
        "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
        "                                                        value=word_to_index[\"<PAD>\"],\n",
        "                                                        padding='post', # 혹은 'pre'\n",
        "                                                        maxlen=maxlen)\n",
        "\n",
        "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
        "                                                       value=word_to_index[\"<PAD>\"],\n",
        "                                                       padding='post', # 혹은 'pre'\n",
        "                                                       maxlen=maxlen)\n",
        "\n",
        "print(x_train.shape)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUbJKytKgkDL"
      },
      "source": [
        "## 1.3. RNN 모델 \n",
        "```python\n",
        "vocab_size = 10000\n",
        "word_vector_dim = 16  # 단어 하나를 표현하는 임베딩 벡터의 차원수입니다. \n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
        "model.add(tf.keras.layers.LSTM(128))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경 가능)\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "model.summary()\n",
        "```\n",
        "```python\n",
        "# validation set 10000건 분리\n",
        "x_val = x_train[:10000]   \n",
        "y_val = y_train[:10000]\n",
        "\n",
        "# validation set을 제외한 나머지 15000건\n",
        "partial_x_train = x_train[10000:]  \n",
        "partial_y_train = y_train[10000:]\n",
        "\n",
        "print(partial_x_train.shape)\n",
        "print(partial_y_train.shape)\n",
        "```\n",
        "```python\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "              \n",
        "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
        "\n",
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val), verbose=1)\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "EXP8_imdb emotion analysis.ipynb",
      "provenance": [],
      "mount_file_id": "1lv3FDw2hKe_Gp56mzCxGPIHof8p0m6Cz",
      "authorship_tag": "ABX9TyOC/JGku4cTE7BJmh7MfHEE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}