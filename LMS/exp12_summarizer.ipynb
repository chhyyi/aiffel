{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "8vWUMYBft8hu",
        "91j6cC70Wnmj",
        "Nvt2bDppvI0_",
        "t1Tv0mAIpfk5",
        "vzWCMoCRu1GG"
      ],
      "authorship_tag": "ABX9TyPoI0vZVwq++OeNy0WR6ZLl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chhyyi/aiffel/blob/main/LMS/exp12_summarizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aiffel LMS EXP12. summarizer \n",
        "\n",
        "일단 버전을 맞춥시다."
      ],
      "metadata": {
        "id": "63boCmhIipNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 list | grep tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxLPoFB7mL66",
        "outputId": "2e01a617-4b93-4dba-f4de-320c35b8ac35"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensorflow                    2.8.2+zzzcolab20220719082949\n",
            "tensorflow-datasets           4.6.0\n",
            "tensorflow-estimator          2.8.0\n",
            "tensorflow-gcs-config         2.8.0\n",
            "tensorflow-hub                0.12.0\n",
            "tensorflow-io-gcs-filesystem  0.26.0\n",
            "tensorflow-metadata           1.10.0\n",
            "tensorflow-probability        0.16.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NY2ATgK-iZmT",
        "outputId": "ba946348-f170-4c8d-fa5c-f167b83bd8f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.6.0\n",
            "  Downloading https://us-python.pkg.dev/colab-wheels/public/tensorflow/tensorflow-2.6.0%2Bzzzcolab20220506153740-cp37-cp37m-linux_x86_64.whl (564.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 564.4 MB 2.4 kB/s \n",
            "\u001b[?25hCollecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (3.1.0)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (2.8.0)\n",
            "Collecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (3.17.3)\n",
            "Collecting gast==0.4.0\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (3.3.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (1.1.0)\n",
            "Collecting numpy~=1.19.2\n",
            "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 7.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (0.37.1)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (1.15.0)\n",
            "Collecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (2.8.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (1.47.0)\n",
            "Collecting clang~=5.0\n",
            "  Downloading clang-5.0.tar.gz (30 kB)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (1.1.2)\n",
            "Collecting absl-py~=0.10\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 58.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (2.8.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (1.6.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow==2.6.0) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (2.23.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.0) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.0) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.6.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.6.0) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.6.0) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.0) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6.0) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6.0) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.6.0) (3.2.0)\n",
            "Building wheels for collected packages: clang, wrapt\n",
            "  Building wheel for clang (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30694 sha256=77dc9b14c065421f8c78246b1d4250ec122df814549b312556f685099a24d3ce\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/91/04/971b4c587cf47ae952b108949b46926f426c02832d120a082a\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68722 sha256=c50fbec0a2341ffc81646645ccb662530abfc77f4d0cbb31e9517eec1a93e003\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
            "Successfully built clang wrapt\n",
            "Installing collected packages: typing-extensions, numpy, absl-py, wrapt, gast, flatbuffers, clang, tensorflow\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.1.1\n",
            "    Uninstalling typing-extensions-4.1.1:\n",
            "      Successfully uninstalled typing-extensions-4.1.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.2.0\n",
            "    Uninstalling absl-py-1.2.0:\n",
            "      Successfully uninstalled absl-py-1.2.0\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0.7\n",
            "    Uninstalling flatbuffers-2.0.7:\n",
            "      Successfully uninstalled flatbuffers-2.0.7\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "cmdstanpy 1.0.7 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\u001b[0m\n",
            "Successfully installed absl-py-0.15.0 clang-5.0 flatbuffers-1.12 gast-0.4.0 numpy-1.19.5 tensorflow-2.6.0+zzzcolab20220506153740 typing-extensions-3.7.4.3 wrapt-1.12.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "typing_extensions"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras==2.6.0\n",
            "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 5.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "Successfully installed keras-2.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nltk==3.6.5\n",
            "  Downloading nltk-3.6.5-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.5) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.5) (4.64.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.5) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.5) (1.1.0)\n",
            "Installing collected packages: nltk\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.7\n",
            "    Uninstalling nltk-3.7:\n",
            "      Successfully uninstalled nltk-3.7\n",
            "Successfully installed nltk-3.6.5\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting summa==1.2.0\n",
            "  Downloading summa-1.2.0.tar.gz (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.7/dist-packages (from summa==1.2.0) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy>=0.19->summa==1.2.0) (1.19.5)\n",
            "Building wheels for collected packages: summa\n",
            "  Building wheel for summa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for summa: filename=summa-1.2.0-py3-none-any.whl size=54412 sha256=6cbeee9ee5ce7f6ecc0ed3d91f9dbf47ec7d88c47541ff72a77ab0035d311747\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/64/ac/7b443477588d365ef37ada30d456bdf5f07dc5be9f6324cb6e\n",
            "Successfully built summa\n",
            "Installing collected packages: summa\n",
            "Successfully installed summa-1.2.0\n"
          ]
        }
      ],
      "source": [
        "#restart runtime required!!\n",
        "!pip install tensorflow==2.6.0\n",
        "!pip install keras==2.6.0\n",
        "!pip install nltk==3.6.5\n",
        "!pip install summa==1.2.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "from bs4 import BeautifulSoup \n",
        "from tensorflow.keras.preprocessing.text import Tokenizer \n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import urllib.request\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDwgI_-1mc7o",
        "outputId": "e20a5d10-68dd-4587-d673-1398f5f5460c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 데이터 수집하기"
      ],
      "metadata": {
        "id": "TsWfcnPpjfBX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
        "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')\n",
        "data.sample(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dcxdPHgWjYrf",
        "outputId": "17785eb4-b1b4-469a-a798-7b41031f15fc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               headlines  \\\n",
              "45004  US studying tardigrades to improve survival ra...   \n",
              "97225  Govt asks MPs to attend 'Dangal' screening wit...   \n",
              "10892  Faizabad will be called Ayodhya from today: UP...   \n",
              "7177   Those with big surnames came & went but found ...   \n",
              "93469  Hackers leak files showing NSA spied on int'l ...   \n",
              "\n",
              "                                                    text  \n",
              "45004  The US government's defence agency DARPA is ho...  \n",
              "97225  Lok Sabha Speaker Sumitra Mahajan has organise...  \n",
              "10892  Uttar Pradesh Chief Minister Yogi Adityanath o...  \n",
              "7177   In an alleged jibe at the Nehru-Gandhi family,...  \n",
              "93469  Hacking group TheShadowBrokers has released do...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b6008d31-117d-465f-ae17-6b11f3d55ded\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headlines</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>45004</th>\n",
              "      <td>US studying tardigrades to improve survival ra...</td>\n",
              "      <td>The US government's defence agency DARPA is ho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97225</th>\n",
              "      <td>Govt asks MPs to attend 'Dangal' screening wit...</td>\n",
              "      <td>Lok Sabha Speaker Sumitra Mahajan has organise...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10892</th>\n",
              "      <td>Faizabad will be called Ayodhya from today: UP...</td>\n",
              "      <td>Uttar Pradesh Chief Minister Yogi Adityanath o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7177</th>\n",
              "      <td>Those with big surnames came &amp; went but found ...</td>\n",
              "      <td>In an alleged jibe at the Nehru-Gandhi family,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93469</th>\n",
              "      <td>Hackers leak files showing NSA spied on int'l ...</td>\n",
              "      <td>Hacking group TheShadowBrokers has released do...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b6008d31-117d-465f-ae17-6b11f3d55ded')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b6008d31-117d-465f-ae17-6b11f3d55ded button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b6008d31-117d-465f-ae17-6b11f3d55ded');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 추상적 요약: 데이터 전처리하기\n",
        "- 불용어 적용 범위?"
      ],
      "metadata": {
        "id": "kPkdyNNojrQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Text 열에서 중복을 배제한 유일한 샘플의 수 :', data['text'].nunique())\n",
        "print('Summary 열에서 중복을 배제한 유일한 샘플의 수 :', data['headlines'].nunique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KadkEpE7ly2K",
        "outputId": "d3d617ea-9665-4354-bf89-e01c211a91cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text 열에서 중복을 배제한 유일한 샘플의 수 : 98360\n",
            "Summary 열에서 중복을 배제한 유일한 샘플의 수 : 98280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inplace=True 를 설정하면 DataFrame 타입 값을 return 하지 않고 data 내부를 직접적으로 바꿉니다\n",
        "data.drop_duplicates(subset = ['text'], inplace=True)\n",
        "print('전체 샘플수 :', (len(data)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AO-ue4A1l_DY",
        "outputId": "207b21fe-9953-4e85-e361-835dd23419ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플수 : 98360\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAVSJy9kmD-2",
        "outputId": "cddd8ce1-0c35-405d-c664-738ba0748c68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "headlines    0\n",
            "text         0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #나중에 비교를 위해 original index를 저장합니다. 인덱스를 바꿀 때마다 이걸 추가할 것입니다..\n",
        "#data['orig_index']=range(len(data))\n",
        "#print(data.tail())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEQYkOT4O1dN",
        "outputId": "739c44f5-77d8-4f03-eb6d-ea74b6973502"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               headlines  \\\n",
            "98396  CRPF jawan axed to death by Maoists in Chhatti...   \n",
            "98397  First song from Sonakshi Sinha's 'Noor' titled...   \n",
            "98398         'The Matrix' film to get a reboot: Reports   \n",
            "98399  Snoop Dogg aims gun at clown dressed as Trump ...   \n",
            "98400  Madhesi Morcha withdraws support to Nepalese g...   \n",
            "\n",
            "                                                    text  orig_index  \n",
            "98396  A CRPF jawan was on Tuesday axed to death with...       98396  \n",
            "98397  'Uff Yeh', the first song from the Sonakshi Si...       98397  \n",
            "98398  According to reports, a new version of the 199...       98398  \n",
            "98399  A new music video shows rapper Snoop Dogg aimi...       98399  \n",
            "98400  Madhesi Morcha, an alliance of seven political...       98400  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
        "\n",
        "print(\"정규화 사전의 수: \", len(contractions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlHqXmq1mGd5",
        "outputId": "5be48d56-6b50-4ae9-90fa-3eb2169e1f58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정규화 사전의 수:  120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('불용어 개수 :', len(stopwords.words('english') ))\n",
        "print(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAW47IV0mO-z",
        "outputId": "bcab20d4-dfbb-44b7-b2b5-44dcc476d73f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "불용어 개수 : 179\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 전처리 함수\n",
        "def preprocess_sentence(sentence, remove_stopwords=True):\n",
        "    sentence = sentence.lower() # 텍스트 소문자화\n",
        "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
        "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
        "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
        "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
        "    sentence = re.sub(r\"'s\\b\",\"\", sentence) # 소유격 제거. Ex) roland's -> roland\n",
        "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
        "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
        "    \n",
        "    # 불용어 제거 (Text)\n",
        "    if remove_stopwords:\n",
        "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
        "    # 불용어 미제거 (Summary)\n",
        "    else:\n",
        "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "XLLezflFm8rJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data['headlines'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYiccxoDnG-e",
        "outputId": "296e10fb-46c7-4634-9f70-8753dc215dd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "upGrad learner switches to career in ML & Al with 90% salary hike\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_text = str(data['text'][0])\n",
        "temp_summary = str(data['headlines'][0])\n",
        "\n",
        "print(\"text: \", preprocess_sentence(temp_text), '\\n orginal: ', temp_text)\n",
        "print(\"headlines:\", preprocess_sentence(temp_summary, False),'\\n orginal: ', temp_summary)  # 불용어를 제거하지 않습니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ilf81WyUnBRJ",
        "outputId": "c2ab99ed-ac7b-4687-ad09-715310dfbb72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text:  saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers \n",
            " orginal:  Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike. upGrad's Online Power Learning has powered 3 lakh+ careers.\n",
            "headlines: upgrad learner switches to career in ml al with salary hike \n",
            " orginal:  upGrad learner switches to career in ML & Al with 90% salary hike\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_text = []\n",
        "\n",
        "for s in data['text']:\n",
        "    clean_text.append(preprocess_sentence(s))\n",
        "\n",
        "# 전처리 후 출력\n",
        "print(\"Text 전처리 후 결과: \", clean_text[:5])"
      ],
      "metadata": {
        "id": "X8AeKyK3oZOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_summary = []\n",
        "\n",
        "for s in data['headlines']:\n",
        "    clean_summary.append(preprocess_sentence(s, False))\n",
        "\n",
        "print(\"headlines 전처리 후 결과: \", clean_summary[:5])"
      ],
      "metadata": {
        "id": "jl5AiDRyohp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 길이 맞추기"
      ],
      "metadata": {
        "id": "8vWUMYBft8hu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 길이 분포 출력\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "text_len = [len(s.split()) for s in clean_text]\n",
        "summary_len = [len(s.split()) for s in clean_summary]\n",
        "\n",
        "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
        "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
        "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
        "print('요약의 최소 길이 : {}'.format(np.min(summary_len)))\n",
        "print('요약의 최대 길이 : {}'.format(np.max(summary_len)))\n",
        "print('요약의 평균 길이 : {}'.format(np.mean(summary_len)))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.boxplot(text_len)\n",
        "plt.title('Text')\n",
        "plt.subplot(1,2,2)\n",
        "plt.boxplot(summary_len)\n",
        "plt.title('Summary')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.title('Text')\n",
        "plt.hist(text_len, bins = 40)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()\n",
        "\n",
        "plt.title('Summary')\n",
        "plt.hist(summary_len, bins = 40)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 962
        },
        "id": "8TUrz5W-t7zZ",
        "outputId": "61fc8f36-9e69-4a2a-ed60-e4c6f833a1d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "텍스트의 최소 길이 : 1\n",
            "텍스트의 최대 길이 : 60\n",
            "텍스트의 평균 길이 : 35.09968483123221\n",
            "요약의 최소 길이 : 1\n",
            "요약의 최대 길이 : 16\n",
            "요약의 평균 길이 : 9.299532330215534\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#데이터셋과 길이를 넣으면 그 이하인 것의 비율을 출력하는 함수\n",
        "def below_threshold_len(max_len, nested_list):\n",
        "  cnt = 0\n",
        "  for s in nested_list:\n",
        "    if(len(s.split()) <= max_len):\n",
        "        cnt = cnt + 1\n",
        "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))\n",
        "\n",
        "#이제 길이를 정해보아요. (이것은 임의로 정해진 것입니다.)\n",
        "below_threshold_len(41, clean_text)\n",
        "below_threshold_len(11, clean_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYVQYqWC7zNP",
        "outputId": "6f2c5ac6-55b7-4f01-d6d3-551c262723c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플 중 길이가 41 이하인 샘플의 비율: 0.9549613664091094\n",
            "전체 샘플 중 길이가 11 이하인 샘플의 비율: 0.9449877999186661\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#41, 11로 정하고 담아봅시다. \n",
        "#LMS에서는 조건식을 통해 array와 shape는 같고 Bool값이 들어있는 array를 데이터셋에 넣어서 하는데\n",
        "#apply 쓰는건 판다스 df거고 고쳐서 해야겠네요.\n",
        "\n",
        "text_max_len=41\n",
        "summary_max_len=11\n",
        "index_to_remain=[]\n",
        "lim_text=np.array(clean_text.copy())\n",
        "lim_summary=np.array(clean_summary.copy())\n",
        "print('maxlen 적용 전 전체 샘플수 :', len(lim_text), len(lim_summary))\n",
        "#better use np.where... but I did not planned to use numpy array so it is a bit dirty.\n",
        "\n",
        "for i, text in enumerate(lim_text):\n",
        "    index_to_remain.append(len(text.split())<=text_max_len or len(lim_summary[i].split())<=summary_max_len)\n",
        "\n",
        "lim_text=lim_text[index_to_remain]\n",
        "lim_summary=lim_summary[index_to_remain]\n",
        "\n",
        "print('maxlen 적용 전 전체 샘플수 :', len(lim_text), len(lim_summary))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-RGFGK7BqSl",
        "outputId": "2ad30e9c-20e4-4920-b5f0-19608ba540bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maxlen 적용 전 전체 샘플수 : 98360 98360\n",
            "maxlen 적용 전 전체 샘플수 : 98130 98130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## summary에 시작/종료 토큰 추가하기\n",
        "decoder는 input으로 시작 토큰이 있는 문자열을 받아 output으로 종료 토큰이 있는 문자열을 내놔야 합니다. 문자열은 그냥 더하면 됩니다."
      ],
      "metadata": {
        "id": "91j6cC70Wnmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_input=['sostoken '+x for x in lim_summary]\n",
        "decoder_target=[x+' eostoken' for x in lim_summary]\n",
        "\n",
        "print(type(decoder_input), type(decoder_target), type(lim_text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehyjrW5WWeiq",
        "outputId": "4ccde817-155d-4323-8925-a9d67f489438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> <class 'list'> <class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lms와 같이 일단 numpy array로 저장하겠습니다.\n",
        "decoder_input=np.array(decoder_input)\n",
        "decoder_target=np.array(decoder_target)"
      ],
      "metadata": {
        "id": "LsqGQQahnfzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train - valid data set 분리"
      ],
      "metadata": {
        "id": "Nvt2bDppvI0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#먼저 numpy를 이용해 shuffle합니다.\n",
        "indices = np.arange(decoder_input.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "encoder_input = np.array(lim_text[indices])\n",
        "decoder_input = decoder_input[indices]\n",
        "decoder_target = decoder_target[indices]"
      ],
      "metadata": {
        "id": "sCKCBW_oM-BM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(decoder_input)"
      ],
      "metadata": {
        "id": "DUsnto9-68MA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_of_val = int(len(encoder_input)*0.2)\n",
        "print('테스트 데이터의 수 :', n_of_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4PLC_ewob5C",
        "outputId": "d41f4f7a-344e-431b-b011-ae685fdcea51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 데이터의 수 : 19626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_train=encoder_input[:-n_of_val]\n",
        "decoder_input_train=decoder_input[:-n_of_val]\n",
        "decoder_target_train=decoder_target[:-n_of_val]\n",
        "\n",
        "encoder_input_test=encoder_input[-n_of_val:]\n",
        "decoder_input_test=decoder_input[-n_of_val:]\n",
        "decoder_target_test=decoder_target[-n_of_val:]\n",
        "\n",
        "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
        "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
        "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
        "print('테스트 레이블의 개수 :', len(decoder_input_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jncF4xJbodYw",
        "outputId": "b41eb0f5-1d81-4316-9bcf-fcbbdf74a624"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터의 개수 : 78504\n",
            "훈련 레이블의 개수 : 78504\n",
            "테스트 데이터의 개수 : 19626\n",
            "테스트 레이블의 개수 : 19626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 정수 인코딩"
      ],
      "metadata": {
        "id": "t1Tv0mAIpfk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
        "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성"
      ],
      "metadata": {
        "id": "-6qJJ9KLpZb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 7\n",
        "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
        "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
        "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
        "\n",
        "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
        "for key, value in src_tokenizer.word_counts.items():\n",
        "    total_freq = total_freq + value\n",
        "\n",
        "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
        "    if(value < threshold):\n",
        "        rare_cnt = rare_cnt + 1\n",
        "        rare_freq = rare_freq + value\n",
        "\n",
        "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
        "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
        "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
        "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C71Jd5-fqQ5_",
        "outputId": "49b97c1a-4f20-4d35-a179-a432666c9675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합(vocabulary)의 크기 : 69478\n",
            "등장 빈도가 6번 이하인 희귀 단어의 수: 47314\n",
            "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 22164\n",
            "단어 집합에서 희귀 단어의 비율: 68.09925444025447\n",
            "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.4884067137868207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_vocab = 22000\n",
        "src_tokenizer = Tokenizer(num_words=src_vocab)\n",
        "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성\n"
      ],
      "metadata": {
        "id": "EuQjYjNAqbA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 텍스트 시퀀스를 정수 시퀀스로 변환 - encoder용\n",
        "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
        "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
        "\n",
        "# 잘 진행되었는지 샘플 출력\n",
        "print(encoder_input_train[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klOQkbhFqjlE",
        "outputId": "41fd4f72-b6f7-4651-fc65-c33e7d2d8c3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3973, 245, 1430, 3621, 587, 281, 358, 4830, 1177, 5944, 1415, 1540, 624, 141, 285, 188, 3973, 81, 6974, 7244, 624, 7154, 2066, 378, 25, 5944, 1415, 152, 624, 4685, 928, 6425, 876, 1977, 5944, 1415], [137, 1234, 858, 13822, 1, 132, 538, 2235, 383, 1586, 320, 100, 1323, 1215, 8837, 149, 3368, 10246, 7155, 405, 356, 538, 383, 42, 1215, 83, 7352, 2368, 7155, 1390, 7155, 7155, 583, 11, 948], [270, 666, 863, 7156, 7, 26, 818, 22, 1587, 6498, 1124, 101, 270, 1701, 71, 569, 830, 340, 5702, 71, 270, 123, 2417, 1749, 1, 270, 356, 71, 1701, 7, 569, 3, 33]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#정수 시퀀스로 변환 - decoder용\n",
        "tar_tokenizer = Tokenizer()\n",
        "tar_tokenizer.fit_on_texts(decoder_input_train)\n"
      ],
      "metadata": {
        "id": "ivYkdu5MrAS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 6\n",
        "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
        "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
        "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
        "\n",
        "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
        "for key, value in tar_tokenizer.word_counts.items():\n",
        "    total_freq = total_freq + value\n",
        "\n",
        "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
        "    if(value < threshold):\n",
        "        rare_cnt = rare_cnt + 1\n",
        "        rare_freq = rare_freq + value\n",
        "\n",
        "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
        "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
        "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
        "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOEspXg7rGa2",
        "outputId": "90bd8505-8f1b-42f9-e6aa-b21504e37afe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합(vocabulary)의 크기 : 30047\n",
            "등장 빈도가 5번 이하인 희귀 단어의 수: 19622\n",
            "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 10425\n",
            "단어 집합에서 희귀 단어의 비율: 65.30435650813725\n",
            "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 4.664551611110355\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tar_vocab = 10000\n",
        "tar_tokenizer = Tokenizer(num_words=tar_vocab) \n",
        "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
        "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
        "\n",
        "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
        "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
        "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
        "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
        "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
        "\n",
        "# 잘 변환되었는지 확인\n",
        "print('input')\n",
        "print('input ',decoder_input_train[:5])\n",
        "print('target')\n",
        "print('decoder ',decoder_target_train[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9sTdpqYr7at",
        "outputId": "b089a93a-7742-4171-e775-8bdd98a4f861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input\n",
            "input  [[1, 2050, 696, 3, 1172, 1323, 3, 325, 2193, 3, 3884], [1, 902, 1166, 172, 955, 30, 978, 11, 481, 42, 799], [1, 143, 864, 79, 1347, 4850, 5, 18, 35, 54, 4, 1061, 58], [1, 2194, 134, 730, 73, 3, 778, 15, 108, 2318, 225], [1, 221, 1315, 1324, 14, 7684, 5020, 2904, 314]]\n",
            "target\n",
            "decoder  [[2050, 696, 3, 1172, 1323, 3, 325, 2193, 3, 3884, 2], [902, 1166, 172, 955, 30, 978, 11, 481, 42, 799, 2], [143, 864, 79, 1347, 4850, 5, 18, 35, 54, 4, 1061, 58, 2], [2194, 134, 730, 73, 3, 778, 15, 108, 2318, 225, 2], [221, 1315, 1324, 14, 7684, 5020, 2904, 314, 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k=0\n",
        "for i, v in tar_tokenizer.word_counts.items():\n",
        "    print(i, v)\n",
        "    k+=1\n",
        "    if k>5:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Hm-M5ZRrYpQ",
        "outputId": "800ad212-0118-4880-96c8-c3a4aedd8cbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sostoken 78504\n",
            "provide 116\n",
            "way 326\n",
            "to 49916\n",
            "check 208\n",
            "sims 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 단어 tokenizer에서 제외된 단어만 있는 문장들 삭제\n",
        "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
        "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
        "\n",
        "print('삭제할 훈련 데이터의 개수 :', len(drop_train))\n",
        "print('삭제할 테스트 데이터의 개수 :', len(drop_test))\n",
        "\n",
        "encoder_input_train = [sentence for index, sentence in enumerate(encoder_input_train) if index not in drop_train]\n",
        "decoder_input_train = [sentence for index, sentence in enumerate(decoder_input_train) if index not in drop_train]\n",
        "decoder_target_train = [sentence for index, sentence in enumerate(decoder_target_train) if index not in drop_train]\n",
        "\n",
        "encoder_input_test = [sentence for index, sentence in enumerate(encoder_input_test) if index not in drop_test]\n",
        "decoder_input_test = [sentence for index, sentence in enumerate(decoder_input_test) if index not in drop_test]\n",
        "decoder_target_test = [sentence for index, sentence in enumerate(decoder_target_test) if index not in drop_test]\n",
        "\n",
        "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
        "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
        "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
        "print('테스트 레이블의 개수 :', len(decoder_input_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzJEdM-mstwN",
        "outputId": "9c706fb4-f2b9-4b92-886e-47a4b6bfbf39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "삭제할 훈련 데이터의 개수 : 0\n",
            "삭제할 테스트 데이터의 개수 : 0\n",
            "훈련 데이터의 개수 : 78504\n",
            "훈련 레이블의 개수 : 78504\n",
            "테스트 데이터의 개수 : 19626\n",
            "테스트 레이블의 개수 : 19626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#padding\n",
        "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
        "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
        "decoder_input_train = pad_sequences(decoder_input_train, maxlen=summary_max_len, padding='post')\n",
        "decoder_target_train = pad_sequences(decoder_target_train, maxlen=summary_max_len, padding='post')\n",
        "decoder_input_test = pad_sequences(decoder_input_test, maxlen=summary_max_len, padding='post')\n",
        "decoder_target_test = pad_sequences(decoder_target_test, maxlen=summary_max_len, padding='post')\n"
      ],
      "metadata": {
        "id": "_cnefCaFtF7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 추상적 요약: 어텐션 메커니즘 사용하기"
      ],
      "metadata": {
        "id": "qDzAl1JClLmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 일단 이대로 추출적 요약 해보기\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.layers import AdditiveAttention\n",
        "\n",
        "\n",
        "# 인코더 설계 시작\n",
        "embedding_dim = 128\n",
        "hidden_size = 256\n",
        "\n",
        "# 인코더\n",
        "encoder_inputs = Input(shape=(text_max_len,))\n",
        "\n",
        "# 인코더의 임베딩 층\n",
        "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
        "\n",
        "# 인코더의 LSTM 1\n",
        "# encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
        "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "# 인코더의 LSTM 2\n",
        "# encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
        "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "# 인코더의 LSTM 3\n",
        "# encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
        "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
        "\n",
        "# 디코더 설계\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "# 디코더의 임베딩 층\n",
        "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# 디코더의 LSTM\n",
        "# decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
        "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n",
        "\n",
        "\n",
        "# 어텐션 층(어텐션 함수)\n",
        "attn_layer = AdditiveAttention(name='attention_layer')\n",
        "\n",
        "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
        "attn_out = attn_layer([decoder_outputs, encoder_outputs])\n",
        "\n",
        "\n",
        "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "# 디코더의 출력층\n",
        "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
        "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
        "\n",
        "# 모델 정의\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzBhCJcXtUOn",
        "outputId": "261413cd-c0e2-4cc2-c9c9-8c4eac9e8efa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 41)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 41, 128)      2816000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 41, 256), (N 394240      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 41, 256), (N 525312      lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 128)    1280000     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 41, 256), (N 525312      lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AdditiveAttent (None, None, 256)    256         lstm_3[0][0]                     \n",
            "                                                                 lstm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 512)    0           lstm_3[0][0]                     \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 10000)  5130000     concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 11,065,360\n",
            "Trainable params: 11,065,360\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### training model"
      ],
      "metadata": {
        "id": "vzWCMoCRu1GG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
        "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
        "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
        "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
        "          batch_size=256, callbacks=[es], epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-qZFqAivC1P",
        "outputId": "5cf37ea8-38e5-4f9f-8376-af3911429063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "307/307 [==============================] - 32s 69ms/step - loss: 6.0253 - val_loss: 5.5855\n",
            "Epoch 2/50\n",
            "307/307 [==============================] - 20s 64ms/step - loss: 5.4202 - val_loss: 5.1836\n",
            "Epoch 3/50\n",
            "307/307 [==============================] - 20s 64ms/step - loss: 5.0513 - val_loss: 4.8866\n",
            "Epoch 4/50\n",
            "307/307 [==============================] - 20s 64ms/step - loss: 4.7673 - val_loss: 4.6792\n",
            "Epoch 5/50\n",
            "307/307 [==============================] - 20s 64ms/step - loss: 4.5415 - val_loss: 4.5242\n",
            "Epoch 6/50\n",
            "307/307 [==============================] - 20s 64ms/step - loss: 4.3528 - val_loss: 4.4075\n",
            "Epoch 7/50\n",
            "307/307 [==============================] - 20s 64ms/step - loss: 4.1938 - val_loss: 4.3182\n",
            "Epoch 8/50\n",
            "307/307 [==============================] - 20s 64ms/step - loss: 4.0564 - val_loss: 4.2320\n",
            "Epoch 9/50\n",
            "307/307 [==============================] - 20s 64ms/step - loss: 3.9336 - val_loss: 4.1823\n",
            "Epoch 10/50\n",
            "307/307 [==============================] - 20s 64ms/step - loss: 3.8237 - val_loss: 4.1320\n",
            "Epoch 11/50\n",
            "307/307 [==============================] - 20s 65ms/step - loss: 3.7268 - val_loss: 4.0785\n",
            "Epoch 12/50\n",
            "307/307 [==============================] - 20s 64ms/step - loss: 3.6399 - val_loss: 4.0612\n",
            "Epoch 13/50\n",
            "307/307 [==============================] - 20s 64ms/step - loss: 3.5578 - val_loss: 4.0243\n",
            "Epoch 14/50\n",
            "307/307 [==============================] - 20s 64ms/step - loss: 3.4844 - val_loss: 3.9989\n",
            "Epoch 15/50\n",
            "307/307 [==============================] - 20s 64ms/step - loss: 3.4154 - val_loss: 3.9817\n",
            "Epoch 16/50\n",
            "307/307 [==============================] - 20s 64ms/step - loss: 3.3541 - val_loss: 3.9696\n",
            "Epoch 17/50\n",
            "307/307 [==============================] - 20s 64ms/step - loss: 3.2967 - val_loss: 3.9612\n",
            "Epoch 18/50\n",
            "307/307 [==============================] - 20s 64ms/step - loss: 3.2432 - val_loss: 3.9485\n",
            "Epoch 19/50\n",
            "307/307 [==============================] - 20s 64ms/step - loss: 3.1913 - val_loss: 3.9395\n",
            "Epoch 20/50\n",
            "307/307 [==============================] - 20s 64ms/step - loss: 3.1439 - val_loss: 3.9318\n",
            "Epoch 21/50\n",
            "307/307 [==============================] - 20s 64ms/step - loss: 3.0957 - val_loss: 3.9354\n",
            "Epoch 22/50\n",
            "307/307 [==============================] - 20s 64ms/step - loss: 3.0484 - val_loss: 3.9256\n",
            "Epoch 23/50\n",
            "307/307 [==============================] - 20s 64ms/step - loss: 3.0030 - val_loss: 3.9219\n",
            "Epoch 24/50\n",
            "307/307 [==============================] - 20s 65ms/step - loss: 2.9639 - val_loss: 3.9248\n",
            "Epoch 25/50\n",
            "307/307 [==============================] - 20s 64ms/step - loss: 2.9278 - val_loss: 3.9190\n",
            "Epoch 26/50\n",
            "307/307 [==============================] - 20s 64ms/step - loss: 2.8949 - val_loss: 3.9236\n",
            "Epoch 27/50\n",
            "307/307 [==============================] - 20s 64ms/step - loss: 2.8632 - val_loss: 3.9211\n",
            "Epoch 00027: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "8XgSxEHcvFY0",
        "outputId": "d7da3652-c164-4563-80a9-5cdd9bfe3700"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1wAu0r8gvCCp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "O6wICpYOuYoy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. 추상적 요약: 실제 결과와 요약문 비교하기"
      ],
      "metadata": {
        "id": "voPn_BiDlZPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#인퍼런스 모델 구현\n",
        "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
        "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
        "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음\n",
        "\n",
        "# 인코더 설계\n",
        "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# 이전 시점의 상태들을 저장하는 텐서\n",
        "decoder_state_input_h = Input(shape=(hidden_size,))\n",
        "decoder_state_input_c = Input(shape=(hidden_size,))\n",
        "\n",
        "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
        "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "# 어텐션 함수\n",
        "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
        "attn_out_inf = attn_layer([decoder_outputs2, decoder_hidden_state_input])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# 디코더의 출력층\n",
        "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
        "\n",
        "# 최종 디코더 모델\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_outputs2] + [state_h2, state_c2])\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    # 입력으로부터 인코더의 상태를 얻음\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "\n",
        "     # <SOS>에 해당하는 토큰 생성\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
        "\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = tar_index_to_word[sampled_token_index]\n",
        "\n",
        "        if (sampled_token!='eostoken'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
        "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (summary_max_len-1)):\n",
        "            stop_condition = True\n",
        "\n",
        "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # 상태를 업데이트 합니다.\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "jHYHbUQGvd3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
        "def seq2text(input_seq):\n",
        "    temp=''\n",
        "    for i in input_seq:\n",
        "        if (i!=0):\n",
        "            temp = temp + src_index_to_word[i]+' '\n",
        "    return temp\n",
        "\n",
        "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
        "def seq2summary(input_seq):\n",
        "    temp=''\n",
        "    for i in input_seq:\n",
        "        if ((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
        "            temp = temp + tar_index_to_word[i] + ' '\n",
        "    return temp\n",
        "\n",
        "print('=3')"
      ],
      "metadata": {
        "id": "b9FUqqpAvxng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for i in range(50, 100):\n",
        "#    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
        "#    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
        "#    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
        "#    print(\"\\n\")\n",
        "#아래에 같이 출력해서 생략"
      ],
      "metadata": {
        "id": "sOhDOEJKvzus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Summa를 이용한 추출적 요약\n",
        "\n",
        "바로 위의 결과와 비교해볼까요? 그런데 전처리 전의 문장을 넣어야 합니다. 처리를 다 반복하면 되겠습니다. 순서대로 짚어봅시다.\n",
        "1. data['text'] 에서 시작하면 되겠습니다. data['text'] #pandas df\n",
        "\n",
        "2. clean_text[i] = preprocess_sentence(data['text']) #불용처 처리\n",
        "3. lim_text[?] = clean_text[index_to_remain[i]]\n",
        "4. lim_text[?] = lim_text[indices[?]]\n",
        "5. encoder_input\n",
        "6. encoder_input_train -> 이런 것이 들어가게 됩니다.\n",
        "\n",
        "\n",
        "\n",
        "결국 decode_sequence()에 넣을 sequence를 만들면 되는데요, "
      ],
      "metadata": {
        "id": "OBcDHuRWlk_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(data['text'][55])\n",
        "print(texts)\n",
        "print(input_texts)\n",
        "#print(list(input_seq[0].split())[:text_max_len])"
      ],
      "metadata": {
        "id": "AjzAJRbvJyuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(55,100):\n",
        "    texts=preprocess_sentence(data['text'][i], True) #remove stopwords : summarize가 아닌 text에 대해서만\n",
        "    input_texts=src_tokenizer.texts_to_sequences(texts)\n",
        "    input_seq=pad_sequences(input_texts, maxlen=text_max_len, padding='post')\n",
        "    print(\"원문 :\", data['text'][i])\n",
        "    print(\"실제 요약 :\", data['headlines'][i])\n",
        "    print(\"예측 요약 :\", decode_sequence(input_seq.split()[:text_max_len]))\n",
        "    for j in range(5,20):\n",
        "        summ_extract=summarize(texts,words=j)\n",
        "        if len(summ_extract):\n",
        "            print(\"추출적 요약 :\", summ_extract)\n",
        "            break\n",
        "        print('failed to find extracted summary', len(summ_extract))\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "e5bzIxYT6JbB",
        "outputId": "c72ce9cf-0e13-4a6f-b609-e9effe1c5724"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "원문 : Actress Mishti, who has featured in 'Manikarnika: The Queen of Jhansi', has said the film's co-director Kangana Ranaut made false promises to the cast. \"Kangana had said, 'I want dates because all characters look jumbled up...I'm trying my best to give everybody a prominent space on screen.' After watching the movie, there is no scope for other characters,\" Mishti added. \n",
            "실제 요약 : Kangana made fake promises to cast: 'Manikarnika' actress Mishti\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-b57bd96f6d5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"원문 :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"실제 요약 :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'headlines'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"예측 요약 :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_max_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0msumm_extract\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 10373 into shape (1,41)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from summa.summarizer import summarize\n",
        "\n",
        "for i in range(55, 70):\n",
        "    texts=clean_text[indices[i]]\n",
        "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
        "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
        "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
        "    for j in range(5,50):\n",
        "        summ_extract=summarize(texts, words=j)\n",
        "        if len(summ_extract)>1:\n",
        "            print(\"추출적 요약 :\", summ_extract)\n",
        "            break\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVdlHCpMwdgo",
        "outputId": "d6358407-c0dc-426e-da19-299005268f58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "원문 : undefeated professional boxer floyd mayweather jr announced retirement knocking mma champion conor mcgregor richest fight history chose right dance partner last dance final fight said mayweather american ends career unbeaten professional record surpassing former boxer rocky marciano career record \n",
            "실제 요약 : mayweather retires after out mcgregor in richest fight \n",
            "예측 요약 :  mayweather mcgregor floyd mayweather to be auctioned\n",
            "\n",
            "\n",
            "원문 : indians make total child brides world according india report nearly million indians married estimated million girls added stated elimination girl child marriages help avoid neonatal deaths infant deaths child deaths \n",
            "실제 요약 : child brides in the world are indian report \n",
            "예측 요약 :  indian origin man to get married in\n",
            "\n",
            "\n",
            "원문 : minister nitin gadkari friday announced world bank backed crore scheme improve irrigation facilities water accessibility capacity several states including maharashtra karnataka telangana gadkari also announced crore worth daman ganga inter state river connectivity project expected resolve domestic water supply demand mumbai \n",
            "실제 요약 : govt announces crore world bank backed scheme \n",
            "예측 요약 :  crore crore tax plan to save cr gadkari\n",
            "\n",
            "\n",
            "원문 : justice indu malhotra woman five member supreme court bench sabarimala temple ban menstruating women said constitutes essential religious practice religious community decide court impact sabarimala places worship justice malhotra said adding cannot brought matters religion \n",
            "실제 요약 : did only woman judge on sc bench support sabarimala women ban \n",
            "예측 요약 :  sc order to kerala women who entered sabarimala\n",
            "\n",
            "\n",
            "원문 : indian origin man sentenced seven years prison six strokes cane singapore stabbing pregnant wife saw talking man accused stabbed wife used sex worker fit rage suspecting man talking \n",
            "실제 요약 : indian origin man stabs pregnant wife for talking to man jailed \n",
            "예측 요약 :  indian origin man jailed for yrs for marrying in yrs\n",
            "\n",
            "\n",
            "원문 : talking son osama bin laden mastermind behind attack alia said good child met people pretty much early added really liked study loved lot said never crossed mind would become jihadist \n",
            "실제 요약 : he was very good until he was osama mother \n",
            "예측 요약 :  never thought he is not an actress on\n",
            "\n",
            "\n",
            "원문 : facebook ceo mark zuckerberg shared photo wife priscilla chan daughter max wearing halloween costumes based movie wild things taking little wild things trick treat first time post read last year zuckerberg family wore costumes based movie train dragon \n",
            "실제 요약 : zuckerberg shares pic with family wearing halloween costumes \n",
            "예측 요약 :  mark zuckerberg shares picture of baby pollard\n",
            "\n",
            "\n",
            "원문 : goods including fake kylie jenner lip apple airpods louis vuitton iphone cases sold amazon guardian revealed used apple iphone chargers also sold new platform contacted media house amazon removed five counterfeit items sale updated information iphone chargers describing used \n",
            "실제 요약 : fake kylie jenner makeup airpods selling on amazon report \n",
            "예측 요약 :  apple co founder invests in report\n",
            "\n",
            "\n",
            "원문 : man allegedly raped seven year old twin daughters months village meghalaya east hills district according reports received complaint rape family two victims twins taken hospital medical treatment examination police officials said officials added accused absconding \n",
            "실제 요약 : year old twin girls raped by step father for months \n",
            "예측 요약 :  man rapes year old girl in front of her rapes\n",
            "\n",
            "\n",
            "원문 : india ranked th countries inclusive internet index economist intelligence unit commissioned facebook sweden took first place followed singapore us scores index covered world population based scores availability relevance readiness categories \n",
            "실제 요약 : india ranks th on internet index facebook \n",
            "예측 요약 :  india named world most powerful indian companies\n",
            "\n",
            "\n",
            "원문 : team india opener shikhar dhawan thursday took instagram share picture wife wish birthday wish happy birthday love great one thanks making life complete pillar family shikhar wrote shikhar tied knot \n",
            "실제 요약 : thanks for making life complete dhawan wishes wife on day \n",
            "예측 요약 :  happy birthday wishes on day day birthday\n",
            "\n",
            "\n",
            "원문 : senior commander iran revolutionary guards brigadier general said threats us president donald trump country amount psychological warfare adding iran resist pressure enemies said never abandon revolutionary beliefs us wants nothing less destroy iran trump cannot damn thing \n",
            "실제 요약 : trump threats are psychological iran general \n",
            "예측 요약 :  iran has no right to iran leader iran\n",
            "\n",
            "\n",
            "원문 : questioning late actress sridevi honoured state funeral maharashtra navnirman sena chief raj thackeray said country body wrapped tricolour added nirav modi talk town issue sridevi came brought change issue \n",
            "실제 요약 : what did sridevi do that she was wrapped in tricolour mns \n",
            "예측 요약 :  he is the best of modi in gujarat bjp\n",
            "\n",
            "\n",
            "원문 : ride hailing startup ola tuesday announced investing million scooter rental startup adding scooters fleet investment would reportedly make ola largest shareholder holding stake founded anand balakrishnan mittal provides scooters rent bengaluru hyderabad \n",
            "실제 요약 : ola announces mn investment in scooter rental startup \n",
            "예측 요약 :  ola rival lyft raises million\n",
            "\n",
            "\n",
            "원문 : usa christian coleman broke year old world record metres sprint registering timing seconds us indoor national championships sunday former american sprinter greene held record seconds coleman metres silver medal last year world championships london \n",
            "실제 요약 : yr old runs in sec breaks yr old world record \n",
            "예측 요약 :  year old sets record for most sec in world record\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 회고, 토의  \n",
        "아무래도 우리말에 대한 자료는 한계가 있나보다. 결국 그냥 영어로 하고 있다. 얼마 전부터 lms의 코드를 거의 그대로 갖다 쓰고 있다. 추출적 요약의 경우 퍼실님께 미리 힌트를 받아서 전처리 전의 데이터를 그대로 \n",
        "\n",
        "원문 : indian spinner kuldeep yadav registered debut saturday said variation taught australian legend shane warne got david warner wicket international career first wicket kuldeep taken warne coach anil kumble session later australia matthew wade said yadav variations hard pick   \n",
        "실제 요약 : taught by warne got me warner wicket kuldeep   \n",
        "예측 요약 :  kuldeep yadav calls kuldeep yadav kuldeep yadav  \n",
        "추출적 요약 : At least one soldier was killed and three others   injured in a suspected IED explosion in Manipur's Tengnoupal district on Monday."
      ],
      "metadata": {
        "id": "o7H-UzpCDj3c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 지푸라기 잡는 식의 시도들 - to figure out the condition summarize work"
      ],
      "metadata": {
        "id": "XnvQhWrVsaqC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fodgglKyE_7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarize(texts,ratio=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XB30SGsIFBdn",
        "outputId": "49c7b920-ceb7-4452-f015-55c5d62c9588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts=lim_text[5]\n",
        "summ_extract=summarize(texts, ratio=100)\n",
        "print(texts)\n",
        "print(summ_extract)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f67_3irFC7O",
        "outputId": "5269c1b3-6cd1-457a-c518-2312ca8417c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "india recorded lowest odi total new zealand getting runs overs fourth odi hamilton thursday seven india batsmen dismissed single digit scores number ten batsman yuzvendra chahal top scored india previous lowest odi total new zealand\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lnwR0yamO58K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "outputId": "c3056395-e09a-493c-ec1a-b35c9ff64ab4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-76da98c404e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'summarize' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from summa.summarizer import summarize\n"
      ],
      "metadata": {
        "id": "0afHzkcGnIqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarize(temp_text,ratio=0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yKADixX_nV6i",
        "outputId": "8ccfd93b-09d3-4641-9434-63e81d183d8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"upGrad's Online Power Learning has powered 3 lakh+ careers.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk==3.6.5\n",
        "!pip install summa==1.2.0\n",
        "print(temp_text)\n",
        "print(preprocess_sentence(temp_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "id": "fueDTqtdnY-L",
        "outputId": "9fed8d18-5a9a-4533-a222-8c510a83c6b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nltk==3.6.5\n",
            "  Downloading nltk-3.6.5-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.5) (4.64.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.5) (2022.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.5) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.5) (1.1.0)\n",
            "Installing collected packages: nltk\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.7\n",
            "    Uninstalling nltk-3.7:\n",
            "      Successfully uninstalled nltk-3.7\n",
            "Successfully installed nltk-3.6.5\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting summa==1.2.0\n",
            "  Downloading summa-1.2.0.tar.gz (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.7/dist-packages (from summa==1.2.0) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy>=0.19->summa==1.2.0) (1.21.6)\n",
            "Building wheels for collected packages: summa\n",
            "  Building wheel for summa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for summa: filename=summa-1.2.0-py3-none-any.whl size=54412 sha256=9c2838f29a4445e12cbfc86512a7b22bdc61481cb1004070123922ec5fc7a16f\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/64/ac/7b443477588d365ef37ada30d456bdf5f07dc5be9f6324cb6e\n",
            "Successfully built summa\n",
            "Installing collected packages: summa\n",
            "Successfully installed summa-1.2.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-7d5c8aa9b66f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install nltk==3.6.5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install summa==1.2.0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'temp_text' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summarize(\"\"\"saurav kant, an alumnus upgrad program of machine learning artificial intelligence of sr systems engineer providing infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers\n",
        "\"\"\",words=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0RTnp8eQnkIz",
        "outputId": "be4e4f00-66be-4f38-c24a-c2f407223a24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range (1,375):\n",
        "    summarized=summarize(temp_text[:189],words=i)\n",
        "    if len(summarized)>0:\n",
        "        print('words=', i)\n",
        "        print(summarized)\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJHcVzTInsgA",
        "outputId": "1fde4357-5724-4962-fc92-1b38e601dbbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "words= 15\n",
            "Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(temp_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQplhXVypXdA",
        "outputId": "512637a4-4b11-48b8-aad3-c63e8540cefb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "375"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(temp_text[:189])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7sc0SzLpmlh",
        "outputId": "9e65b057-d5b6-453c-d988-47ff5690d68c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The p\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aa=preprocess_sentence(temp_text)\n",
        "aa='''india recorded lowest odi total new zealand getting runs overs fourth odi hamilton thursday seven india batsmen dismissed single digit scores number ten batsman yuzvendra chahal top scored india previous lowest odi Total new zealand'''\n",
        "for i in range (1,375):\n",
        "#    summarized=summarize(aa+'. The E',words=i)\n",
        "    summarized=summarize(aa,words=i)\n",
        "    if len(summarized)>0:\n",
        "        print('words=', i)\n",
        "        print(summarized)\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fovZxEo1p1tM",
        "outputId": "3aceb96c-2ed5-41a0-bd61-c6695eb5447b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "words= 8\n",
            "india recorded lowest odi total new zealand getting runs overs fourth odi hamilton thursday seven.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(aa)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8HtnSiTqRC_",
        "outputId": "e83a4fcf-a5ac-43a6-af89-ad427b1814f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "onWgK-I7qa5O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}