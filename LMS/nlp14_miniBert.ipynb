{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chhyyi/aiffel/blob/main/LMS/nlp14_miniBert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dab3bf15",
      "metadata": {
        "id": "dab3bf15"
      },
      "source": [
        "# mini BERT project\n",
        "this notebook is part of submission of MODULAB's AIFFEL LMS NLP Node 14\n",
        "\n",
        "Build mini BERT with vocab size 8000, ~1Million parameter, train for 10 epochs\n",
        "\n",
        "# 토크나이저 준비하기\n",
        "vocab size의 변경 : spm.SentencePieceProcessor()의 서브클래스를 생성합니다.   \n",
        "\n",
        "- encode_as_ids 의 결과 중 vocab_size 이상을 unk token으로 바꾸는 메소드 생성 (piece='[UNK]', id=1)\n",
        "- 조금 느리겠지만 decode, encode는 훈련과정중 반복되지 않으므로 괜찮습니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "import shutil\n",
        "import zipfile\n",
        "import copy\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "sFuhJLgchmRJ"
      },
      "id": "sFuhJLgchmRJ",
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnT9UaQOauw5",
        "outputId": "59f4de0a-ba8f-4e42-c198-a0f2cac07955"
      },
      "id": "TnT9UaQOauw5",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92WUkbKfdpsw",
        "outputId": "c51bf256-317d-4de2-8678-d453e63411ea"
      },
      "id": "92WUkbKfdpsw",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.97)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "16713e91",
      "metadata": {
        "id": "16713e91"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "import re\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import collections\n",
        "import json\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import sentencepiece as spm\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "021361ca",
      "metadata": {
        "id": "021361ca"
      },
      "outputs": [],
      "source": [
        "corpus_file = '/content/drive/MyDrive/colabdata/modulabs/nlp14/kowiki.txt'\n",
        "f=open(corpus_file, 'r')\n",
        "corpus_namu=f.readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "9621535a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9621535a",
        "outputId": "ed86f80a-4c1e-44ce-ec63-20dd9d016ef1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "/device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "random_seed = 1234\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "tf.random.set_seed(random_seed)\n",
        "\n",
        "# tf version 및 gpu 확인\n",
        "print(tf.__version__)\n",
        "print(tf.config.list_physical_devices('GPU'))\n",
        "print(tf.test.gpu_device_name())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "4786e3ca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4786e3ca",
        "outputId": "f0b7e99d-17ea-480c-e3cd-e7be9eb1474c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "data_dir = '/content/drive/MyDrive/colabdata/modulabs/nlp14'\n",
        "model_dir = '/content/drive/MyDrive/colabdata/modulabs/nlp14'\n",
        "\n",
        "vocab = spm.SentencePieceProcessor()\n",
        "vocab.load(f\"{model_dir}/ko_32000.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "2f5f7d3e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2f5f7d3e",
        "outputId": "5bb9bd73-ef67-450c-8206-a88675b3f9df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[BOS]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "vocab.id_to_piece(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "bcc569a1",
      "metadata": {
        "id": "bcc569a1"
      },
      "outputs": [],
      "source": [
        "class SPMWithLimitedVocab(spm.SentencePieceProcessor):\n",
        "    def __init__(self, vocab_size):\n",
        "        spm.SentencePieceProcessor.__init__(self)\n",
        "        self.vocab_size=vocab_size\n",
        "    \n",
        "    def limited_encode_as_ids(self, s):\n",
        "        ids=self.encode_as_ids(s)\n",
        "        ids=[i if i<=self.vocab_size else 1 for i in ids]\n",
        "        return ids\n",
        "\n",
        "    def limited_vocab_to_id(self, id):\n",
        "        if id<=self.vocab_size:\n",
        "            return self.vocab_to_id(id)\n",
        "        else:\n",
        "            return 1\n",
        "    \n",
        "    def limited_id_to_piece(self, id):\n",
        "        if id<=self.vocab_size:\n",
        "            return self.id_to_piece(id)\n",
        "        else:\n",
        "            return self.id_to_piece(1) #'unk' id\n",
        "    \n",
        "    def limited_piece_to_id(self, piece):\n",
        "        pi_=self.piece_to_id(piece)\n",
        "        if pi_<=self.vocab_size:\n",
        "            return pi_\n",
        "        else:\n",
        "            return 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "25937076",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "25937076",
        "outputId": "9de1bc55-15f1-4f62-be52-96b2fb52956d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'▁반복'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "vocab.IdToPiece(3901)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "60261d61",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60261d61",
        "outputId": "ebe5c19a-512a-445e-f89d-39de164ff2a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "vocab_size=8007\n",
        "vocab = SPMWithLimitedVocab(vocab_size)\n",
        "vocab.load(f\"{model_dir}/ko_32000.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "29a7ebba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29a7ebba",
        "outputId": "82cdce89-529d-4efa-c764-98bedeb12f88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 207, 4612, 5551, 1, 630, 1, 4269, 429, 5346, 1, 1, 1605, 1, 5551, 1, 1, 1, 1, 13, 81, 1, 2247, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1232, 1, 1, 4777, 1, 243, 2780, 14, 1509, 1, 414, 165, 1697, 1, 1, 1, 1, 593, 21, 1, 399, 5540, 813, 17, 1, 307, 1, 103, 1, 1, 1, 1, 98, 1, 1, 2543, 309, 337, 5771, 1, 1, 4578, 1]\n"
          ]
        }
      ],
      "source": [
        "print(vocab.limited_encode_as_ids(corpus_namu[2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "6313d638",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6313d638",
        "outputId": "f014b429-0c3a-4ce8-c79b-0855ab4a4b75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[16415, 207, 4612, 5551, 27646, 630, 27714, 4269, 429, 5346, 27626, 14406, 1605, 27599, 5551, 14146, 15991, 8637, 27599, 13, 81, 25987, 2247, 15033, 27873, 14475, 27813, 27873, 28196, 27636, 10185, 16285, 1232, 22935, 27599, 4777, 27625, 243, 2780, 14, 1509, 22095, 414, 165, 1697, 28290, 27873, 27703, 27683, 593, 21, 29007, 399, 5540, 813, 17, 27599, 307, 16905, 103, 28313, 28290, 19041, 27718, 98, 27878, 15784, 2543, 309, 337, 5771, 27616, 27603, 4578, 27599]\n"
          ]
        }
      ],
      "source": [
        "print(vocab.encode_as_ids(corpus_namu[2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e30b241",
      "metadata": {
        "id": "7e30b241"
      },
      "source": [
        "8000을 넘는 인덱스는 unk로 바뀌어 있슴을 확인할 수 있습니다.\n",
        "\n",
        "# 2-4 전처리, 데이터셋 완성\n",
        "__Mask 처리하기 / NSP페어 생성__\n",
        "전체 중 15%의 토큰에 Mask 처리를 합니다. 이 작업은 SentencePiece의 토큰(piece)이 아니라 띄어쓰기된 단어 단위로 수행합니다. 한 단어 내의 토큰들을 80% 확률로 mask, 10% 확률로 임의의 토큰으로 바꾸고, 10% 확률로 원래 토큰을 남깁니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "336eab77",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "336eab77",
        "outputId": "f64ff308-9f11-45e1-9865-2b88e47def6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['▁지미', '▁카', '터는', '▁조지아', '주', '▁섬', '터', '▁카운티', '▁플', '레인', '스', '▁마을에서', '▁태어났다', '.', '▁조지아', '▁공과', '대학교를', '▁졸업하였다', '.', '▁그', '▁후', '▁해군에', '▁들어가', '▁전함', '·', '원자', '력', '·', '잠', '수', '함의', '▁승무', '원으로', '▁일하였다', '.', '▁1953', '년', '▁미국', '▁해군', '▁대', '위로', '▁예편', '하였고', '▁이후', '▁땅', '콩', '·', '면', '화', '▁등을', '▁가', '꿔', '▁많은', '▁돈을', '▁벌', '었다', '.', '▁그의', '▁별명이', '▁\"', '땅', '콩', '▁농부', '\"', '▁(', 'P', 'ean', 'ut', '▁F', 'ar', 'mer', ')', '로', '▁알려졌다', '.']\n"
          ]
        }
      ],
      "source": [
        "_=vocab.encode_as_pieces(corpus_namu[2])\n",
        "print(_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "ee26cedf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee26cedf",
        "outputId": "921f0719-72b5-4bfa-a4de-ff51477dd72d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'\\\\u2581\\\\uc9c0\\\\ubbf8' ▁지미\n",
            "b'\\\\u2581\\\\uce74' ▁카\n",
            "b'\\\\ud130\\\\ub294' 터는\n",
            "b'\\\\u2581\\\\uc870\\\\uc9c0\\\\uc544' ▁조지아\n",
            "b'\\\\uc8fc' 주\n"
          ]
        }
      ],
      "source": [
        "for i in _[:5]:\n",
        "    print(i.encode('raw_unicode_escape'), i)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0adf08e2",
      "metadata": {
        "id": "0adf08e2"
      },
      "source": [
        "띄어쓰기 후 새로운 단어의 시작을 뜻하는 언더바 기호는 b'\\\\u2581'입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "0af95849",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0af95849",
        "outputId": "dfe15637-67f4-4d80-f49c-9a41b36f2363"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▁지미\n",
            "▁카\n",
            "▁조지아\n"
          ]
        }
      ],
      "source": [
        "for i in _[:5]:\n",
        "    if i.startswith(u'\\u2581'):\n",
        "        print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2c30463",
      "metadata": {
        "id": "f2c30463"
      },
      "source": [
        "그런데 이것은 make_pretrain_data(), create_pretrain_instances() 등 함수로 만들어져 있으니 이걸 씁니다.\n",
        "memmap을 이용해 데이터를 불러오는 함수도 가져옵니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "b2db6c24",
      "metadata": {
        "id": "b2db6c24"
      },
      "outputs": [],
      "source": [
        "def create_pretrain_mask(tokens, mask_cnt, vocab_list):\n",
        "    \"\"\"\n",
        "    마스크 생성\n",
        "    :param tokens: tokens\n",
        "    :param mask_cnt: mask 개수 (전체 tokens의 15%)\n",
        "    :param vocab_list: vocab list (random token 용)\n",
        "    :return tokens: mask된 tokens\n",
        "    :return mask_idx: mask된 token의 index\n",
        "    :return mask_label: mask된 token의 원래 값\n",
        "    \"\"\"\n",
        "    # 단어 단위로 mask 하기 위해서 index 분할\n",
        "    cand_idx = []  # word 단위의 index array\n",
        "    for (i, token) in enumerate(tokens):\n",
        "        if token == \"[CLS]\" or token == \"[SEP]\":\n",
        "            continue\n",
        "        if 0 < len(cand_idx) and not token.startswith(u\"\\u2581\"):\n",
        "            cand_idx[-1].append(i)\n",
        "        else:\n",
        "            cand_idx.append([i])\n",
        "    # random mask를 위해서 순서를 섞음\n",
        "    random.shuffle(cand_idx)\n",
        "\n",
        "    mask_lms = []  # mask 된 값\n",
        "    for index_set in cand_idx:\n",
        "        if len(mask_lms) >= mask_cnt:  # 핸재 mask된 개수가 15%를 넘으면 중지\n",
        "            break\n",
        "        if len(mask_lms) + len(index_set) > mask_cnt:  # 이번에 mask할 개수를 포함해 15%를 넘으면 skip\n",
        "            continue\n",
        "        dice = random.random()  # 0..1 사이의 확률 값\n",
        "        for index in index_set:\n",
        "            masked_token = None\n",
        "            if dice < 0.8:  # 80% replace with [MASK]\n",
        "                masked_token = \"[MASK]\"\n",
        "            elif dice < 0.9: # 10% keep original\n",
        "                masked_token = tokens[index]\n",
        "            else:  # 10% random word\n",
        "                masked_token = random.choice(vocab_list)\n",
        "            mask_lms.append({\"index\": index, \"label\": tokens[index]})\n",
        "            tokens[index] = masked_token\n",
        "    # mask_lms 정렬 후 mask_idx, mask_label 추출\n",
        "    mask_lms = sorted(mask_lms, key=lambda x: x[\"index\"])\n",
        "    mask_idx = [p[\"index\"] for p in mask_lms]  # mask된 token의 index\n",
        "    mask_label = [p[\"label\"] for p in mask_lms]  # mask된 token의 원래 값\n",
        "\n",
        "    return tokens, mask_idx, mask_label\n",
        "\n",
        "def trim_tokens(tokens_a, tokens_b, max_seq):\n",
        "    \"\"\"\n",
        "    tokens_a, tokens_b의 길이를 줄임 최대 길이: max_seq\n",
        "    :param tokens_a: tokens A\n",
        "    :param tokens_b: tokens B\n",
        "    :param max_seq: 두 tokens 길이의 최대 값\n",
        "    \"\"\"\n",
        "    while True:\n",
        "        total_length = len(tokens_a) + len(tokens_b)\n",
        "        if total_length <= max_seq:\n",
        "            break\n",
        "\n",
        "        if len(tokens_a) > len(tokens_b):\n",
        "            del tokens_a[0]\n",
        "        else:\n",
        "            tokens_b.pop()\n",
        "\n",
        "def create_pretrain_instances(vocab, doc, n_seq, mask_prob, vocab_list):\n",
        "    \"\"\"\n",
        "    doc별 pretrain 데이터 생성\n",
        "    \"\"\"\n",
        "    # for CLS], [SEP], [SEP]\n",
        "    max_seq = n_seq - 3\n",
        "\n",
        "    instances = []\n",
        "    current_chunk = []\n",
        "    current_length = 0\n",
        "    for i in range(len(doc)):\n",
        "        current_chunk.append(doc[i])  # line\n",
        "        current_length += len(doc[i])\n",
        "        if 1 < len(current_chunk) and (i == len(doc) - 1 or current_length >= max_seq):\n",
        "            # token a\n",
        "            a_end = 1\n",
        "            if 1 < len(current_chunk):\n",
        "                a_end = random.randrange(1, len(current_chunk))\n",
        "            tokens_a = []\n",
        "            for j in range(a_end):\n",
        "                tokens_a.extend(current_chunk[j])\n",
        "            # token b\n",
        "            tokens_b = []\n",
        "            for j in range(a_end, len(current_chunk)):\n",
        "                tokens_b.extend(current_chunk[j])\n",
        "\n",
        "            if random.random() < 0.5:  # 50% 확률로 swap\n",
        "                is_next = 0\n",
        "                tokens_t = tokens_a\n",
        "                tokens_a = tokens_b\n",
        "                tokens_b = tokens_t\n",
        "            else:\n",
        "                is_next = 1\n",
        "            # max_seq 보다 큰 경우 길이 조절\n",
        "            trim_tokens(tokens_a, tokens_b, max_seq)\n",
        "            assert 0 < len(tokens_a)\n",
        "            assert 0 < len(tokens_b)\n",
        "            # tokens & aegment 생성\n",
        "            tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"] + tokens_b + [\"[SEP]\"]\n",
        "            segment = [0] * (len(tokens_a) + 2) + [1] * (len(tokens_b) + 1)\n",
        "            # mask\n",
        "            tokens, mask_idx, mask_label = create_pretrain_mask(tokens, int((len(tokens) - 3) * mask_prob), vocab_list)\n",
        "\n",
        "            instance = {\n",
        "                \"tokens\": tokens,\n",
        "                \"segment\": segment,\n",
        "                \"is_next\": is_next,\n",
        "                \"mask_idx\": mask_idx,\n",
        "                \"mask_label\": mask_label\n",
        "            }\n",
        "            instances.append(instance)\n",
        "\n",
        "            current_chunk = []\n",
        "            current_length = 0\n",
        "    return instances\n",
        "\n",
        "def make_pretrain_data(vocab, in_file, out_file, n_seq, mask_prob=0.15, vocab_size=vocab_size):\n",
        "    \"\"\" pretrain 데이터 생성 \"\"\"\n",
        "    def save_pretrain_instances(out_f, doc):\n",
        "        instances = create_pretrain_instances(vocab, doc, n_seq, mask_prob, vocab_list)\n",
        "        for instance in instances:\n",
        "            out_f.write(json.dumps(instance, ensure_ascii=False))\n",
        "            out_f.write(\"\\n\")\n",
        "\n",
        "    # 특수문자 7개를 제외한 vocab_list 생성\n",
        "    vocab_list = []\n",
        "    for id in range(7, vocab_size):\n",
        "        if not vocab.is_unknown(id) :        # 생성되는 단어 목록이 unknown인 경우는 제거합니다. \n",
        "            vocab_list.append(vocab.limited_id_to_piece(id))\n",
        "\n",
        "    # line count 확인\n",
        "    line_cnt = 0\n",
        "    with open(in_file, \"r\") as in_f:\n",
        "        for line in in_f:\n",
        "            line_cnt += 1\n",
        "\n",
        "    with open(in_file, \"r\") as in_f:\n",
        "        with open(out_file, \"w\") as out_f:\n",
        "            doc = []\n",
        "            for line in tqdm(in_f, total=line_cnt):\n",
        "                line = line.strip()\n",
        "                if line == \"\":  # line이 빈줄 일 경우 (새로운 단락)\n",
        "                    if 0 < len(doc):\n",
        "                        save_pretrain_instances(out_f, doc)\n",
        "                        doc = []\n",
        "                else:  # line이 빈줄이 아닐 경우 tokenize 해서 doc에 저장\n",
        "                    pieces = vocab.encode_as_pieces(line)\n",
        "                    if 0 < len(pieces):\n",
        "                        doc.append(pieces)\n",
        "            if 0 < len(doc):  # 마지막에 처리되지 않은 doc가 있는 경우\n",
        "                save_pretrain_instances(out_f, doc)\n",
        "                doc = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "e261da17",
      "metadata": {
        "id": "e261da17"
      },
      "outputs": [],
      "source": [
        "def load_pre_train_data(vocab, filename, n_seq, count=None):\n",
        "    \"\"\"\n",
        "    학습에 필요한 데이터를 로드\n",
        "    :param vocab: vocab\n",
        "    :param filename: 전처리된 json 파일\n",
        "    :param n_seq: 시퀀스 길이 (number of sequence)\n",
        "    :param count: 데이터 수 제한 (None이면 전체)\n",
        "    :return enc_tokens: encoder inputs\n",
        "    :return segments: segment inputs\n",
        "    :return labels_nsp: nsp labels\n",
        "    :return labels_mlm: mlm labels\n",
        "    \"\"\"\n",
        "    total = 0\n",
        "    with open(filename, \"r\") as f:\n",
        "        for line in f:\n",
        "            total += 1\n",
        "            # 데이터 수 제한\n",
        "            if count is not None and count <= total:\n",
        "                break\n",
        "    \n",
        "    # np.memmap을 사용하면 메모리를 적은 메모리에서도 대용량 데이터 처리가 가능 함\n",
        "    enc_tokens = np.memmap(filename='enc_tokens.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
        "    segments = np.memmap(filename='segments.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
        "    labels_nsp = np.memmap(filename='labels_nsp.memmap', mode='w+', dtype=np.int32, shape=(total,))\n",
        "    labels_mlm = np.memmap(filename='labels_mlm.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
        "\n",
        "    with open(filename, \"r\") as f:\n",
        "        for i, line in enumerate(tqdm(f, total=total)):\n",
        "            if total <= i:\n",
        "                print(\"data load early stop\", total, i)\n",
        "                break\n",
        "            data = json.loads(line)\n",
        "            # encoder token\n",
        "            enc_token = [vocab.limited_piece_to_id(p) for p in data[\"tokens\"]]\n",
        "            enc_token += [0] * (n_seq - len(enc_token))\n",
        "            # segment\n",
        "            segment = data[\"segment\"]\n",
        "            segment += [0] * (n_seq - len(segment))\n",
        "            # nsp label\n",
        "            label_nsp = data[\"is_next\"]\n",
        "            # mlm label\n",
        "            mask_idx = np.array(data[\"mask_idx\"], dtype=np.int)\n",
        "            mask_label = np.array([vocab.limited_piece_to_id(p) for p in data[\"mask_label\"]], dtype=np.int)\n",
        "            label_mlm = np.full(n_seq, dtype=np.int, fill_value=0)\n",
        "            label_mlm[mask_idx] = mask_label\n",
        "\n",
        "            assert len(enc_token) == len(segment) == len(label_mlm) == n_seq\n",
        "\n",
        "            enc_tokens[i] = enc_token\n",
        "            segments[i] = segment\n",
        "            labels_nsp[i] = label_nsp\n",
        "            labels_mlm[i] = label_mlm\n",
        "\n",
        "    return (enc_tokens, segments), (labels_nsp, labels_mlm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "5c59dc09",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "6a7c018e3e644c0ea505686ac1603829",
            "649ccbb67ec24d1f8c03447e65d89f50",
            "efd0e90f3e214d1aa9f15e16ed4da740",
            "35210d30554149e2a93fc3a8d1ef4051",
            "831f5c35025d445e85005087aae81d64",
            "291e4695615746f091194d368b6f9eeb",
            "88afdb0a8e9d4184bbaab8df451d82b4",
            "f1ecf3cb42bb40abb2bd340cfb1874ca",
            "a7ee517cd7e54a5cb0f146339cfc5f68",
            "0fa74f6df085440981892171ca30e66f",
            "ffef7ddd92154e09aa4269b8b53b332e"
          ]
        },
        "id": "5c59dc09",
        "outputId": "653738ae-20d3-4702-96c2-b4262294a88b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3957761 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a7c018e3e644c0ea505686ac1603829"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "pretrain_json_path = '/content/drive/MyDrive/colabdata/modulabs/nlp14/bert_pre_train.json'\n",
        "\n",
        "make_pretrain_data(vocab, corpus_file, pretrain_json_path, 128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "d4c8dd0f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178,
          "referenced_widgets": [
            "0d981df302cf42058ee08090166a0eca",
            "1e2682671554409cb6ae2af59d6fddd8",
            "1d2c79e990da48e1bb154c5b55e5a048",
            "d629305aa7bd43a6ae00b08d46a1ce0a",
            "faccb773fe7e4f4f893e36ded9cb9c89",
            "4c2aab6af42f43a98a69f1bd9fe816d2",
            "6e60c7e13fe142a796581caa74cd4ad6",
            "4cb6a689bf864527b0ace28f1fc5efc5",
            "699a9aad6fd340d19fa5d9bb471fbff3",
            "32c7d7bcbd974fc78be2f7fdecd8e749",
            "6df43d58ab6744d1bbeecbb99e490de7"
          ]
        },
        "id": "d4c8dd0f",
        "outputId": "a81b827f-175c-416e-8f75-ced806b7ae31"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/862285 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d981df302cf42058ee08090166a0eca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        }
      ],
      "source": [
        "# 전체 데이터 메모리에 로딩\n",
        "pre_train_inputs, pre_train_labels = load_pre_train_data(vocab, pretrain_json_path, 128, count=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4b0ab1f",
      "metadata": {
        "id": "a4b0ab1f"
      },
      "source": [
        "# Bert 모델 구현\n",
        "\n",
        "> pad mask, ahead mask 함수, gelu activation 함수, parameter initializer 생성 함수, json을 config 형태로 사용하기 위한 유틸리티 함수를 먼저 만들어 두세요.\n",
        "\n",
        "이것도 노드에서 가져옵니다.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "4d1c8910",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d1c8910",
        "outputId": "b47d20de-539c-40e5-cdfd-e6d9da2c5405"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝=3\n"
          ]
        }
      ],
      "source": [
        "def get_pad_mask(tokens, i_pad=0):\n",
        "    \"\"\"\n",
        "    pad mask 계산하는 함수\n",
        "    :param tokens: tokens (bs, n_seq)\n",
        "    :param i_pad: id of pad\n",
        "    :return mask: pad mask (pad: 1, other: 0)\n",
        "    \"\"\"\n",
        "    mask = tf.cast(tf.math.equal(tokens, i_pad), tf.float32)\n",
        "    mask = tf.expand_dims(mask, axis=1)\n",
        "    return mask\n",
        "\n",
        "\n",
        "def get_ahead_mask(tokens, i_pad=0):\n",
        "    \"\"\"\n",
        "    ahead mask 계산하는 함수\n",
        "    :param tokens: tokens (bs, n_seq)\n",
        "    :param i_pad: id of pad\n",
        "    :return mask: ahead and pad mask (ahead or pad: 1, other: 0)\n",
        "    \"\"\"\n",
        "    n_seq = tf.shape(tokens)[1]\n",
        "    ahead_mask = 1 - tf.linalg.band_part(tf.ones((n_seq, n_seq)), -1, 0)\n",
        "    ahead_mask = tf.expand_dims(ahead_mask, axis=0)\n",
        "    pad_mask = get_pad_mask(tokens, i_pad)\n",
        "    mask = tf.maximum(ahead_mask, pad_mask)\n",
        "    return mask\n",
        "print(\"슝=3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "f620050f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f620050f",
        "outputId": "fa829240-da67-4252-aa73-62e7b27be1ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝=3\n"
          ]
        }
      ],
      "source": [
        "@tf.function(experimental_relax_shapes=True)\n",
        "def gelu(x):\n",
        "    \"\"\"\n",
        "    gelu activation 함수\n",
        "    :param x: 입력 값\n",
        "    :return: gelu activation result\n",
        "    \"\"\"\n",
        "    return 0.5*x*(1+tf.tanh(np.sqrt(2/np.pi)*(x+0.044715*tf.pow(x, 3))))\n",
        "\n",
        "print(\"슝=3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "9c89e393",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c89e393",
        "outputId": "b268f93b-7f6a-4ee2-94af-3c729b7706d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝=3\n"
          ]
        }
      ],
      "source": [
        "def kernel_initializer(stddev=0.02):\n",
        "    \"\"\"\n",
        "    parameter initializer 생성\n",
        "    :param stddev: 생성할 랜덤 변수의 표준편차\n",
        "    \"\"\"\n",
        "    return tf.keras.initializers.TruncatedNormal(stddev=stddev)\n",
        "\n",
        "\n",
        "def bias_initializer():\n",
        "    \"\"\"\n",
        "    bias initializer 생성\n",
        "    \"\"\"\n",
        "    return tf.zeros_initializer\n",
        "print(\"슝=3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "47256bac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47256bac",
        "outputId": "76c8968d-1520-4ab7-f905-ad916953e1b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝=3\n"
          ]
        }
      ],
      "source": [
        "class Config(dict):\n",
        "    \"\"\"\n",
        "    json을 config 형태로 사용하기 위한 Class\n",
        "    :param dict: config dictionary\n",
        "    \"\"\"\n",
        "    __getattr__ = dict.__getitem__\n",
        "    __setattr__ = dict.__setitem__\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, file):\n",
        "        \"\"\"\n",
        "        file에서 Config를 생성 함\n",
        "        :param file: filename\n",
        "        \"\"\"\n",
        "        with open(file, 'r') as f:\n",
        "            config = json.loads(f.read())\n",
        "            return Config(config)\n",
        "print(\"슝=3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e584f512",
      "metadata": {
        "id": "e584f512"
      },
      "source": [
        "Bert model 역시 노드에서 옮겨옵니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "4140aad2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4140aad2",
        "outputId": "ec0b7841-a057-4f78-cdf6-30beda45abf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝=3\n"
          ]
        }
      ],
      "source": [
        "class SharedEmbedding(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Weighed Shaed Embedding Class\n",
        "    \"\"\"\n",
        "    def __init__(self, config, name=\"weight_shared_embedding\"):\n",
        "        \"\"\"\n",
        "        생성자\n",
        "        :param config: Config 객체\n",
        "        :param name: layer name\n",
        "        \"\"\"\n",
        "        super().__init__(name=name)\n",
        "\n",
        "        self.n_vocab = config.n_vocab\n",
        "        self.d_model = config.d_model\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        \"\"\"\n",
        "        shared weight 생성\n",
        "        :param input_shape: Tensor Shape (not used)\n",
        "        \"\"\"\n",
        "        with tf.name_scope(\"shared_embedding_weight\"):\n",
        "            self.shared_weights = self.add_weight(\n",
        "                \"weights\",\n",
        "                shape=[self.n_vocab, self.d_model],\n",
        "                initializer=kernel_initializer()\n",
        "            )\n",
        "\n",
        "    def call(self, inputs, mode=\"embedding\"):\n",
        "        \"\"\"\n",
        "        layer 실행\n",
        "        :param inputs: 입력\n",
        "        :param mode: 실행 모드\n",
        "        :return: embedding or linear 실행 결과\n",
        "        \"\"\"\n",
        "        # mode가 embedding일 경우 embedding lookup 실행\n",
        "        if mode == \"embedding\":\n",
        "            return self._embedding(inputs)\n",
        "        # mode가 linear일 경우 linear 실행\n",
        "        elif mode == \"linear\":\n",
        "            return self._linear(inputs)\n",
        "        # mode가 기타일 경우 오류 발생\n",
        "        else:\n",
        "            raise ValueError(f\"mode {mode} is not valid.\")\n",
        "    \n",
        "    def _embedding(self, inputs):\n",
        "        \"\"\"\n",
        "        embedding lookup\n",
        "        :param inputs: 입력\n",
        "        \"\"\"\n",
        "        embed = tf.gather(self.shared_weights, tf.cast(inputs, tf.int32))\n",
        "        return embed\n",
        "\n",
        "    def _linear(self, inputs):  # (bs, n_seq, d_model)\n",
        "        \"\"\"\n",
        "        linear 실행\n",
        "        :param inputs: 입력\n",
        "        \"\"\"\n",
        "        n_batch = tf.shape(inputs)[0]\n",
        "        n_seq = tf.shape(inputs)[1]\n",
        "        inputs = tf.reshape(inputs, [-1, self.d_model])  # (bs * n_seq, d_model)\n",
        "        outputs = tf.matmul(inputs, self.shared_weights, transpose_b=True)\n",
        "        outputs = tf.reshape(outputs, [n_batch, n_seq, self.n_vocab])  # (bs, n_seq, n_vocab)\n",
        "        return outputs\n",
        "print(\"슝=3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "c6a6b1bb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6a6b1bb",
        "outputId": "8c704db3-8535-4d7c-9fcb-65f9d5f4fbf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝=3\n"
          ]
        }
      ],
      "source": [
        "class PositionEmbedding(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Position Embedding Class\n",
        "    \"\"\"\n",
        "    def __init__(self, config, name=\"position_embedding\"):\n",
        "        \"\"\"\n",
        "        생성자\n",
        "        :param config: Config 객체\n",
        "        :param name: layer name\n",
        "        \"\"\"\n",
        "        super().__init__(name=name)\n",
        "        \n",
        "        self.embedding = tf.keras.layers.Embedding(config.n_seq, config.d_model, embeddings_initializer=kernel_initializer())\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        layer 실행\n",
        "        :param inputs: 입력\n",
        "        :return embed: position embedding lookup 결과\n",
        "        \"\"\"\n",
        "        position = tf.cast(tf.math.cumsum(tf.ones_like(inputs), axis=1, exclusive=True), tf.int32)\n",
        "        embed = self.embedding(position)\n",
        "        return embed\n",
        "print(\"슝=3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "9335478c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9335478c",
        "outputId": "42ce0e4f-d134-43b3-bebd-159684c6522f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝=3\n"
          ]
        }
      ],
      "source": [
        "class ScaleDotProductAttention(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Scale Dot Product Attention Class\n",
        "    \"\"\"\n",
        "    def __init__(self, name=\"scale_dot_product_attention\"):\n",
        "        \"\"\"\n",
        "        생성자\n",
        "        :param name: layer name\n",
        "        \"\"\"\n",
        "        super().__init__(name=name)\n",
        "\n",
        "    def call(self, Q, K, V, attn_mask):\n",
        "        \"\"\"\n",
        "        layer 실행\n",
        "        :param Q: Q value\n",
        "        :param K: K value\n",
        "        :param V: V value\n",
        "        :param attn_mask: 실행 모드\n",
        "        :return attn_out: attention 실행 결과\n",
        "        \"\"\"\n",
        "        attn_score = tf.matmul(Q, K, transpose_b=True)\n",
        "        scale = tf.math.sqrt(tf.cast(tf.shape(K)[-1], tf.float32))\n",
        "        attn_scale = tf.math.divide(attn_score, scale)\n",
        "        attn_scale -= 1.e9 * attn_mask\n",
        "        attn_prob = tf.nn.softmax(attn_scale, axis=-1)\n",
        "        attn_out = tf.matmul(attn_prob, V)\n",
        "        return attn_out\n",
        "print(\"슝=3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "6614bf8f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6614bf8f",
        "outputId": "bb55d49d-67e5-4fb5-b29e-01864c107ab2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝=3\n"
          ]
        }
      ],
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Multi Head Attention Class\n",
        "    \"\"\"\n",
        "    def __init__(self, config, name=\"multi_head_attention\"):\n",
        "        \"\"\"\n",
        "        생성자\n",
        "        :param config: Config 객체\n",
        "        :param name: layer name\n",
        "        \"\"\"\n",
        "        super().__init__(name=name)\n",
        "\n",
        "        self.d_model = config.d_model\n",
        "        self.n_head = config.n_head\n",
        "        self.d_head = config.d_head\n",
        "\n",
        "        # Q, K, V input dense layer\n",
        "        self.W_Q = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
        "        self.W_K = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
        "        self.W_V = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
        "        # Scale Dot Product Attention class\n",
        "        self.attention = ScaleDotProductAttention(name=\"self_attention\")\n",
        "        # output dense layer\n",
        "        self.W_O = tf.keras.layers.Dense(config.d_model, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
        "\n",
        "    def call(self, Q, K, V, attn_mask):\n",
        "        \"\"\"\n",
        "        layer 실행\n",
        "        :param Q: Q value\n",
        "        :param K: K value\n",
        "        :param V: V value\n",
        "        :param attn_mask: 실행 모드\n",
        "        :return attn_out: attention 실행 결과\n",
        "        \"\"\"\n",
        "        # reshape Q, K, V, attn_mask\n",
        "        batch_size = tf.shape(Q)[0]\n",
        "        Q_m = tf.transpose(tf.reshape(self.W_Q(Q), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, Q_len, d_head)\n",
        "        K_m = tf.transpose(tf.reshape(self.W_K(K), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, K_len, d_head)\n",
        "        V_m = tf.transpose(tf.reshape(self.W_V(V), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, K_len, d_head)\n",
        "        attn_mask_m = tf.expand_dims(attn_mask, axis=1)\n",
        "        # Scale Dot Product Attention with multi head Q, K, V, attn_mask\n",
        "        attn_out = self.attention(Q_m, K_m, V_m, attn_mask_m)  # (bs, n_head, Q_len, d_head)\n",
        "        # transpose and liner\n",
        "        attn_out_m = tf.transpose(attn_out, perm=[0, 2, 1, 3])  # (bs, Q_len, n_head, d_head)\n",
        "        attn_out = tf.reshape(attn_out_m, [batch_size, -1, config.n_head * config.d_head])  # (bs, Q_len, d_model)\n",
        "        attn_out = self.W_O(attn_out) # (bs, Q_len, d_model)\n",
        "\n",
        "        return attn_out\n",
        "print(\"슝=3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "bfc03ca6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfc03ca6",
        "outputId": "6d06c74c-f648-4b3f-9156-292f8fb73fb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝=3\n"
          ]
        }
      ],
      "source": [
        "class PositionWiseFeedForward(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Position Wise Feed Forward Class\n",
        "    \"\"\"\n",
        "    def __init__(self, config, name=\"feed_forward\"):\n",
        "        \"\"\"\n",
        "        생성자\n",
        "        :param config: Config 객체\n",
        "        :param name: layer name\n",
        "        \"\"\"\n",
        "        super().__init__(name=name)\n",
        "\n",
        "        self.W_1 = tf.keras.layers.Dense(config.d_ff, activation=gelu, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
        "        self.W_2 = tf.keras.layers.Dense(config.d_model, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        layer 실행\n",
        "        :param inputs: inputs\n",
        "        :return ff_val: feed forward 실행 결과\n",
        "        \"\"\"\n",
        "        ff_val = self.W_2(self.W_1(inputs))\n",
        "        return ff_val\n",
        "print(\"슝=3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "086a4e45",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "086a4e45",
        "outputId": "bd6f4827-52e3-471b-b1e2-0e9b8e7a8116"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝=3\n"
          ]
        }
      ],
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Encoder Layer Class\n",
        "    \"\"\"\n",
        "    def __init__(self, config, name=\"encoder_layer\"):\n",
        "        \"\"\"\n",
        "        생성자\n",
        "        :param config: Config 객체\n",
        "        :param name: layer name\n",
        "        \"\"\"\n",
        "        super().__init__(name=name)\n",
        "\n",
        "        self.self_attention = MultiHeadAttention(config)\n",
        "        self.norm1 = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
        "\n",
        "        self.ffn = PositionWiseFeedForward(config)\n",
        "        self.norm2 = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
        " \n",
        "    def call(self, enc_embed, self_mask):\n",
        "        \"\"\"\n",
        "        layer 실행\n",
        "        :param enc_embed: enc_embed 또는 이전 EncoderLayer의 출력\n",
        "        :param self_mask: enc_tokens의 pad mask\n",
        "        :return enc_out: EncoderLayer 실행 결과\n",
        "        \"\"\"\n",
        "        self_attn_val = self.self_attention(enc_embed, enc_embed, enc_embed, self_mask)\n",
        "        norm1_val = self.norm1(enc_embed + self.dropout(self_attn_val))\n",
        "\n",
        "        ffn_val = self.ffn(norm1_val)\n",
        "        enc_out = self.norm2(norm1_val + self.dropout(ffn_val))\n",
        "\n",
        "        return enc_out\n",
        "print(\"슝=3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "c72d7930",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c72d7930",
        "outputId": "4b69ac49-e2ba-441e-fa62-6ca8ae0cf61a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝=3\n"
          ]
        }
      ],
      "source": [
        "class BERT(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    BERT Class\n",
        "    \"\"\"\n",
        "    def __init__(self, config, name=\"bert\"):\n",
        "        \"\"\"\n",
        "        생성자\n",
        "        :param config: Config 객체\n",
        "        :param name: layer name\n",
        "        \"\"\"\n",
        "        super().__init__(name=name)\n",
        "\n",
        "        self.i_pad = config.i_pad\n",
        "        self.embedding = SharedEmbedding(config)\n",
        "        self.position = PositionEmbedding(config)\n",
        "        self.segment = tf.keras.layers.Embedding(2, config.d_model, embeddings_initializer=kernel_initializer())\n",
        "        self.norm = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
        "        \n",
        "        self.encoder_layers = [EncoderLayer(config, name=f\"encoder_layer_{i}\") for i in range(config.n_layer)]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        layer 실행\n",
        "        :param inputs: (enc_tokens, segments)\n",
        "        :return logits: dec_tokens에 대한 다음 토큰 예측 결과 logits\n",
        "        \"\"\"\n",
        "        enc_tokens, segments = inputs\n",
        "\n",
        "        enc_self_mask = tf.keras.layers.Lambda(get_pad_mask, output_shape=(1, None), name='enc_self_mask')(enc_tokens, self.i_pad)\n",
        "\n",
        "        enc_embed = self.get_embedding(enc_tokens, segments)\n",
        "\n",
        "        enc_out = self.dropout(enc_embed)\n",
        "        for encoder_layer in self.encoder_layers:\n",
        "            enc_out = encoder_layer(enc_out, enc_self_mask)\n",
        "\n",
        "        logits_cls = enc_out[:,0]\n",
        "        logits_lm = self.embedding(enc_out, mode=\"linear\")\n",
        "        return logits_cls, logits_lm\n",
        "    \n",
        "    def get_embedding(self, tokens, segments):\n",
        "        \"\"\"\n",
        "        token embedding, position embedding lookup\n",
        "        :param tokens: 입력 tokens\n",
        "        :param segments: 입력 segments\n",
        "        :return embed: embedding 결과\n",
        "        \"\"\"\n",
        "        embed = self.embedding(tokens) + self.position(tokens) + self.segment(segments)\n",
        "        embed = self.norm(embed)\n",
        "        return embed\n",
        "print(\"슝=3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "a6ce9755",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6ce9755",
        "outputId": "e25982e8-56a7-4c33-843c-3e0a468fb7a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝=3\n"
          ]
        }
      ],
      "source": [
        "# Encoder Layer class 정의\n",
        "class PooledOutput(tf.keras.layers.Layer):\n",
        "    def __init__(self, config, n_output, name=\"pooled_output\"):\n",
        "        super().__init__(name=name)\n",
        "\n",
        "        self.dense1 = tf.keras.layers.Dense(config.d_model, activation=tf.nn.tanh, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
        "        self.dense2 = tf.keras.layers.Dense(n_output, use_bias=False, activation=tf.nn.softmax, name=\"nsp\", kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
        " \n",
        "    def call(self, inputs):\n",
        "        outputs = self.dense1(inputs)\n",
        "        outputs = self.dense2(outputs)\n",
        "        return outputs\n",
        "print(\"슝=3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "f78099d2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f78099d2",
        "outputId": "23f78fd3-2a10-469e-8aa6-34b60b3bf502"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝=3\n"
          ]
        }
      ],
      "source": [
        "def build_model_pre_train(config):\n",
        "    enc_tokens = tf.keras.layers.Input((None,), name=\"enc_tokens\")\n",
        "    segments = tf.keras.layers.Input((None,), name=\"segments\")\n",
        "\n",
        "    bert = BERT(config)\n",
        "    logits_cls, logits_lm = bert((enc_tokens, segments))\n",
        "\n",
        "    logits_cls = PooledOutput(config, 2, name=\"pooled_nsp\")(logits_cls)\n",
        "    outputs_nsp = tf.keras.layers.Softmax(name=\"nsp\")(logits_cls)\n",
        "\n",
        "    outputs_mlm = tf.keras.layers.Softmax(name=\"mlm\")(logits_lm)\n",
        "\n",
        "    model = tf.keras.Model(inputs=(enc_tokens, segments), outputs=(outputs_nsp, outputs_mlm))\n",
        "    return model\n",
        "print(\"슝=3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "08e4d0c5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08e4d0c5",
        "outputId": "e4542a4d-c94b-4ba9-d961-dcc179e0a8bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'d_model': 256, 'n_head': 4, 'd_head': 64, 'dropout': 0.1, 'd_ff': 1024, 'layernorm_epsilon': 0.001, 'n_layer': 3, 'n_seq': 256, 'n_vocab': 32007, 'i_pad': 0}\n",
            "Epoch 1/2\n",
            "2/2 [==============================] - 8s 24ms/step - loss: 11.2227 - nsp_loss: 0.7743 - mlm_loss: 10.4484 - nsp_acc: 0.5000 - mlm_acc: 0.0000e+00\n",
            "Epoch 2/2\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 10.0172 - nsp_loss: 0.6251 - mlm_loss: 9.3921 - nsp_acc: 0.8000 - mlm_acc: 0.0200\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5b8c15a650>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "#validation with tiny Bert\n",
        "config = Config({\"d_model\": 256, \"n_head\": 4, \"d_head\": 64, \"dropout\": 0.1, \"d_ff\": 1024, \"layernorm_epsilon\": 0.001, \"n_layer\": 3, \"n_seq\": 256, \"n_vocab\": 0, \"i_pad\": 0})\n",
        "config.n_vocab = len(vocab)\n",
        "config.i_pad = vocab.pad_id()\n",
        "print(config)\n",
        "\n",
        "n_seq = 10\n",
        "\n",
        "# make test inputs\n",
        "enc_tokens = np.random.randint(0, len(vocab), (10, n_seq))\n",
        "segments = np.random.randint(0, 2, (10, n_seq))\n",
        "labels_nsp = np.random.randint(0, 2, (10,))\n",
        "labels_mlm = np.random.randint(0, len(vocab), (10, n_seq))\n",
        "\n",
        "test_model = build_model_pre_train(config)\n",
        "test_model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy, optimizer=tf.keras.optimizers.Adam(), metrics=[\"acc\"])\n",
        "\n",
        "# test model fit\n",
        "test_model.fit((enc_tokens, segments), (labels_nsp, labels_mlm), epochs=2, batch_size=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfd90053",
      "metadata": {
        "id": "dfd90053"
      },
      "source": [
        "# pretrain진행\n",
        "이것도 노드에서 가져옵니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "3bd496ce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bd496ce",
        "outputId": "974b5048-6c3a-4f3d-fe55-f4318cdcaf15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝=3\n"
          ]
        }
      ],
      "source": [
        "def lm_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    loss 계산 함수\n",
        "    :param y_true: 정답 (bs, n_seq)\n",
        "    :param y_pred: 예측 값 (bs, n_seq, n_vocab)\n",
        "    \"\"\"\n",
        "    # loss 계산\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)(y_true, y_pred)\n",
        "    # pad(0) 인 부분 mask\n",
        "    mask = tf.cast(tf.math.not_equal(y_true, 0), dtype=loss.dtype)\n",
        "    loss *= mask\n",
        "    return loss * 20  # mlm을 더 잘 학습하도록 20배 증가 시킴\n",
        "print(\"슝=3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "1788ecab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1788ecab",
        "outputId": "27e49c8e-74b1-4f7c-a9fa-f2ca3e1bd827"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝=3\n"
          ]
        }
      ],
      "source": [
        "def lm_acc(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    acc 계산 함수\n",
        "    :param y_true: 정답 (bs, n_seq)\n",
        "    :param y_pred: 예측 값 (bs, n_seq, n_vocab)\n",
        "    \"\"\"\n",
        "    # 정답 여부 확인\n",
        "    y_pred_class = tf.cast(K.argmax(y_pred, axis=-1), tf.float32)\n",
        "    matches = tf.cast(K.equal(y_true, y_pred_class), tf.float32)\n",
        "    # pad(0) 인 부분 mask\n",
        "    mask = tf.cast(tf.math.not_equal(y_true, 0), dtype=matches.dtype)\n",
        "    matches *= mask\n",
        "    # 정확도 계산\n",
        "    accuracy = K.sum(matches) / K.maximum(K.sum(mask), 1)\n",
        "    return accuracy\n",
        "print(\"슝=3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "ad81d3a1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad81d3a1",
        "outputId": "edc59884-63e6-499a-9a20-6d3d5f223ce1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝=3\n"
          ]
        }
      ],
      "source": [
        "class CosineSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    \"\"\"\n",
        "    CosineSchedule Class\n",
        "    \"\"\"\n",
        "    def __init__(self, train_steps=4000, warmup_steps=2000, max_lr=2.5e-4):\n",
        "        \"\"\"\n",
        "        생성자\n",
        "        :param train_steps: 학습 step 총 합\n",
        "        :param warmup_steps: warmup steps\n",
        "        :param max_lr: 최대 learning rate\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        assert 0 < warmup_steps < train_steps\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.train_steps = train_steps\n",
        "        self.max_lr = max_lr\n",
        "\n",
        "    def __call__(self, step_num):\n",
        "        \"\"\"\n",
        "        learning rate 계산\n",
        "        :param step_num: 현재 step number\n",
        "        :retrun: 계산된 learning rate\n",
        "        \"\"\"\n",
        "        state = tf.cast(step_num <= self.warmup_steps, tf.float32)\n",
        "        lr1 = tf.cast(step_num, tf.float32) / self.warmup_steps\n",
        "        progress = tf.cast(step_num - self.warmup_steps, tf.float32) / max(1, self.train_steps - self.warmup_steps)\n",
        "        lr2 = 0.5 * (1.0 + tf.math.cos(math.pi * progress))\n",
        "        return (state * lr1 + (1 - state) * lr2) * self.max_lr\n",
        "print(\"슝=3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "8bcaebc7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "8bcaebc7",
        "outputId": "24abcf6a-fc5d-417c-8fca-2d5fc84db794"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# compute lr \n",
        "test_schedule = CosineSchedule(train_steps=4000, warmup_steps=500)\n",
        "lrs = []\n",
        "for step_num in range(4000):\n",
        "    lrs.append(test_schedule(float(step_num)).numpy())\n",
        "\n",
        "# draw\n",
        "plt.plot(lrs, 'r-', label='learning_rate')\n",
        "plt.xlabel('Step')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "cef08967",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cef08967",
        "outputId": "78681e0f-5edc-4df2-c91b-8e6fcb6f49e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " enc_tokens (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " segments (InputLayer)          [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " bert (BERT)                    ((None, 256),        10629632    ['enc_tokens[0][0]',             \n",
            "                                 (None, None, 32007               'segments[0][0]']               \n",
            "                                ))                                                                \n",
            "                                                                                                  \n",
            " pooled_nsp (PooledOutput)      (None, 2)            66304       ['bert[0][0]']                   \n",
            "                                                                                                  \n",
            " nsp (Softmax)                  (None, 2)            0           ['pooled_nsp[0][0]']             \n",
            "                                                                                                  \n",
            " mlm (Softmax)                  (None, None, 32007)  0           ['bert[0][1]']                   \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10,695,936\n",
            "Trainable params: 10,695,936\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 모델 생성\n",
        "pre_train_model = build_model_pre_train(config)\n",
        "pre_train_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "3fd0cf88",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fd0cf88",
        "outputId": "0e512aa1-aa73-43f0-e972-6c82f9a94e42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_steps: 134740\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "batch_size = 64\n",
        "\n",
        "# optimizer\n",
        "train_steps = math.ceil(len(pre_train_inputs[0]) / batch_size) * epochs\n",
        "print(\"train_steps:\", train_steps)\n",
        "learning_rate = CosineSchedule(train_steps=train_steps, warmup_steps=max(100, train_steps // 10))\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "# compile\n",
        "pre_train_model.compile(loss=(tf.keras.losses.sparse_categorical_crossentropy, lm_loss), optimizer=optimizer, metrics={\"nsp\": \"acc\", \"mlm\": lm_acc})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "805d1b5f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "805d1b5f",
        "outputId": "134200ba-f7c0-47fd-ba68-3ed8e4f344b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "  486/13474 [>.............................] - ETA: 1:02:23 - loss: 20.6320 - nsp_loss: 0.6922 - mlm_loss: 19.9398 - nsp_acc: 0.5327 - mlm_lm_acc: 0.2374"
          ]
        }
      ],
      "source": [
        "# save weights callback\n",
        "save_weights = tf.keras.callbacks.ModelCheckpoint(f\"{model_dir}/bert_pre_train.hdf5\", monitor=\"mlm_lm_acc\", verbose=1, save_best_only=True, mode=\"max\", save_freq=\"epoch\", save_weights_only=True)\n",
        "# train\n",
        "history = pre_train_model.fit(pre_train_inputs, pre_train_labels, epochs=epochs, batch_size=batch_size, callbacks=[save_weights])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a967eab7",
      "metadata": {
        "id": "a967eab7"
      },
      "outputs": [],
      "source": [
        "# training result\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['nsp_loss'], 'b-', label='nsp_loss')\n",
        "plt.plot(history.history['mlm_loss'], 'r--', label='mlm_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['nsp_acc'], 'g-', label='nsp_acc')\n",
        "plt.plot(history.history['mlm_lm_acc'], 'k--', label='mlm_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0lU_0upjfIVZ"
      },
      "id": "0lU_0upjfIVZ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6a7c018e3e644c0ea505686ac1603829": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_649ccbb67ec24d1f8c03447e65d89f50",
              "IPY_MODEL_efd0e90f3e214d1aa9f15e16ed4da740",
              "IPY_MODEL_35210d30554149e2a93fc3a8d1ef4051"
            ],
            "layout": "IPY_MODEL_831f5c35025d445e85005087aae81d64"
          }
        },
        "649ccbb67ec24d1f8c03447e65d89f50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_291e4695615746f091194d368b6f9eeb",
            "placeholder": "​",
            "style": "IPY_MODEL_88afdb0a8e9d4184bbaab8df451d82b4",
            "value": "100%"
          }
        },
        "efd0e90f3e214d1aa9f15e16ed4da740": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1ecf3cb42bb40abb2bd340cfb1874ca",
            "max": 3957761,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a7ee517cd7e54a5cb0f146339cfc5f68",
            "value": 3957761
          }
        },
        "35210d30554149e2a93fc3a8d1ef4051": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fa74f6df085440981892171ca30e66f",
            "placeholder": "​",
            "style": "IPY_MODEL_ffef7ddd92154e09aa4269b8b53b332e",
            "value": " 3957761/3957761 [05:14&lt;00:00, 17715.16it/s]"
          }
        },
        "831f5c35025d445e85005087aae81d64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "291e4695615746f091194d368b6f9eeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88afdb0a8e9d4184bbaab8df451d82b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1ecf3cb42bb40abb2bd340cfb1874ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7ee517cd7e54a5cb0f146339cfc5f68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0fa74f6df085440981892171ca30e66f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffef7ddd92154e09aa4269b8b53b332e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d981df302cf42058ee08090166a0eca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1e2682671554409cb6ae2af59d6fddd8",
              "IPY_MODEL_1d2c79e990da48e1bb154c5b55e5a048",
              "IPY_MODEL_d629305aa7bd43a6ae00b08d46a1ce0a"
            ],
            "layout": "IPY_MODEL_faccb773fe7e4f4f893e36ded9cb9c89"
          }
        },
        "1e2682671554409cb6ae2af59d6fddd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c2aab6af42f43a98a69f1bd9fe816d2",
            "placeholder": "​",
            "style": "IPY_MODEL_6e60c7e13fe142a796581caa74cd4ad6",
            "value": "100%"
          }
        },
        "1d2c79e990da48e1bb154c5b55e5a048": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cb6a689bf864527b0ace28f1fc5efc5",
            "max": 862285,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_699a9aad6fd340d19fa5d9bb471fbff3",
            "value": 862285
          }
        },
        "d629305aa7bd43a6ae00b08d46a1ce0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32c7d7bcbd974fc78be2f7fdecd8e749",
            "placeholder": "​",
            "style": "IPY_MODEL_6df43d58ab6744d1bbeecbb99e490de7",
            "value": " 862285/862285 [03:08&lt;00:00, 5989.48it/s]"
          }
        },
        "faccb773fe7e4f4f893e36ded9cb9c89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c2aab6af42f43a98a69f1bd9fe816d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e60c7e13fe142a796581caa74cd4ad6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cb6a689bf864527b0ace28f1fc5efc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "699a9aad6fd340d19fa5d9bb471fbff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "32c7d7bcbd974fc78be2f7fdecd8e749": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6df43d58ab6744d1bbeecbb99e490de7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}