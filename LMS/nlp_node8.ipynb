{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Z8e4KRj05KrAsf_goMWSAGc73YBUM7OE",
      "authorship_tag": "ABX9TyNzk1SRuUivJ4+q/21jMyRS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chhyyi/aiffel/blob/main/LMS/nlp_node8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# About this notebook  \n",
        "이 노트북은 모두의 연구소 AIFFEL LMS NLP node8의 프로젝트입니다. seq2seq 한-영 번역기를 attention을 사용하여 만듭니다.   \n",
        "\n",
        "This is written as a part of the deep learning training course by Aiffel, Korea. LMS NLP node 8. I have to make a korean - english seq2seq translator. Additionaly attention should be used."
      ],
      "metadata": {
        "id": "Uhazh0Hz814w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.ticker as ticker\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import time\n",
        "import re\n",
        "import os\n",
        "import io"
      ],
      "metadata": {
        "id": "NfwCDP2D9rDD"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checkout version of libraries"
      ],
      "metadata": {
        "id": "33QNvzDV9xLv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "\n",
        "print(pd.__version__)\n",
        "print(tf.__version__)\n",
        "print(matplotlib.__version__)\n",
        "```"
      ],
      "metadata": {
        "id": "Zj9J_eLi91-K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download, load dataset\n",
        "download korean-english-park.train.tar.gz from this github rep.\n",
        "[jungyeul/korean-parallel-corpora](https://github.com/jungyeul/korean-parallel-corpora/tree/master/korean-english-news-v1)  \n",
        "instead of tf.keras.utils.get_file(), google drive web page and terminal used."
      ],
      "metadata": {
        "id": "svatjaZO9-k4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "en_path = '/content/drive/MyDrive/colabdata/modulabs/nlp8/korean-english-park.train.en'\n",
        "ko_path = '/content/drive/MyDrive/colabdata/modulabs/nlp8/korean-english-park.train.ko'\n",
        "f_ko=open(ko_path, 'r')\n",
        "f_en=open(en_path, 'r')\n",
        "ko_raw = f_ko.readlines()\n",
        "en_raw = f_en.readlines()"
      ],
      "metadata": {
        "id": "3Iqf_sZR-hYK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(ko_raw), len(en_raw))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QmbzPte_MSh",
        "outputId": "a40d2808-df0f-4fe1-b6c1-8a5b6ada2114"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94123 94123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame()\n",
        "test_rows=0 #temporal index for scripting\n",
        "if test_rows:\n",
        "    data['ko_raw']=ko_raw[:test_rows]\n",
        "    data['en_raw']=en_raw[:test_rows]\n",
        "else:\n",
        "    data['ko_raw']=ko_raw\n",
        "    data['en_raw']=en_raw\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "uSDTPVElBsRP",
        "outputId": "69e54fd2-49c3-465f-bd91-54921557e467"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  ko_raw  \\\n",
              "0                 개인용 컴퓨터 사용의 상당 부분은 \"이것보다 뛰어날 수 있느냐?\"\\n   \n",
              "1      모든 광마우스와 마찬가지 로 이 광마우스도 책상 위에 놓는 마우스 패드를 필요로 하...   \n",
              "2                           그러나 이것은 또한 책상도 필요로 하지 않는다.\\n   \n",
              "3      79.95달러하는 이 최첨단 무선 광마우스는 허공에서 팔목, 팔, 그외에 어떤 부분...   \n",
              "4      정보 관리들은 동남 아시아에서의 선박들에 대한 많은 (테러) 계획들이 실패로 돌아갔...   \n",
              "...                                                  ...   \n",
              "94118  “우리는 3월 8일 김승연 회장과 그의 아들이 보복폭행에 가담한 혐의를 찾기 위해 ...   \n",
              "94119  월요일 술집 종업원 6명은 김회장과 아들에게 폭행을 당했음을 진술했다고 경찰은 말했...   \n",
              "94120                     그러나 불충분한 증거 확보로 수사에 어려움이 있다.\\n   \n",
              "94121                김회장과 그의 아들은 보복폭행 혐의를 강력히 부인하고 있다.\\n   \n",
              "94122  경찰은 김회장의 집무실에서 추가 증거를 찾은 이후 가능한 한 오늘 김회장과 아들을 ...   \n",
              "\n",
              "                                                  en_raw  \n",
              "0      Much of personal computing is about \"can you t...  \n",
              "1      so a mention a few weeks ago about a rechargea...  \n",
              "2      Like all optical mice, But it also doesn't nee...  \n",
              "3      uses gyroscopic sensors to control the cursor ...  \n",
              "4      Intelligence officials have revealed a spate o...  \n",
              "...                                                  ...  \n",
              "94118  ””We are hoping to seize material evidence to ...  \n",
              "94119  ” On Monday, police secured statements from si...  \n",
              "94120  But the lack of material evidence is making it...  \n",
              "94121       Kim and his son both deny the allegations.\\n  \n",
              "94122  Police are planning to seek arrest warrants fo...  \n",
              "\n",
              "[94123 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-887dbe61-6a45-4e04-a510-6631a9391cbe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ko_raw</th>\n",
              "      <th>en_raw</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>개인용 컴퓨터 사용의 상당 부분은 \"이것보다 뛰어날 수 있느냐?\"\\n</td>\n",
              "      <td>Much of personal computing is about \"can you t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>모든 광마우스와 마찬가지 로 이 광마우스도 책상 위에 놓는 마우스 패드를 필요로 하...</td>\n",
              "      <td>so a mention a few weeks ago about a rechargea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>그러나 이것은 또한 책상도 필요로 하지 않는다.\\n</td>\n",
              "      <td>Like all optical mice, But it also doesn't nee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>79.95달러하는 이 최첨단 무선 광마우스는 허공에서 팔목, 팔, 그외에 어떤 부분...</td>\n",
              "      <td>uses gyroscopic sensors to control the cursor ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>정보 관리들은 동남 아시아에서의 선박들에 대한 많은 (테러) 계획들이 실패로 돌아갔...</td>\n",
              "      <td>Intelligence officials have revealed a spate o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94118</th>\n",
              "      <td>“우리는 3월 8일 김승연 회장과 그의 아들이 보복폭행에 가담한 혐의를 찾기 위해 ...</td>\n",
              "      <td>””We are hoping to seize material evidence to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94119</th>\n",
              "      <td>월요일 술집 종업원 6명은 김회장과 아들에게 폭행을 당했음을 진술했다고 경찰은 말했...</td>\n",
              "      <td>” On Monday, police secured statements from si...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94120</th>\n",
              "      <td>그러나 불충분한 증거 확보로 수사에 어려움이 있다.\\n</td>\n",
              "      <td>But the lack of material evidence is making it...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94121</th>\n",
              "      <td>김회장과 그의 아들은 보복폭행 혐의를 강력히 부인하고 있다.\\n</td>\n",
              "      <td>Kim and his son both deny the allegations.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94122</th>\n",
              "      <td>경찰은 김회장의 집무실에서 추가 증거를 찾은 이후 가능한 한 오늘 김회장과 아들을 ...</td>\n",
              "      <td>Police are planning to seek arrest warrants fo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>94123 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-887dbe61-6a45-4e04-a510-6631a9391cbe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-887dbe61-6a45-4e04-a510-6631a9391cbe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-887dbe61-6a45-4e04-a510-6631a9391cbe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# About Data load...\n",
        "\n",
        "두 파일은 영어, 한국어 문장이 순서대로 들어가있으므로 순서를 그대로 읽어야 합니다. \n",
        "pandas.read_csv나 read_table을 썼을 때에는 줄의 개수가 달라져서 seperator를 고쳐보다가 안돼서 그냥 file.readlines()를 사용하였습니다.\n",
        "\n",
        "Two data file have corresponding sentences. So its order should be preserved. but when I have tried pandas.read_csv and pandas.read_table first. In that case, length of both file did not matched. maybe I should change seperator   \n",
        "\n"
      ],
      "metadata": {
        "id": "7lBhOopZFJ8I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data refine, cleaning"
      ],
      "metadata": {
        "id": "-hujrRjJE-Ns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.isna().any()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKpacav9EBzm",
        "outputId": "32371765-5ab8-4875-fdc6-f581f1cf9194"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ko_raw    False\n",
              "en_raw    False\n",
              "dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data['ko_raw'].apply(lambda x: '\\\\' in x)"
      ],
      "metadata": {
        "id": "UwN_3eg9EL9x"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Characters?\n",
        " before we process regular expressions, let's figure out set of characters shown in each dataset."
      ],
      "metadata": {
        "id": "YXSmBFVUMjlw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def characters_in_column(df, col_name):\n",
        "    \"\"\"characters_in_column(df, col_name)\n",
        "    df is pandas dataframe. this function converts df[\"col_name\"] into set of characters. return ordered list.\n",
        "    \"\"\"\n",
        "    _=pd.Series()\n",
        "    _=df[col_name].apply(lambda x: [i for i in x])\n",
        "    return np.unique(np.concatenate(_.values))\n"
      ],
      "metadata": {
        "id": "5SwRU1KlM6YZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ko_chars=characters_in_column(data, 'ko_raw')\n",
        "print(ko_chars)\n",
        "print(' '.join(ko_chars))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-95xJ9nSyHC",
        "outputId": "01a41e78-ccaf-4bea-a9e3-b67425952259"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n' ' ' '!' ... '８' '？' '\\U000d51d1']\n",
            "\n",
            "   ! \" # $ % & ' ( ) * + , - . / 0 1 2 3 4 5 6 7 8 9 : ; = > ? @ A B C D E F G H I J K L M N O P Q R S T U V W X Y Z [ ] ^ _ ` a b c d e f g h i j k l m n o p q r s t u v w x y z { } ~   ± ´ · × é ˙ ˝ – ― ‘ ’ “ ” • ‥ … ℃ ℓ ▲ ▶ 　 〈 〉 〔 〕 い か き く さ ざ し す そ て と ば ぶ ぷ ま や よ ら り ん ㄴ ㅇ ㆍ ㈜ ㎝ ㎞ ㎠ ㎡ ㎢ ㎾ 一 万 三 上 不 丙 中 主 之 九 亞 交 京 仁 代 佛 促 信 修 假 備 傷 像 僞 價 億 兆 光 克 兒 內 全 公 兵 再 切 前 劉 力 加 動 勝 北 區 卍 占 印 卿 反 受 古 司 吉 同 名 吳 命 和 品 商 善 喩 器 四 因 國 園 圓 團 在 地 坤 型 城 基 堀 報 場 塔 墓 壽 外 多 大 天 夫 奔 奴 姓 婦 子 字 孩 學 宇 安 官 室 家 富 察 寧 寶 寺 對 導 小 局 居 屋 山 岩 島 峽 川 州 市 席 常 平 幹 店 度 座 庫 康 廣 建 式 弗 强 影 後 心 性 愁 愚 愛 慶 懷 戰 所 手 掃 掌 換 播 故 效 敎 敢 敵 文 斌 新 方 族 旗 日 早 明 星 時 晉 晴 書 曾 會 月 本 朱 李 東 林 査 株 案 棺 植 楊 機 權 次 止 正 死 殘 毁 母 毛 毬 民 氣 水 氷 江 沈 河 油 法 泥 泰 流 浅 海 淘 淺 港 湖 湛 溫 滑 澤 濠 濤 濱 瀋 灣 火 無 然 焼 煙 照 燭 父 物 獨 獸 率 王 珀 現 球 理 琥 環 生 産 田 男 異 畵 疑 疫 病 登 發 的 省 眞 石 社 神 票 祭 福 私 種 空 突 章 管 節 築 精 紅 紙 結 總 纏 置 羅 美 群 習 翔 老 者 耳 聖 聲 職 肢 胡 能 膚 臺 舊 航 船 花 芽 英 草 華 董 葬 蓄 蓋 蔣 藥 藻 號 街 衛 要 視 親 覺 言 詩 誌 語 談 論 諡 諸 識 貧 買 費 賣 質 赤 走 超 足 路 身 軌 軍 輔 輿 辛 近 迷 送 通 進 道 邦 邸 郞 郡 都 鄕 配 酒 酸 醒 醜 野 銀 銅 錦 鎔 長 門 開 間 陳 陽 雙 難 雨 雲 電 霧 靑 靜 非 頁 頂 頭 題 類 食 香 馬 駐 體 髮 魚 鳥 鳩 麥 麻 鼓 가 각 간 갇 갈 갉 감 갑 값 갓 갔 강 갖 갗 같 갚 갛 개 객 갠 갤 갬 갭 갯 갱 갸 걀 거 걱 건 걷 걸 검 겁 것 겅 겉 게 겐 겔 겜 겝 겟 겠 겡 겨 격 겪 견 결 겸 겹 겼 경 곁 계 고 곡 곤 곧 골 곰 곱 곳 공 과 곽 관 괄 괌 광 괘 괜 괭 괴 굉 교 구 국 군 굳 굴 굵 굶 굽 굿 궁 궂 궈 권 궐 궤 귀 귄 귈 귓 규 균 귤 그 극 근 글 긁 금 급 긋 긍 기 긱 긴 길 김 깁 깃 깅 깊 까 깍 깎 깐 깔 깜 깝 깡 깥 깨 깬 깰 깼 꺼 꺽 꺾 껀 껄 껌 껍 껏 껐 껑 께 껴 꼈 꼐 꼬 꼭 꼰 꼴 꼼 꼽 꼿 꽁 꽂 꽃 꽉 꽝 꽤 꽥 꾀 꾸 꾹 꾼 꿀 꿇 꿈 꿋 꿔 꿨 꿰 뀌 뀐 뀔 뀝 끄 끈 끊 끌 끓 끔 끗 끝 끼 끽 낀 낄 낌 낍 낑 나 낙 낚 난 날 낡 남 납 낫 났 낭 낮 낯 낱 낳 내 낵 낸 낼 냄 냅 냇 냈 냉 냐 냑 냔 냥 너 넉 넋 넌 널 넒 넓 넘 넛 넜 넝 넣 네 넥 넨 넬 넴 넵 넷 넸 넹 녀 녁 년 념 녔 녕 녘 녠 노 녹 논 놀 놈 놋 농 높 놓 놔 놨 뇌 뇨 뇰 뇽 누 눅 눈 눌 눔 눕 눠 눴 뉘 뉜 뉴 뉼 늄 늉 느 늑 는 늘 늙 늠 능 늦 늪 늬 니 닉 닌 닐 님 닙 닛 닝 다 닥 닦 단 닫 달 닭 닮 닳 담 답 닷 당 닻 닿 대 댁 댄 댈 댐 댓 댔 댕 댜 더 덕 던 덜 덟 덤 덥 덧 덩 덫 덮 데 덱 덴 델 뎀 뎁 뎃 뎅 뎌 뎠 도 독 돈 돋 돌 돔 돕 돗 동 돛 돼 됐 되 된 될 됨 됩 두 둑 둔 둘 둠 둡 둣 둥 둬 뒀 뒈 뒤 뒷 뒹 듀 듈 듐 드 득 든 듣 들 듦 듬 듭 듯 등 디 딕 딘 딛 딜 딤 딥 딧 딩 딪 따 딱 딴 딸 땀 땄 땅 땋 때 땐 땔 땠 떠 떡 떤 떨 떳 떴 떻 떼 뗀 뗄 뗏 뗐 또 똑 똥 뙤 뚜 뚝 뚤 뚫 뚱 뛰 뛴 뛸 뜨 뜩 뜬 뜯 뜰 뜻 띄 띈 띠 띤 띨 띵 라 락 란 랄 람 랍 랏 랐 랑 랗 래 랙 랜 랠 램 랩 랫 랬 랭 랴 략 럇 량 러 럭 런 럴 럼 럽 럿 렀 렁 렇 레 렉 렌 렐 렘 렙 렛 렝 려 력 련 렬 렴 렵 렷 렸 령 례 롄 로 록 론 롤 롬 롭 롯 롱 뢰 료 룡 루 룩 룬 룰 룸 룹 룻 룽 뤄 뤘 뤼 뤽 류 륙 륜 률 륨 륭 르 륵 른 를 름 릅 릇 릉 릎 리 릭 린 릴 림 립 릿 링 마 막 만 많 맏 말 맑 맘 맙 맛 망 맞 맡 맣 매 맥 맨 맬 맴 맵 맷 맸 맹 맺 먀 머 먹 먼 멀 멈 멉 멋 멍 멎 메 멕 멘 멜 멤 멧 멩 며 면 멸 몄 명 몇 모 목 몫 몬 몰 몸 몹 못 몽 뫼 묘 무 묵 묶 문 묻 물 뭄 뭇 뭉 뭍 뭐 뭔 뭘 뭣 뮈 뮌 뮐 뮤 뮬 뮴 므 믈 믐 미 믹 민 믿 밀 밈 밋 밌 밍 및 밑 바 박 밖 반 받 발 밝 밟 밤 밥 밧 방 밭 배 백 밴 밸 뱀 뱃 뱅 뱉 뱌 버 벅 번 벌 범 법 벗 벙 벚 벛 베 벡 벤 벨 벳 벵 벼 벽 변 별 볍 볐 병 볕 볜 보 복 본 볼 봄 봅 봇 봉 봐 봤 뵈 뵙 부 북 분 붇 불 붉 붐 붑 붓 붕 붙 붸 뷔 뷜 뷰 뷴 뷸 브 븍 븐 블 비 빅 빈 빌 빔 빕 빗 빙 빚 빛 빠 빡 빤 빨 빰 빴 빵 빼 빽 뺀 뺄 뺌 뺏 뺐 뺑 뺨 뻐 뻑 뻔 뻗 뻘 뻣 뻤 뻬 뼈 뽀 뽐 뽑 뽕 뾰 뿌 뿍 뿐 뿔 뿜 쁘 쁜 쁠 쁨 쁩 삐 삔 사 삭 삯 산 살 삶 삼 삽 삿 샀 상 샅 새 색 샌 샐 샘 샛 생 샤 샨 샬 샴 샵 샷 샹 섀 서 석 섞 선 섣 설 섬 섭 섯 섰 성 세 섹 센 셀 셈 셉 셋 셌 셍 셔 션 셜 셤 셨 셩 셰 셴 셸 솀 솅 소 속 손 솔 솜 솟 송 솥 쇄 쇠 쇤 쇨 쇼 숀 숄 숍 숏 수 숙 순 숟 술 숨 숩 숫 숭 숱 숲 숴 쉈 쉐 쉔 쉘 쉠 쉥 쉬 쉭 쉰 쉴 쉼 쉽 슈 슐 슘 슛 슝 스 슥 슨 슬 슭 슴 습 슷 승 시 식 신 싣 실 싫 심 십 싯 싰 싱 싶 싸 싹 싼 쌀 쌈 쌌 쌍 쌓 써 썩 썬 썰 썹 썼 썽 쎄 쏘 쏙 쏜 쏟 쏠 쏴 쐈 쐐 쐬 쑤 쑥 쓰 쓱 쓴 쓸 씀 씌 씨 씩 씬 씰 씸 씹 씻 씽 아 악 안 앉 않 알 앓 암 압 앗 았 앙 앞 애 액 앤 앨 앰 앱 앳 앴 앵 야 약 얀 얄 얇 얌 얏 양 얕 얗 얘 어 억 언 얹 얻 얼 얽 엄 업 없 엇 었 엉 엌 엎 에 엑 엔 엘 엠 엡 엣 엥 여 역 엮 연 열 염 엽 엾 엿 였 영 옅 옆 옇 예 옌 옐 옛 옜 오 옥 온 올 옭 옮 옳 옴 옵 옷 옹 옻 와 왁 완 왈 왑 왓 왔 왕 왜 외 왼 요 욕 욘 욜 욤 용 우 욱 운 울 움 웁 웃 웅 워 웍 원 월 웜 웝 웠 웡 웨 웬 웰 웸 웹 웽 위 윅 윈 윌 윔 윕 윗 윙 유 육 윤 율 윰 윱 윳 융 윺 으 윽 은 을 읊 음 읍 응 의 읜 이 익 인 일 읽 잃 임 입 잇 있 잉 잊 잎 자 작 잔 잖 잘 잠 잡 잣 잤 장 잦 재 잭 잰 잼 잿 쟀 쟁 쟈 쟝 저 적 전 절 젊 점 접 젓 정 젖 제 젝 젠 젤 젬 젭 젯 젱 져 젼 졌 조 족 존 졸 좀 좁 종 좇 좋 좌 죄 죌 죠 죤 주 죽 준 줄 줌 줍 줏 중 줘 줬 쥐 쥔 쥘 쥬 쥴 즈 즉 즌 즐 즘 즙 증 지 직 진 질 짊 짐 집 짓 징 짖 짙 짚 짜 짝 짠 짢 짤 짧 짰 짱 째 쨌 쨍 쩌 쩍 쩔 쩡 쪄 쪘 쪼 쪽 쫑 쫓 쬐 쬔 쭈 쭉 쭐 쮸 쯔 쯤 찌 찍 찐 찔 찜 찟 찡 찢 차 착 찬 찮 찰 참 찻 찼 창 찾 채 책 챈 챌 챔 챕 챗 챘 챙 챠 챤 챨 챵 처 척 천 철 첨 첩 첫 청 체 첵 첸 첼 쳄 쳇 쳉 쳐 쳔 쳤 쳬 쳴 초 촉 촌 촐 촘 촛 총 촨 촬 최 쵸 춀 추 축 춘 출 춤 춥 춧 충 춰 췄 췌 취 츄 츈 츠 측 츤 츨 츰 층 치 칙 친 칠 침 칩 칫 칭 카 칵 칸 칼 캄 캅 캇 캉 캐 캔 캘 캠 캡 캣 캥 캬 커 컥 컨 컫 컬 컴 컵 컷 컸 컹 케 켁 켄 켈 켐 켓 켕 켜 켠 켤 켬 켰 코 콕 콘 콜 콤 콥 콧 콩 콰 콴 콸 쾅 쾌 쾰 쿄 쿠 쿡 쿤 쿨 쿰 쿱 쿵 쿼 퀀 퀄 퀘 퀴 퀵 퀸 퀼 큄 큇 큉 큐 큘 크 큰 클 큼 키 킥 킨 킬 킴 킵 킷 킹 타 탁 탄 탈 탐 탑 탓 탔 탕 태 택 탠 탤 탬 탭 탯 탰 탱 탸 터 턱 턴 털 텀 텁 텄 텅 테 텍 텐 텔 템 텝 텟 텡 텨 텼 토 톡 톤 톨 톰 톱 통 퇀 퇘 퇴 툐 투 툭 툰 툴 툼 툿 퉁 퉈 퉜 튀 튈 튕 튜 튠 튬 트 특 튼 튿 틀 틈 틔 티 틱 틴 틸 팀 팁 팅 파 팍 팎 판 팔 팜 팝 팟 팠 팡 패 팩 팬 팰 팸 팹 팻 팽 퍼 퍽 펀 펄 펌 펍 펏 펐 펑 페 펙 펜 펠 펫 펭 펴 편 펼 폄 폅 폈 평 폐 포 폭 폰 폴 폼 폿 퐁 푀 표 푸 푹 푼 풀 품 풋 풍 퓌 퓨 퓰 프 픈 플 픔 피 픽 핀 필 핌 핍 핏 핑 하 학 한 할 핥 함 합 핫 항 해 핵 핸 핼 햄 햅 햇 했 행 햐 향 허 헉 헌 헐 험 헛 헝 헤 헥 헨 헬 헴 헷 헹 혀 혁 현 혈 혐 협 혓 혔 형 혜 호 혹 혼 홀 홈 홉 홋 홍 화 확 환 활 홧 황 횃 회 획 횟 횡 효 후 훅 훈 훌 훑 훔 훗 훙 훤 훨 훼 휘 휜 휠 휩 휫 휴 흄 흉 흐 흑 흔 흘 흙 흠 흡 흥 흩 희 흰 히 힉 힌 힐 힘 힙 힛 힝  金 懶 不 良 女 年 戀 領 料 遼 龍 柳 輪 率 識 ！ （ ） － ． １ ２ ３ ４ ５ ８ ？ 󕇑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "온갖 글자가 다 있습니다. 줄넘김, 한자도 있네요."
      ],
      "metadata": {
        "id": "lNZMqmEEYfRF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 텍스트 전처리 수정(정제)\n",
        "노드의 코드를 보면 정규표현식을 다음과 같이 사용합니다.\n",
        "```python\n",
        "sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
        "```\n",
        "위의 예에서 보면 많은 경우 \\n 등이 삽입돼 있는데 줄넘김 표시이므로 삭제합니다.  \n",
        "외래어도 자연스럽게 우리말 문장에 영어로 들어가 있는 경우도 많 때문에 굳이 영어 알파벳를 빼지는 않겠습니다.\n",
        "\n",
        "```python\n",
        "sentence = re.sub(r\"\\\\[a-zA-Z]\", \" \", sentence)\n",
        "sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "sentence = re.sub(r\"[^ㄱ-ㅎ가-힣a-zA-Z?.!,]+\", \" \", sentence)\n",
        "```"
      ],
      "metadata": {
        "id": "eSB892rfSu71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#print(re.sub(r\"\\\\[a-zA-Z]\", \" \", '\\dsdfasf dasfd ahf'))\n",
        "#print('\\ndasd')"
      ],
      "metadata": {
        "id": "ibe2x0byNkX4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_en(sentence, s_token=True, e_token=True):\n",
        "    sentence = sentence.lower().strip()\n",
        "    sentence = re.sub(r\"\\\\[a-zA-Z]\", \" \", sentence)\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
        "\n",
        "    sentence = sentence.strip()\n",
        "\n",
        "    if s_token:\n",
        "        sentence = '<start> ' + sentence\n",
        "\n",
        "    if e_token:\n",
        "        sentence += ' <end>'\n",
        "    \n",
        "    return sentence"
      ],
      "metadata": {
        "id": "72R7p1tynu0m"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_ko(sentence):\n",
        "    sentence = sentence.lower().strip()\n",
        "\n",
        "    sentence = re.sub(r\"\\\\[a-zA-Z]\", \" \", sentence)\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "    sentence = re.sub(r\"[^ㄱ-ㅎ가-힣a-zA-Z?.!,]+\", \" \", sentence)\n",
        "\n",
        "    sentence = sentence.strip()\n",
        "\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "-AqgtibgSAap"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['ko_sentence']=data['ko_raw'].apply(preprocess_ko)\n",
        "data['en_sentence']=data['en_raw'].apply(preprocess_en)\n",
        "data.drop(columns=['en_raw','ko_raw'], inplace=True)\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "kvwDuslWmiCu",
        "outputId": "7c9c1a02-b931-44ce-bcdb-97eeb83dc3a0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             ko_sentence  \\\n",
              "0                    개인용 컴퓨터 사용의 상당 부분은 이것보다 뛰어날 수 있느냐 ?   \n",
              "1      모든 광마우스와 마찬가지 로 이 광마우스도 책상 위에 놓는 마우스 패드를 필요로 하...   \n",
              "2                            그러나 이것은 또한 책상도 필요로 하지 않는다 .   \n",
              "3      . 달러하는 이 최첨단 무선 광마우스는 허공에서 팔목 , 팔 , 그외에 어떤 부분이...   \n",
              "4      정보 관리들은 동남 아시아에서의 선박들에 대한 많은 테러 계획들이 실패로 돌아갔음을...   \n",
              "...                                                  ...   \n",
              "94118  우리는 월 일 김승연 회장과 그의 아들이 보복폭행에 가담한 혐의를 찾기 위해 총력을...   \n",
              "94119   월요일 술집 종업원 명은 김회장과 아들에게 폭행을 당했음을 진술했다고 경찰은 말했다 .   \n",
              "94120                      그러나 불충분한 증거 확보로 수사에 어려움이 있다 .   \n",
              "94121                 김회장과 그의 아들은 보복폭행 혐의를 강력히 부인하고 있다 .   \n",
              "94122  경찰은 김회장의 집무실에서 추가 증거를 찾은 이후 가능한 한 오늘 김회장과 아들을 ...   \n",
              "\n",
              "                                             en_sentence  \n",
              "0      <start> much of personal computing is about ca...  \n",
              "1      <start> so a mention a few weeks ago about a r...  \n",
              "2      <start> like all optical mice , but it also do...  \n",
              "3      <start> uses gyroscopic sensors to control the...  \n",
              "4      <start> intelligence officials have revealed a...  \n",
              "...                                                  ...  \n",
              "94118  <start> we are hoping to seize material eviden...  \n",
              "94119  <start> on monday , police secured statements ...  \n",
              "94120  <start> but the lack of material evidence is m...  \n",
              "94121  <start> kim and his son both deny the allegati...  \n",
              "94122  <start> police are planning to seek arrest war...  \n",
              "\n",
              "[94123 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad493cd1-14a5-41dc-9a78-193a632b6635\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ko_sentence</th>\n",
              "      <th>en_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>개인용 컴퓨터 사용의 상당 부분은 이것보다 뛰어날 수 있느냐 ?</td>\n",
              "      <td>&lt;start&gt; much of personal computing is about ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>모든 광마우스와 마찬가지 로 이 광마우스도 책상 위에 놓는 마우스 패드를 필요로 하...</td>\n",
              "      <td>&lt;start&gt; so a mention a few weeks ago about a r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>그러나 이것은 또한 책상도 필요로 하지 않는다 .</td>\n",
              "      <td>&lt;start&gt; like all optical mice , but it also do...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>. 달러하는 이 최첨단 무선 광마우스는 허공에서 팔목 , 팔 , 그외에 어떤 부분이...</td>\n",
              "      <td>&lt;start&gt; uses gyroscopic sensors to control the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>정보 관리들은 동남 아시아에서의 선박들에 대한 많은 테러 계획들이 실패로 돌아갔음을...</td>\n",
              "      <td>&lt;start&gt; intelligence officials have revealed a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94118</th>\n",
              "      <td>우리는 월 일 김승연 회장과 그의 아들이 보복폭행에 가담한 혐의를 찾기 위해 총력을...</td>\n",
              "      <td>&lt;start&gt; we are hoping to seize material eviden...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94119</th>\n",
              "      <td>월요일 술집 종업원 명은 김회장과 아들에게 폭행을 당했음을 진술했다고 경찰은 말했다 .</td>\n",
              "      <td>&lt;start&gt; on monday , police secured statements ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94120</th>\n",
              "      <td>그러나 불충분한 증거 확보로 수사에 어려움이 있다 .</td>\n",
              "      <td>&lt;start&gt; but the lack of material evidence is m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94121</th>\n",
              "      <td>김회장과 그의 아들은 보복폭행 혐의를 강력히 부인하고 있다 .</td>\n",
              "      <td>&lt;start&gt; kim and his son both deny the allegati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94122</th>\n",
              "      <td>경찰은 김회장의 집무실에서 추가 증거를 찾은 이후 가능한 한 오늘 김회장과 아들을 ...</td>\n",
              "      <td>&lt;start&gt; police are planning to seek arrest war...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>94123 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad493cd1-14a5-41dc-9a78-193a632b6635')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ad493cd1-14a5-41dc-9a78-193a632b6635 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ad493cd1-14a5-41dc-9a78-193a632b6635');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 중복 데이터 삭제"
      ],
      "metadata": {
        "id": "ytLGSEyvKrqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[data.duplicated(keep=False)].sort_values(by='ko_sentence')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "uIw_cJwkKvGc",
        "outputId": "5cb403c0-2c91-4847-e464-de34e27a2b4f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             ko_sentence  \\\n",
              "69441                                   , kg 에메랄드 소유권 분쟁   \n",
              "69429                                   , kg 에메랄드 소유권 분쟁   \n",
              "86489  , korean women are working as prostitutes in j...   \n",
              "73805  , korean women are working as prostitutes in j...   \n",
              "62240                                , 고대 이집트 지배층 유물 전시회   \n",
              "...                                                  ...   \n",
              "93792                                  힐러리 클린턴 , 북한 방문할까   \n",
              "79517                                  힐러리 클린턴 , 북한 방문할까   \n",
              "78621                                  힐러리 클린턴 , 북한 방문할까   \n",
              "64666                  힐러리 클린턴은 지난 년 월 이후 상원의원에 재임 중이다 .   \n",
              "64682                  힐러리 클린턴은 지난 년 월 이후 상원의원에 재임 중이다 .   \n",
              "\n",
              "                                             en_sentence  \n",
              "69441   <start> pound emerald at center of dispute <end>  \n",
              "69429   <start> pound emerald at center of dispute <end>  \n",
              "86489  <start> some of the brokers bragged about bein...  \n",
              "73805  <start> some of the brokers bragged about bein...  \n",
              "62240  <start> king tut and , years in ancient egypt ...  \n",
              "...                                                  ...  \n",
              "93792  <start> would hillary clinton visit north kore...  \n",
              "79517  <start> would hillary clinton visit north kore...  \n",
              "78621  <start> would hillary clinton visit north kore...  \n",
              "64666  <start> hillary clinton has been in the senate...  \n",
              "64682  <start> hillary clinton has been in the senate...  \n",
              "\n",
              "[22086 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-39c30bd8-776c-4877-83bb-a9189bfb4ed8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ko_sentence</th>\n",
              "      <th>en_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>69441</th>\n",
              "      <td>, kg 에메랄드 소유권 분쟁</td>\n",
              "      <td>&lt;start&gt; pound emerald at center of dispute &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69429</th>\n",
              "      <td>, kg 에메랄드 소유권 분쟁</td>\n",
              "      <td>&lt;start&gt; pound emerald at center of dispute &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86489</th>\n",
              "      <td>, korean women are working as prostitutes in j...</td>\n",
              "      <td>&lt;start&gt; some of the brokers bragged about bein...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73805</th>\n",
              "      <td>, korean women are working as prostitutes in j...</td>\n",
              "      <td>&lt;start&gt; some of the brokers bragged about bein...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62240</th>\n",
              "      <td>, 고대 이집트 지배층 유물 전시회</td>\n",
              "      <td>&lt;start&gt; king tut and , years in ancient egypt ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93792</th>\n",
              "      <td>힐러리 클린턴 , 북한 방문할까</td>\n",
              "      <td>&lt;start&gt; would hillary clinton visit north kore...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79517</th>\n",
              "      <td>힐러리 클린턴 , 북한 방문할까</td>\n",
              "      <td>&lt;start&gt; would hillary clinton visit north kore...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78621</th>\n",
              "      <td>힐러리 클린턴 , 북한 방문할까</td>\n",
              "      <td>&lt;start&gt; would hillary clinton visit north kore...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64666</th>\n",
              "      <td>힐러리 클린턴은 지난 년 월 이후 상원의원에 재임 중이다 .</td>\n",
              "      <td>&lt;start&gt; hillary clinton has been in the senate...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64682</th>\n",
              "      <td>힐러리 클린턴은 지난 년 월 이후 상원의원에 재임 중이다 .</td>\n",
              "      <td>&lt;start&gt; hillary clinton has been in the senate...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>22086 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39c30bd8-776c-4877-83bb-a9189bfb4ed8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-39c30bd8-776c-4877-83bb-a9189bfb4ed8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-39c30bd8-776c-4877-83bb-a9189bfb4ed8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop_duplicates(inplace=True)\n",
        "data.reset_index(inplace=True)\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "y5zYyBuZMWpa",
        "outputId": "2740234e-392a-46d4-ab47-5f05d497c482"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       index                                        ko_sentence  \\\n",
              "0          0                개인용 컴퓨터 사용의 상당 부분은 이것보다 뛰어날 수 있느냐 ?   \n",
              "1          1  모든 광마우스와 마찬가지 로 이 광마우스도 책상 위에 놓는 마우스 패드를 필요로 하...   \n",
              "2          2                        그러나 이것은 또한 책상도 필요로 하지 않는다 .   \n",
              "3          3  . 달러하는 이 최첨단 무선 광마우스는 허공에서 팔목 , 팔 , 그외에 어떤 부분이...   \n",
              "4          4  정보 관리들은 동남 아시아에서의 선박들에 대한 많은 테러 계획들이 실패로 돌아갔음을...   \n",
              "...      ...                                                ...   \n",
              "78840  94118  우리는 월 일 김승연 회장과 그의 아들이 보복폭행에 가담한 혐의를 찾기 위해 총력을...   \n",
              "78841  94119   월요일 술집 종업원 명은 김회장과 아들에게 폭행을 당했음을 진술했다고 경찰은 말했다 .   \n",
              "78842  94120                      그러나 불충분한 증거 확보로 수사에 어려움이 있다 .   \n",
              "78843  94121                 김회장과 그의 아들은 보복폭행 혐의를 강력히 부인하고 있다 .   \n",
              "78844  94122  경찰은 김회장의 집무실에서 추가 증거를 찾은 이후 가능한 한 오늘 김회장과 아들을 ...   \n",
              "\n",
              "                                             en_sentence  \n",
              "0      <start> much of personal computing is about ca...  \n",
              "1      <start> so a mention a few weeks ago about a r...  \n",
              "2      <start> like all optical mice , but it also do...  \n",
              "3      <start> uses gyroscopic sensors to control the...  \n",
              "4      <start> intelligence officials have revealed a...  \n",
              "...                                                  ...  \n",
              "78840  <start> we are hoping to seize material eviden...  \n",
              "78841  <start> on monday , police secured statements ...  \n",
              "78842  <start> but the lack of material evidence is m...  \n",
              "78843  <start> kim and his son both deny the allegati...  \n",
              "78844  <start> police are planning to seek arrest war...  \n",
              "\n",
              "[78845 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e1ce064b-2fb4-4be1-a4f4-79b2e3d178d5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>ko_sentence</th>\n",
              "      <th>en_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>개인용 컴퓨터 사용의 상당 부분은 이것보다 뛰어날 수 있느냐 ?</td>\n",
              "      <td>&lt;start&gt; much of personal computing is about ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>모든 광마우스와 마찬가지 로 이 광마우스도 책상 위에 놓는 마우스 패드를 필요로 하...</td>\n",
              "      <td>&lt;start&gt; so a mention a few weeks ago about a r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>그러나 이것은 또한 책상도 필요로 하지 않는다 .</td>\n",
              "      <td>&lt;start&gt; like all optical mice , but it also do...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>. 달러하는 이 최첨단 무선 광마우스는 허공에서 팔목 , 팔 , 그외에 어떤 부분이...</td>\n",
              "      <td>&lt;start&gt; uses gyroscopic sensors to control the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>정보 관리들은 동남 아시아에서의 선박들에 대한 많은 테러 계획들이 실패로 돌아갔음을...</td>\n",
              "      <td>&lt;start&gt; intelligence officials have revealed a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78840</th>\n",
              "      <td>94118</td>\n",
              "      <td>우리는 월 일 김승연 회장과 그의 아들이 보복폭행에 가담한 혐의를 찾기 위해 총력을...</td>\n",
              "      <td>&lt;start&gt; we are hoping to seize material eviden...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78841</th>\n",
              "      <td>94119</td>\n",
              "      <td>월요일 술집 종업원 명은 김회장과 아들에게 폭행을 당했음을 진술했다고 경찰은 말했다 .</td>\n",
              "      <td>&lt;start&gt; on monday , police secured statements ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78842</th>\n",
              "      <td>94120</td>\n",
              "      <td>그러나 불충분한 증거 확보로 수사에 어려움이 있다 .</td>\n",
              "      <td>&lt;start&gt; but the lack of material evidence is m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78843</th>\n",
              "      <td>94121</td>\n",
              "      <td>김회장과 그의 아들은 보복폭행 혐의를 강력히 부인하고 있다 .</td>\n",
              "      <td>&lt;start&gt; kim and his son both deny the allegati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78844</th>\n",
              "      <td>94122</td>\n",
              "      <td>경찰은 김회장의 집무실에서 추가 증거를 찾은 이후 가능한 한 오늘 김회장과 아들을 ...</td>\n",
              "      <td>&lt;start&gt; police are planning to seek arrest war...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>78845 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1ce064b-2fb4-4be1-a4f4-79b2e3d178d5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e1ce064b-2fb4-4be1-a4f4-79b2e3d178d5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e1ce064b-2fb4-4be1-a4f4-79b2e3d178d5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop(columns=['index'], inplace=True)"
      ],
      "metadata": {
        "id": "GAN1oEBVWIiW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 중복 문제가 심각하네요. set를 사용하라고 했는데 그냥 pandas의 drop_duplicate를 썼습니다."
      ],
      "metadata": {
        "id": "F6323FoZMKD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 토큰화 수정\n",
        "한국어의 형태소 분석 적용 토큰화: MeCab을 사용합니다. 이것은 [exploration node 8(github)](https://github.com/chhyyi/aiffel/blob/main/LMS/EXP8_imdb_emotion_analysis.ipynb)에서 했던 것을 참고하여 작성합니다.\n"
      ],
      "metadata": {
        "id": "G4ODC8FSvAee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update && apt-get install -y g++ default-jdk\n",
        "!pip install konlpy\n",
        "!sudo apt-get install curl git\n",
        "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5PwEd91vWoM",
        "outputId": "ad66f096-2cf7-4144-cb89-c1a1f0b5ac19"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:7 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Ign:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "default-jdk is already the newest version (2:1.11-68ubuntu1~18.04.1).\n",
            "g++ is already the newest version (4:7.4.0-1ubuntu2.3).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "curl is already the newest version (7.58.0-2ubuntu3.20).\n",
            "git is already the newest version (1:2.17.1-1ubuntu0.13).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "mecab-ko is already installed\n",
            "mecab-ko-dic is already installed\n",
            "mecab-python is already installed\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import konlpy\n",
        "import gensim\n",
        "from konlpy.tag import Mecab\n",
        "\n",
        "num_words=10000\n",
        "tokenizer = Mecab()\n",
        "stopwords_kr = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']"
      ],
      "metadata": {
        "id": "I2J4fjbLvXYh"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "#Counter([1,2,3,4,2,3,4])\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "en_stopwords = list(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZrZMMsfJI5R",
        "outputId": "31c2b25e-4af3-41c6-a0eb-0d40786657a7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xg5sDhT8fZQr"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_int_encode(df, num_words=num_words, maxlen=40):\n",
        "    \"\"\"\n",
        "    tokenize_and_int_encode(df, num_words=num_words, maxlen=40)\n",
        "    receive pandas DataFrame and tokenize it's ko_sentence.\n",
        "    return processed korean sentences and corresponding english sentences\n",
        "    return dictionaries; word_to_index, index_to_word\n",
        "    \"\"\"\n",
        "    idx=[] #integer encoded sentences array. will be returned first.\n",
        "    \n",
        "    raw_corpus=[] #after Counter, set(raw_corpus) will be corpus.\n",
        "    en_sentences=[]\n",
        "    ko_sentences=[]\n",
        "    #word to_index, index_to_word 초기화.\n",
        "\n",
        "    word_to_index={}\n",
        "    index_to_word={}\n",
        "    #dict_last_index=3 #while 0, 1, 2 will be <PAD>, <BOS>, <UNK>(unkown)\n",
        "\n",
        "    #tokenize by mecab\n",
        "    for ko_sent, en_sent in zip(df['ko_sentence'].to_list(), df['en_sentence'].to_list()):\n",
        "        tokens=list(tokenizer.morphs(ko_sent))\n",
        "        if len(tokens)>maxlen:\n",
        "            continue\n",
        "        else:\n",
        "            en_sentences.append(en_sent)\n",
        "            ko_sentences.append(tokens)\n",
        "            raw_corpus+=tokens\n",
        "    raw_corpus = [ww for ww in raw_corpus if ww not in stopwords_kr]\n",
        "    print('example of raw_corpus',raw_corpus[:10])\n",
        "\n",
        "    most_words=dict(Counter(raw_corpus).most_common(num_words)).keys()\n",
        "    print('length of most common {} words are '.format(num_words),len(most_words))\n",
        "    word_to_index = dict(zip(most_words, list(range(3, 3+len(most_words)))))\n",
        "    index_to_word = dict(zip(list(range(3, 3+len(most_words))), most_words))\n",
        "\n",
        "    #encode as integer\n",
        "    for tokens in ko_sentences:\n",
        "        _=[]\n",
        "        for tk in tokens:\n",
        "            if tk in most_words:\n",
        "                _.append(word_to_index[tk])\n",
        "            else:\n",
        "                _.append(2)\n",
        "        idx.append(_)\n",
        "\n",
        "    word_to_index={**word_to_index, \"<PAD>\":0, \"<BOS>\":1, \"<UNK>\":2}\n",
        "    index_to_word={**index_to_word, 0:\"<PAD>\", 1:\"<BOS>\", 2:\"<UNK>\"}                \n",
        "\n",
        "    return idx, en_sentences, word_to_index, index_to_word\n",
        "\n",
        "#index_to_word도 load_data에서 만들었기 때문에 그냥 같이 반환합니다.\n",
        "kr_idx, en_sentences, word2index_ko, index2word_ko=tokenize_and_int_encode(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwZRznC2Jo-j",
        "outputId": "5347e086-dea9-434f-9674-f1d56dbe631f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "example of raw_corpus ['개인', '용', '컴퓨터', '사용', '상당', '부분', '이것', '보다', '뛰어날', '수']\n",
            "length of most common 10000 words are  10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('lengths - kr_idx(enc_input):{}, en_sentences:{}, word2index_ko:{}, index2word_ko:{}'.format(len(kr_idx), len(en_sentences), len(word2index_ko), len(index2word_ko)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhCTXJyZZ3bw",
        "outputId": "61eda12a-9602-46ba-cbdd-644efe59b3c5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lengths - kr_idx(enc_input):66360, en_sentences:66360, word2index_ko:10003, index2word_ko:10003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['en_sentence'].sample().values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6J8UDBCBtDW",
        "outputId": "dbb3d5cb-2725-4b00-9366-b2a6d78193d1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['<start> a three way meeting with u . s . secretary of state condoleezza rice , israeli prime minister ehud olmert and palestinian president mahmoud abbas will take place in jerusalem on february , olmert said during a speech tuesday . <end>'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def en_tokenize_and_encode(en_sents, num_words=num_words):\n",
        "    \"\"\"\n",
        "    tokenize_and_int_encode\n",
        "    take english sentences and tokenize and encode as integers.\n",
        "    return processed english sentences\n",
        "    return dictionaries; word_to_index, index_to_word\n",
        "    \"\"\"\n",
        "\n",
        "    idx=[] #integer encoded sentences array. will be returned first.\n",
        "\n",
        "    raw_corpus=[] #after Counter, set(raw_corpus) will be corpus.\n",
        "    sentences=[]\n",
        "    #word to_index, index_to_word 초기화.\n",
        "\n",
        "    word_to_index={}\n",
        "    index_to_word={}\n",
        "    #dict_last_index=3 #while 0, 1, 2 will be <PAD>, <BOS>, <UNK>(unkown)\n",
        "\n",
        "    #tokenize by mecab\n",
        "    for sent in en_sents:\n",
        "        sentences.append(list(sent.split()))\n",
        "        raw_corpus+=sentences[-1]\n",
        "    raw_corpus=[i for i in raw_corpus if i not in en_stopwords]\n",
        "    most_words=list(dict(Counter(raw_corpus).most_common(num_words)).keys())\n",
        "    print('length of most common {} words are '.format(num_words),len(most_words))\n",
        "    print('most common words: ', most_words[:10])\n",
        "    word_to_index = dict(zip(most_words, list(range(3, 3+len(most_words)))))\n",
        "    index_to_word = dict(zip(list(range(3, 3+len(most_words))), most_words))\n",
        "    print(len(word_to_index), len(index_to_word))\n",
        "\n",
        "    for tokens in sentences:\n",
        "        _=[]\n",
        "        for tk in tokens:\n",
        "            if tk in most_words:\n",
        "                _.append(word_to_index[tk])\n",
        "            else:\n",
        "                _.append(2)\n",
        "        idx.append(_)\n",
        "\n",
        "    word_to_index={**word_to_index, \"<PAD>\":0, \"<BOS>\":1, \"<UNK>\":2}\n",
        "    index_to_word={**index_to_word, 0:\"<PAD>\", 1:\"<BOS>\", 2:\"<UNK>\"}                \n",
        "\n",
        "    return idx, word_to_index, index_to_word\n"
      ],
      "metadata": {
        "id": "a0Qa0ut6DZi4"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_idx, word2index_en, index2word_en=en_tokenize_and_encode(en_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v30dpmwgVbDI",
        "outputId": "eaa4b22a-b31b-463f-c59a-58f4a59698cb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of most common 10000 words are  10000\n",
            "most common words:  ['.', ',', '<start>', '<end>', 'said', 'year', 'people', 'two', 'u', 'one']\n",
            "10000 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#np.max([len(x) for x in en_idx])"
      ],
      "metadata": {
        "id": "LJ-vjdEtVk0N"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_idx = tf.keras.preprocessing.sequence.pad_sequences(en_idx, padding='post')\n",
        "kr_idx = tf.keras.preprocessing.sequence.pad_sequences(kr_idx, padding='post')"
      ],
      "metadata": {
        "id": "6igracxDXSt5"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(kr_idx, en_idx, test_size=0.2)\n",
        "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gw2s06QDWXOW",
        "outputId": "1c406815-f1c4-41cc-dec6-d2048556a06d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(53088, 40) (13272, 40) (53088, 85) (13272, 85)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.w_dec = tf.keras.layers.Dense(units)\n",
        "        self.w_enc = tf.keras.layers.Dense(units)\n",
        "        self.w_com = tf.keras.layers.Dense(1)\n",
        "    \n",
        "    def call(self, h_enc, h_dec):\n",
        "        # h_enc shape: [batch x length x units]\n",
        "        # h_dec shape: [batch x units]\n",
        "\n",
        "        h_enc = self.w_enc(h_enc)\n",
        "        h_dec = tf.expand_dims(h_dec, 1)\n",
        "        h_dec = self.w_dec(h_dec)\n",
        "\n",
        "        score = self.w_com(tf.nn.tanh(h_dec + h_enc))\n",
        "        \n",
        "        attn = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "        context_vec = attn * h_enc\n",
        "        context_vec = tf.reduce_sum(context_vec, axis=1)\n",
        "\n",
        "        return context_vec, attn\n",
        "\n",
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.d1 = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(enc_units, return_sequences = True)\n",
        "\t\t\n",
        "    def call(self, x):\n",
        "        x = self.d1(x)\n",
        "        x=self.gru(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(dec_units, return_sequences=True, return_state=True)\n",
        "        self.attention = BahdanauAttention(self.dec_units)   # Attention 필수 사용!\n",
        "        self.output_layer = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, x, h_dec, enc_out):\n",
        "        context_vec, attn =self.attention(enc_out, h_dec)\n",
        "\n",
        "        out = self.embedding(x)\n",
        "        out = tf.concat([tf.expand_dims(context_vec, 1), out], axis = -1)\n",
        "\n",
        "        out, state = self.gru(out)\n",
        "        out = tf.reshape(out, (-1, out.shape[2]))\n",
        "        out = self.output_layer(out)\n",
        "\n",
        "        return out, h_dec, attn\n",
        "\n",
        "# 코드를 실행하세요.\n",
        "\n",
        "BATCH_SIZE     = 64\n",
        "SRC_VOCAB_SIZE = len(index2word_ko) + 1\n",
        "TGT_VOCAB_SIZE = len(index2word_en) + 1\n",
        "\n",
        "units         = 1024\n",
        "embedding_dim = 512\n",
        "\n",
        "encoder = Encoder(SRC_VOCAB_SIZE, embedding_dim, units)\n",
        "decoder = Decoder(TGT_VOCAB_SIZE, embedding_dim, units)\n",
        "\n",
        "# sample input\n",
        "sequence_len = 30\n",
        "\n",
        "sample_enc = tf.random.uniform((BATCH_SIZE, sequence_len))\n",
        "sample_output = encoder(sample_enc)\n",
        "\n",
        "print ('Encoder Output:', sample_output.shape)\n",
        "\n",
        "sample_state = tf.random.uniform((BATCH_SIZE, units))\n",
        "\n",
        "sample_logits, h_dec, attn = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                     sample_state, sample_output)\n",
        "\n",
        "print ('Decoder Output:', sample_logits.shape)\n",
        "print ('Decoder Hidden State:', h_dec.shape)\n",
        "print ('Attention:', attn.shape)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss = loss_object(real, pred)\n",
        "    \n",
        "    mask = tf.cast(mask, dtype=loss.dtype)\n",
        "    loss *= mask\n",
        "    \n",
        "    return tf.reduce_mean(loss)\n",
        "\n",
        "print(\"슝~\")\n",
        "\n",
        "@tf.function\n",
        "def train_step(src, tgt, encoder, decoder, optimizer, dec_w2i):\n",
        "    bsz = src.shape[0]\n",
        "    loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_out = encoder(src)\n",
        "        h_dec = enc_out[:, -1]\n",
        "        \n",
        "        dec_src = tf.expand_dims([dec_w2i['<start>']] * bsz, 1)\n",
        "\n",
        "        for t in range(1, tgt.shape[1]):\n",
        "            pred, h_dec, _ = decoder(dec_src, h_dec, enc_out)\n",
        "\n",
        "            loss += loss_function(tgt[:, t], pred)\n",
        "            dec_src = tf.expand_dims(tgt[:, t], 1)\n",
        "        \n",
        "    batch_loss = (loss / int(tgt.shape[1]))\n",
        "\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "    \n",
        "    return batch_loss\n",
        "\n",
        "from tqdm import tqdm    # tqdm\n",
        "import random\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "@tf.function\n",
        "def eval_step(src, tgt, encoder, decoder, optimizer, dec_w2i):\n",
        "    bsz = src.shape[0]\n",
        "    loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_out = encoder(src)\n",
        "        h_dec = enc_out[:, -1]\n",
        "        \n",
        "        dec_src = tf.expand_dims([dec_w2i['<start>']] * bsz, 1)\n",
        "\n",
        "        for t in range(1, tgt.shape[1]):\n",
        "            pred, h_dec, _ = decoder(dec_src, h_dec, enc_out)\n",
        "\n",
        "            loss += loss_function(tgt[:, t], pred)\n",
        "            dec_src = tf.expand_dims(tgt[:, t], 1)\n",
        "        \n",
        "    batch_loss = (loss / int(tgt.shape[1]))\n",
        "    return batch_loss\n",
        "\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "    \n",
        "    idx_list = list(range(0, X_train.shape[0], BATCH_SIZE))\n",
        "    random.shuffle(idx_list)\n",
        "    t = tqdm(idx_list)    # tqdm\n",
        "\n",
        "    for (batch, idx) in enumerate(t):\n",
        "        batch_loss = train_step(X_train[idx:idx+BATCH_SIZE],\n",
        "                                Y_train[idx:idx+BATCH_SIZE],\n",
        "                                encoder,\n",
        "                                decoder,\n",
        "                                optimizer,\n",
        "                                word2index_en)\n",
        "    \n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        t.set_description_str('Epoch %2d' % (epoch + 1))    # tqdm\n",
        "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))    # tqdm\n",
        "    \n",
        "    test_total_loss = 0\n",
        "    idx_list = list(range(0, X_test.shape[0], BATCH_SIZE))\n",
        "    random.shuffle(idx_list)\n",
        "    t = tqdm(idx_list)\n",
        "\n",
        "    for (batch, idx) in enumerate(t):\n",
        "        batch_loss = eval_step(X_test[idx:idx+BATCH_SIZE], Y_test[idx:idx+BATCH_SIZE],\n",
        "        encoder, decoder,\n",
        "        optimizer, word2index_en)\n",
        "        total_loss +=batch_loss\n",
        "\n",
        "        t.set_description_str('Test Epoch %2d' % (epoch + 1))    # tqdm\n",
        "        t.set_postfix_str('Test Loss %.4f' % (total_loss.numpy() / (batch + 1)))    # tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3yjvztpW33d",
        "outputId": "64a2ccbb-af75-476f-b2d6-6b3c5531c1f2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder Output: (64, 30, 1024)\n",
            "Decoder Output: (64, 10004)\n",
            "Decoder Hidden State: (64, 1024)\n",
            "Attention: (64, 30, 1)\n",
            "슝~\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch  1: 100%|██████████| 830/830 [17:24<00:00,  1.26s/it, Loss 1.4250]\n",
            "Test Epoch  1: 100%|██████████| 208/208 [02:50<00:00,  1.22it/s, Test Loss 7.1072]\n",
            "Epoch  2: 100%|██████████| 830/830 [14:45<00:00,  1.07s/it, Loss 1.4140]\n",
            "Test Epoch  2: 100%|██████████| 208/208 [01:51<00:00,  1.87it/s, Test Loss 7.0636]\n",
            "Epoch  3: 100%|██████████| 830/830 [14:45<00:00,  1.07s/it, Loss 1.3794]\n",
            "Test Epoch  3: 100%|██████████| 208/208 [01:52<00:00,  1.85it/s, Test Loss 6.7804]\n",
            "Epoch  4: 100%|██████████| 830/830 [14:52<00:00,  1.08s/it, Loss 1.2046]\n",
            "Test Epoch  4: 100%|██████████| 208/208 [01:51<00:00,  1.86it/s, Test Loss 5.9668]\n",
            "Epoch  5: 100%|██████████| 830/830 [14:51<00:00,  1.07s/it, Loss 1.1004]\n",
            "Test Epoch  5: 100%|██████████| 208/208 [01:52<00:00,  1.85it/s, Test Loss 5.4925]\n",
            "Epoch  6: 100%|██████████| 830/830 [14:52<00:00,  1.07s/it, Loss 1.0292]\n",
            "Test Epoch  6: 100%|██████████| 208/208 [01:51<00:00,  1.86it/s, Test Loss 5.1801]\n",
            "Epoch  7: 100%|██████████| 830/830 [14:50<00:00,  1.07s/it, Loss 0.9724]\n",
            "Test Epoch  7: 100%|██████████| 208/208 [01:53<00:00,  1.83it/s, Test Loss 4.9423]\n",
            "Epoch  8: 100%|██████████| 830/830 [14:50<00:00,  1.07s/it, Loss 0.9207]\n",
            "Test Epoch  8: 100%|██████████| 208/208 [01:53<00:00,  1.84it/s, Test Loss 4.7296]\n",
            "Epoch  9: 100%|██████████| 830/830 [14:49<00:00,  1.07s/it, Loss 0.8709]\n",
            "Test Epoch  9: 100%|██████████| 208/208 [01:53<00:00,  1.83it/s, Test Loss 4.5366]\n",
            "Epoch 10: 100%|██████████| 830/830 [14:55<00:00,  1.08s/it, Loss 0.8220]\n",
            "Test Epoch 10: 100%|██████████| 208/208 [01:52<00:00,  1.85it/s, Test Loss 4.3510]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(sentence, encoder, decoder):\n",
        "    attention = np.zeros((Y_train.shape[-1], X_train.shape[-1]))\n",
        "    \n",
        "    ####inserted line by chyi####\n",
        "    ko_sent = preprocess_ko(sentence)\n",
        "    _=pd.DataFrame()\n",
        "    \n",
        "    tokens=tokenizer.morphs(ko_sent)\n",
        "\n",
        "    _=[]\n",
        "    for tk in tokens:\n",
        "        if tk in word2index_ko.keys():\n",
        "            _.append(word2index_ko[tk])\n",
        "        else:\n",
        "            _.append(2)\n",
        "    inputs=[_,]\n",
        "    print(inputs)\n",
        "    \n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
        "                                                           maxlen=40,\n",
        "                                                           padding='post')\n",
        "\n",
        "    result = ''\n",
        "\n",
        "    enc_out = encoder(inputs)\n",
        "\n",
        "    dec_hidden = enc_out[:, -1]\n",
        "    dec_input = tf.expand_dims([word2index_en['<start>']],0)\n",
        "\n",
        "    for t in range(Y_train.shape[-1]):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                             dec_hidden,\n",
        "                                                             enc_out)\n",
        "\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = \\\n",
        "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0]).numpy()\n",
        "        #if predicted_id>2:\n",
        "        result += index2word_en[predicted_id] + ' '\n",
        "\n",
        "        if index2word_en[predicted_id] == '<end>':\n",
        "            return result, sentence, attention\n",
        "\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence, attention\n",
        "\n",
        "\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 14}\n",
        "\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def translate(sentence, encoder, decoder):\n",
        "    result, sentence, attention = evaluate(sentence, encoder, decoder)\n",
        "\n",
        "    print('Input: %s' % (sentence))\n",
        "    print('Predicted translation: {}'.format(result))\n",
        "    \n",
        "    #attention = attention[:len(result.split()), :len(sentence.split())]\n",
        "    #plot_attention(attention, sentence.split(), result.split(' '))\n",
        "\n",
        "\n",
        "translate(\"나는 그런 한심한 상황을 이해할 수 없었다. 왜 그렇게 된 거지?\", encoder, decoder)\n"
      ],
      "metadata": {
        "id": "24IvP0LJZAgp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e30a1c7d-cc47-4442-a02f-5f9534adde1d"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[83, 2, 1303, 2, 2, 251, 5, 1734, 26, 29, 56, 21, 4, 3, 1686, 1973, 31, 2009, 19, 349]]\n",
            "Input: 나는 그런 한심한 상황을 이해할 수 없었다. 왜 그렇게 된 거지?\n",
            "Predicted translation: <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_save = '/content/drive/MyDrive/colabdata/modulabs/nlp8/'\n",
        "encoder.save_weights(path_save+'my_checkpoint_enc')\n",
        "decoder.save_weights(path_save+'my_checkpoint_dec')"
      ],
      "metadata": {
        "id": "Eocs0CCDempj"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translate('개인용 컴퓨터 사용의 상당 부분은 이것보다 뛰어날 수 있느냐 ?', encoder, decoder)"
      ],
      "metadata": {
        "id": "JCvj-8Y2rQKp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6343ff2c-a070-4f6e-f99d-bf64c95b7ee2"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[696, 596, 522, 160, 2, 1312, 840, 2, 707, 150, 2, 29, 9, 3709, 349]]\n",
            "Input: 개인용 컴퓨터 사용의 상당 부분은 이것보다 뛰어날 수 있느냐 ?\n",
            "Predicted translation: <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2index_en['<start>']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYder_uU3UGN",
        "outputId": "71a3ac28-9bf1-497d-a935-c9f2b90f1ddc"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AOcMhtAV5Ewb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}